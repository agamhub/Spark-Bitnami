{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aee6c1b-f8aa-4065-9ad7-bf27b1107ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Int: long (nullable = true)\n",
      " |-- Decimal: decimal(18,2) (nullable = true)\n",
      " |-- Float: decimal(18,2) (nullable = true)\n",
      " |-- Money: string (nullable = true)\n",
      " |-- Bigint: long (nullable = true)\n",
      " |-- DateTime: timestamp (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n",
      "+---+-------+------+-------+------+-------------------+----------+\n",
      "|Int|Decimal| Float|  Money|Bigint|           DateTime|      Date|\n",
      "+---+-------+------+-------+------+-------------------+----------+\n",
      "|  1| 141.23|141.23|4141.32|     0|2025-03-22 10:00:00|2025-03-22|\n",
      "+---+-------+------+-------+------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "def spark_read_csv_from_os(spark, file_path, schema, **kwargs):\n",
    "    base_options = {\n",
    "        \"inferSchema\": \"False\",\n",
    "        \"header\": \"True\",\n",
    "        \"quote\": '\"',\n",
    "        \"columnNameOfCorruptRecord\": \"rejected_records\",\n",
    "        \"mode\": \"PERMISSIVE\"\n",
    "    }\n",
    "    base_options.update(kwargs)\n",
    "    \n",
    "    try:\n",
    "        #schema = StructType(schema.fields + [StructField(\"rejected_records\", StringType(), True)])\n",
    "        df = spark.read.options(**base_options).schema(schema).csv(file_path)\n",
    "    \n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at path: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:  # Catch other potential exceptions (e.g., parsing errors)\n",
    "        print(f\"An error occurred while reading the CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"/mnt/apps/Files/ETL4/TMP/test.csv\"\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"Int\", LongType(), True),\n",
    "        StructField(\"Decimal\", DecimalType(18, 2), True),\n",
    "        StructField(\"Float\", DecimalType(18, 2), True),\n",
    "        StructField(\"Money\", StringType(), True),\n",
    "        StructField(\"Bigint\", LongType(), True),\n",
    "        StructField(\"DateTime\", TimestampType(), True),\n",
    "        StructField(\"Date\", DateType(), True)\n",
    "    ])\n",
    "    \n",
    "    spark = SparkSession. \\\n",
    "        builder. \\\n",
    "        appName(\"Testing\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.ui.port\", \"4222\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    df = spark_read_csv_from_os(spark, path, schema, sep=\"|\")\n",
    "    df = df.withColumn(\"Money\", regexp_replace(col(\"Money\"), \",\", \".\"))\n",
    "    \n",
    "    df.printSchema()\n",
    "    df.show()\n",
    "    \n",
    "    spark.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96543d2-ea4d-4423-bcd1-950b4fcb9e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/23 11:32:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/23 11:32:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/23 11:32:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/23 11:32:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/23 11:32:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+----------+-----------+\n",
      "|CAST(replace(Budget, ,, .) AS DECIMAL(18,2))|Budget    |SM         |\n",
      "+--------------------------------------------+----------+-----------+\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "|1000232.32                                  |1000232,32|18004181.76|\n",
      "+--------------------------------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def loadTable(**kwargs):\n",
    "    pathCheck = kwargs[\"path\"].replace(\"/part*\",\"\")\n",
    "    if not os.path.exists(pathCheck):\n",
    "        return None\n",
    "    try:\n",
    "        if kwargs[\"loadType\"] == \"Parquet\":\n",
    "            sparkDqc.sql(f\"\"\"\n",
    "            CREATE EXTERNAL TABLE IF NOT EXISTS {kwargs[\"tableName\"]}\n",
    "            USING PARQUET LOCATION '{kwargs[\"path\"]}'\n",
    "            \"\"\")\n",
    "            return True\n",
    "        else:\n",
    "            sparkDqc.sql(f\"\"\"\n",
    "            CREATE EXTERNAL TABLE IF NOT EXISTS {kwargs[\"tableName\"]}\n",
    "            USING CSV\n",
    "            OPTIONS (\n",
    "                'path' '{kwargs[\"path\"]}',\n",
    "                'delimiter' '|',\n",
    "                'compression' 'gzip',\n",
    "                'header' 'true'\n",
    "            )\n",
    "            \"\"\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path = \"/mnt/apps/Files/data-movement/Parquet/RTRNPF\"\n",
    "    \n",
    "    sparkDqc =  SparkSession. \\\n",
    "            builder. \\\n",
    "            appName(\"parquet\") \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .config(\"spark.ui.port\", \"4222\") \\\n",
    "            .getOrCreate()\n",
    "            \n",
    "    df_table = loadTable(path=path, loadType=\"Parquet\", tableName=\"RTRNPF\")\n",
    "    df_sql = sparkDqc.sql(\"SELECT CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2)), Budget, SUM(CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2))) OVER(ORDER BY NULL) SM FROM RTRNPF\").show(truncate=False)\n",
    "\n",
    "    sparkDqc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
