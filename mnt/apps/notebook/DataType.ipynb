{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aee6c1b-f8aa-4065-9ad7-bf27b1107ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/14 14:53:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Int: long (nullable = true)\n",
      " |-- Decimal: decimal(18,2) (nullable = true)\n",
      " |-- Float: decimal(18,2) (nullable = true)\n",
      " |-- Money: string (nullable = true)\n",
      " |-- Bigint: long (nullable = true)\n",
      " |-- DateTime: timestamp (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n",
      "+---+-------+------+-------+------+-------------------+----------+\n",
      "|Int|Decimal| Float|  Money|Bigint|           DateTime|      Date|\n",
      "+---+-------+------+-------+------+-------------------+----------+\n",
      "|  1| 141.23|141.23|4141.32|     0|2025-03-22 10:00:00|2025-03-22|\n",
      "+---+-------+------+-------+------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "def spark_read_csv_from_os(spark, file_path, schema, **kwargs):\n",
    "    base_options = {\n",
    "        \"inferSchema\": \"False\",\n",
    "        \"header\": \"True\",\n",
    "        \"quote\": '\"',\n",
    "        \"columnNameOfCorruptRecord\": \"rejected_records\",\n",
    "        \"mode\": \"PERMISSIVE\"\n",
    "    }\n",
    "    base_options.update(kwargs)\n",
    "    \n",
    "    try:\n",
    "        #schema = StructType(schema.fields + [StructField(\"rejected_records\", StringType(), True)])\n",
    "        df = spark.read.options(**base_options).schema(schema).csv(file_path)\n",
    "    \n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at path: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:  # Catch other potential exceptions (e.g., parsing errors)\n",
    "        print(f\"An error occurred while reading the CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"/mnt/apps/Files/ETL4/TMP/test.csv\"\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"Int\", LongType(), True),\n",
    "        StructField(\"Decimal\", DecimalType(18, 2), True),\n",
    "        StructField(\"Float\", DecimalType(18, 2), True),\n",
    "        StructField(\"Money\", StringType(), True),\n",
    "        StructField(\"Bigint\", LongType(), True),\n",
    "        StructField(\"DateTime\", TimestampType(), True),\n",
    "        StructField(\"Date\", DateType(), True)\n",
    "    ])\n",
    "    \n",
    "    spark = SparkSession. \\\n",
    "        builder. \\\n",
    "        appName(\"Testing\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.ui.port\", \"4222\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    df = spark_read_csv_from_os(spark, path, schema, sep=\"|\")\n",
    "    df = df.withColumn(\"Money\", regexp_replace(col(\"Money\"), \",\", \".\"))\n",
    "    \n",
    "    df.printSchema()\n",
    "    df.show()\n",
    "    \n",
    "    spark.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96543d2-ea4d-4423-bcd1-950b4fcb9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def loadTable(**kwargs):\n",
    "    pathCheck = kwargs[\"path\"].replace(\"/part*\",\"\")\n",
    "    if not os.path.exists(pathCheck):\n",
    "        return None\n",
    "    try:\n",
    "        if kwargs[\"loadType\"] == \"Parquet\":\n",
    "            sparkDqc.sql(f\"\"\"\n",
    "            CREATE EXTERNAL TABLE IF NOT EXISTS {kwargs[\"tableName\"]}\n",
    "            USING PARQUET LOCATION '{kwargs[\"path\"]}'\n",
    "            \"\"\")\n",
    "            return True\n",
    "        else:\n",
    "            sparkDqc.sql(f\"\"\"\n",
    "            CREATE EXTERNAL TABLE IF NOT EXISTS {kwargs[\"tableName\"]}\n",
    "            USING CSV\n",
    "            OPTIONS (\n",
    "                'path' '{kwargs[\"path\"]}',\n",
    "                'delimiter' '|',\n",
    "                'compression' 'gzip',\n",
    "                'header' 'true'\n",
    "            )\n",
    "            \"\"\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path = \"/mnt/apps/Files/data-movement/Parquet/RTRNPF\"\n",
    "    \n",
    "    sparkDqc =  SparkSession. \\\n",
    "            builder. \\\n",
    "            appName(\"parquet\") \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .config(\"spark.ui.port\", \"4222\") \\\n",
    "            .getOrCreate()\n",
    "            \n",
    "    df_table = loadTable(path=path, loadType=\"Parquet\", tableName=\"RTRNPF\")\n",
    "    df_sql = sparkDqc.sql(\"SELECT * FROM RTRNPF LIMIT 100\")\n",
    "\n",
    "    html = df_sql.toPandas().to_html()  # Convert to HTML\n",
    "    styled_html = f\"\"\"\n",
    "    <style>\n",
    "      table {{width: 100%; border-collapse: collapse;}}\n",
    "      th, td {{border: 1px solid black; padding: 8px; text-align: left;}}\n",
    "    </style>\n",
    "    {html}\n",
    "    \"\"\"\n",
    "    HTML(styled_html)\n",
    "\n",
    "    sparkDqc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6d1651-a55f-4442-9675-d571cd0e5fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-numeric rows: 3\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, isnull, count, length\n",
    "\n",
    "def count_non_numeric(df, colName):\n",
    "    df_cleaned = df.withColumn(\n",
    "        f\"{colName}_cleaned\",\n",
    "        regexp_replace(col(colName), \"[^0-9.]\", \"\")\n",
    "    )\n",
    "\n",
    "    df_non_numeric = df_cleaned.filter(\n",
    "        (length(col(f\"{colName}_cleaned\")) == 0) & col(colName).isNotNull()\n",
    "    )\n",
    "\n",
    "    non_numeric_count = df_non_numeric.count()\n",
    "\n",
    "    return non_numeric_count\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CountNonNumeric\").getOrCreate()\n",
    "\n",
    "data = [(\"1000.31\",), (None,), (\"AGAM\",), (\"AGAM\",), (\"AGAM\",)]\n",
    "df = spark.createDataFrame(data, [\"AMT\"])\n",
    "\n",
    "non_numeric_count = count_non_numeric(df, \"AMT\")\n",
    "print(f\"Number of non-numeric rows: {non_numeric_count}\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee009aaf-db48-4004-ba88-c4caf0bf51bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  table {width: 100%; border-collapse: collapse;}\n",
       "  th, td {border: 1px solid black; padding: 8px; text-align: left; word-wrap: break-word;}\n",
       "  th, td:nth-child(1) {width: 50px;} /* Example: Fixed width for the first column */\n",
       "  th, td:nth-child(2) {width: 150px;} /* Example: Fixed width for the second column */\n",
       "  /* Add widths for other columns as needed */\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Index</th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Phone 1</th>\n",
       "      <th>Phone 2</th>\n",
       "      <th>Email</th>\n",
       "      <th>Subscription Date</th>\n",
       "      <th>Website</th>\n",
       "      <th>Budget</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaa</th>\n",
       "      <th>bbbbbbbbbbbbbbbbbbbbbbbbbbbb</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</th>\n",
       "      <th>Index</th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Phone 1</th>\n",
       "      <th>Phone 2</th>\n",
       "      <th>Email</th>\n",
       "      <th>Subscription Date</th>\n",
       "      <th>Website</th>\n",
       "      <th>Budget</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaa</th>\n",
       "      <th>bbbbbbbbbbbbbbbbbbbbbbbbbbbb</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4962fdbE6Bfee6D</td>\n",
       "      <td>Pam</td>\n",
       "      <td>Sparks</td>\n",
       "      <td>Patel-Deleon</td>\n",
       "      <td>Blakemouth</td>\n",
       "      <td>British Indian Ocean Territory (Chagos Archipelago)</td>\n",
       "      <td>267-243-9490x035</td>\n",
       "      <td>480-078-0535x889</td>\n",
       "      <td>nicolas00@faulkner-kramer.com</td>\n",
       "      <td>2020-11-29</td>\n",
       "      <td>https://nelson.com/</td>\n",
       "      <td>1000232,32</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>4962fdbE6Bfee6D</td>\n",
       "      <td>Pam</td>\n",
       "      <td>Sparks</td>\n",
       "      <td>Patel-Deleon</td>\n",
       "      <td>Blakemouth</td>\n",
       "      <td>British Indian Ocean Territory (Chagos Archipelago)</td>\n",
       "      <td>267-243-9490x035</td>\n",
       "      <td>480-078-0535x889</td>\n",
       "      <td>nicolas00@faulkner-kramer.com</td>\n",
       "      <td>2020-11-29</td>\n",
       "      <td>https://nelson.com/</td>\n",
       "      <td>1000232,32</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9b12Ae76fdBc9bE</td>\n",
       "      <td>Gina</td>\n",
       "      <td>Rocha</td>\n",
       "      <td>Acosta, Paul and Barber</td>\n",
       "      <td>East Lynnchester</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>027.142.0940</td>\n",
       "      <td>+1-752-593-4777x07171</td>\n",
       "      <td>yfarley@morgan.com</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>https://pineda-rogers.biz/</td>\n",
       "      <td>1000232,32</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>4962fdbE6Bfee6D</td>\n",
       "      <td>Pam</td>\n",
       "      <td>Sparks</td>\n",
       "      <td>Patel-Deleon</td>\n",
       "      <td>Blakemouth</td>\n",
       "      <td>British Indian Ocean Territory (Chagos Archipelago)</td>\n",
       "      <td>267-243-9490x035</td>\n",
       "      <td>480-078-0535x889</td>\n",
       "      <td>nicolas00@faulkner-kramer.com</td>\n",
       "      <td>2020-11-29</td>\n",
       "      <td>https://nelson.com/</td>\n",
       "      <td>1000232,32</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>39edFd2F60C85BC</td>\n",
       "      <td>Kristie</td>\n",
       "      <td>Greer</td>\n",
       "      <td>Ochoa PLC</td>\n",
       "      <td>West Pamela</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>+1-049-168-7497x5053</td>\n",
       "      <td>+1-311-216-7855</td>\n",
       "      <td>jennyhayden@p</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>4962fdbE6Bfee6D</td>\n",
       "      <td>Pam</td>\n",
       "      <td>Sparks</td>\n",
       "      <td>Patel-Deleon</td>\n",
       "      <td>Blakemouth</td>\n",
       "      <td>British Indian Ocean Territory (Chagos Archipelago)</td>\n",
       "      <td>267-243-9490x035</td>\n",
       "      <td>480-078-0535x889</td>\n",
       "      <td>nicolas00@faulkner-kramer.com</td>\n",
       "      <td>2020-11-29</td>\n",
       "      <td>https://nelson.com/</td>\n",
       "      <td>1000232,32</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "      <td>aaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PrettySparkOutput\").getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, \"4962fdbE6Bfee6D\", \"Pam\", \"Sparks\", \"Patel-Deleon\", \"Blakemouth\", \"British Indian Ocean Territory (Chagos Archipelago)\", \"267-243-9490x035\", \"480-078-0535x889\", \"nicolas00@faulkner-kramer.com\", \"2020-11-29\", \"https://nelson.com/\", \"1000232,32\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",1, \"4962fdbE6Bfee6D\", \"Pam\", \"Sparks\", \"Patel-Deleon\", \"Blakemouth\", \"British Indian Ocean Territory (Chagos Archipelago)\", \"267-243-9490x035\", \"480-078-0535x889\", \"nicolas00@faulkner-kramer.com\", \"2020-11-29\", \"https://nelson.com/\", \"1000232,32\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\"),\n",
    "    (2, \"9b12Ae76fdBc9bE\", \"Gina\", \"Rocha\", \"Acosta, Paul and Barber\", \"East Lynnchester\", \"Costa Rica\", \"027.142.0940\", \"+1-752-593-4777x07171\", \"yfarley@morgan.com\", \"2021-01-03\", \"https://pineda-rogers.biz/\", \"1000232,32\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",1, \"4962fdbE6Bfee6D\", \"Pam\", \"Sparks\", \"Patel-Deleon\", \"Blakemouth\", \"British Indian Ocean Territory (Chagos Archipelago)\", \"267-243-9490x035\", \"480-078-0535x889\", \"nicolas00@faulkner-kramer.com\", \"2020-11-29\", \"https://nelson.com/\", \"1000232,32\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\"),\n",
    "    (3, \"39edFd2F60C85BC\", \"Kristie\", \"Greer\", \"Ochoa PLC\", \"West Pamela\", \"Ecuador\", \"+1-049-168-7497x5053\", \"+1-311-216-7855\", \"jennyhayden@p\", None, None, None,\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",1, \"4962fdbE6Bfee6D\", \"Pam\", \"Sparks\", \"Patel-Deleon\", \"Blakemouth\", \"British Indian Ocean Territory (Chagos Archipelago)\", \"267-243-9490x035\", \"480-078-0535x889\", \"nicolas00@faulkner-kramer.com\", \"2020-11-29\", \"https://nelson.com/\", \"1000232,32\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\",\"aaaaaaaaaaaaaaaaaaaaaaa\")\n",
    "]\n",
    "\n",
    "columns = [\"Index\", \"Customer Id\", \"First Name\", \"Last Name\", \"Company\", \"City\", \"Country\", \"Phone 1\", \"Phone 2\", \"Email\", \"Subscription Date\", \"Website\", \"Budget\",\"aaaaaaaaaaaaaaaaaa\",\"bbbbbbbbbbbbbbbbbbbbbbbbbbbb\",\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\",\"Index\", \"Customer Id\", \"First Name\", \"Last Name\", \"Company\", \"City\", \"Country\", \"Phone 1\", \"Phone 2\", \"Email\", \"Subscription Date\", \"Website\", \"Budget\",\"aaaaaaaaaaaaaaaaaa\",\"bbbbbbbbbbbbbbbbbbbbbbbbbbbb\",\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "pandas_df = df.toPandas()\n",
    "#print(pandas_df)\n",
    "pandas_df = pandas_df.fillna(\"\")\n",
    "html = pandas_df.to_html(index=False) # index=false to remove index column from html\n",
    "styled_html = f\"\"\"\n",
    "<style>\n",
    "  table {{width: 100%; border-collapse: collapse;}}\n",
    "  th, td {{border: 1px solid black; padding: 8px; text-align: left; word-wrap: break-word;}}\n",
    "  th, td:nth-child(1) {{width: 50px;}} /* Example: Fixed width for the first column */\n",
    "  th, td:nth-child(2) {{width: 150px;}} /* Example: Fixed width for the second column */\n",
    "  /* Add widths for other columns as needed */\n",
    "</style>\n",
    "{html}\n",
    "\"\"\"\n",
    "display(HTML(styled_html))\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65c7bf-7b42-4d24-bd08-8d9c235ddbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PrettySparkOutput\").getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, \"4962fdbE6Bfee6D\", \"Pam\", \"Sparks\", \"Patel-Deleon\", \"Blakemouth\", \"British Indian Ocean Territory (Chagos Archipelago)\", \"267-243-9490x035\", \"480-078-0535x889\", \"nicolas00@faulkner-kramer.com\", \"2020-11-29\", \"https://nelson.com/\", \"1000232,32\"),\n",
    "    (2, \"9b12Ae76fdBc9bE\", \"Gina\", \"Rocha\", \"Acosta, Paul and Barber\", \"East Lynnchester\", \"Costa Rica\", \"027.142.0940\", \"+1-752-593-4777x07171\", \"yfarley@morgan.com\", \"2021-01-03\", \"https://pineda-rogers.biz/\", \"1000232,32\"),\n",
    "    (3, \"39edFd2F60C85BC\", \"Kristie\", \"Greer\", \"Ochoa PLC\", \"West Pamela\", \"Ecuador\", \"+1-049-168-7497x5053\", \"+1-311-216-7855\", \"jennyhayden@p\", None, None, None)\n",
    "]\n",
    "\n",
    "columns = [\"Index\", \"Customer Id\", \"First Name\", \"Last Name\", \"Company\", \"City\", \"Country\", \"Phone 1\", \"Phone 2\", \"Email\", \"Subscription Date\", \"Website\", \"Budget\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "pandas_df = df.toPandas()\n",
    "pandas_df = pandas_df.fillna(\"\")\n",
    "\n",
    "print(pandas_df)  # Check Pandas DataFrame content\n",
    "\n",
    "HTML(\"<h1>Hello, World!</h1>\")  # Basic HTML test\n",
    "\n",
    "html = pandas_df.to_html(index=False)\n",
    "print(html) # check the html string.\n",
    "\n",
    "HTML(html)  # Try displaying basic HTML\n",
    "\n",
    "display(pandas_df) # test the display method.\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2741b03c-e852-41e7-b528-497ada850a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/bitnami/python/lib/python3.12/site-packages/pip-23.3.2-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Package(s) not found: py4j\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show py4j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
