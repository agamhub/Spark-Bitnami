+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
|    |  BatchName  |  DqcId   |                                  Scripts                                   | Run | RefTable | SP |
+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
| 8  | BATCH_RTNPF | DQ000001 |                      SELECT COUNT(1) CNT FROM RTRNPF                       |  1  |   nan    | 0  |
| 9  | BATCH_RTNPF | DQ000002 |  SELECT COUNT(1) CNT FROM RTRNPF WHERE YEAR(`Subscription Date`) = '2021'  |  1  |   nan    | 0  |
| 10 | BATCH_RTNPF | DQ000002 | SELECT SUM(CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2))) CNT FROM RTRNPF |  1  |   nan    | 0  |
+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
+---+-------------+---------+
|   |  BatchName  | JobName |
+---+-------------+---------+
| 0 | BATCH_RTNPF | RTRNPF  |
+---+-------------+---------+
25/04/14 15:41:05 INFO SparkContext: Running Spark version 3.5.4
25/04/14 15:41:05 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
25/04/14 15:41:05 INFO SparkContext: Java version 17.0.14
25/04/14 15:41:05 INFO ResourceUtils: ==============================================================
25/04/14 15:41:05 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/14 15:41:05 INFO ResourceUtils: ==============================================================
25/04/14 15:41:05 INFO SparkContext: Submitted application: BATCH_RTNPF_DQC
25/04/14 15:41:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 512, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/14 15:41:05 INFO ResourceProfile: Limiting resource is cpu
25/04/14 15:41:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/14 15:41:05 INFO SecurityManager: Changing view acls to: spark,root
25/04/14 15:41:05 INFO SecurityManager: Changing modify acls to: spark,root
25/04/14 15:41:05 INFO SecurityManager: Changing view acls groups to: 
25/04/14 15:41:05 INFO SecurityManager: Changing modify acls groups to: 
25/04/14 15:41:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, root; groups with view permissions: EMPTY; users with modify permissions: spark, root; groups with modify permissions: EMPTY
25/04/14 15:41:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/14 15:41:05 INFO Utils: Successfully started service 'sparkDriver' on port 40341.
25/04/14 15:41:05 INFO SparkEnv: Registering MapOutputTracker
25/04/14 15:41:05 INFO SparkEnv: Registering BlockManagerMaster
25/04/14 15:41:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/14 15:41:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/14 15:41:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/14 15:41:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c54fb0d7-2e72-4b98-a013-1222df8eb4fa
25/04/14 15:41:05 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/04/14 15:41:05 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/14 15:41:05 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/04/14 15:41:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/14 15:41:06 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/14 15:41:06 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 25 ms (0 ms spent in bootstraps)
25/04/14 15:41:06 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250414154106-0001
25/04/14 15:41:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250414154106-0001/0 on worker-20250414153918-172.20.0.8-37829 (172.20.0.8:37829) with 1 core(s)
25/04/14 15:41:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250414154106-0001/0 on hostPort 172.20.0.8:37829 with 1 core(s), 512.0 MiB RAM
25/04/14 15:41:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250414154106-0001/1 on worker-20250414153918-172.20.0.5-34419 (172.20.0.5:34419) with 1 core(s)
25/04/14 15:41:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250414154106-0001/1 on hostPort 172.20.0.5:34419 with 1 core(s), 512.0 MiB RAM
25/04/14 15:41:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250414154106-0001/2 on worker-20250414153918-172.20.0.7-43723 (172.20.0.7:43723) with 1 core(s)
25/04/14 15:41:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250414154106-0001/2 on hostPort 172.20.0.7:43723 with 1 core(s), 512.0 MiB RAM
25/04/14 15:41:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42009.
25/04/14 15:41:06 INFO NettyBlockTransferService: Server created on 2f7b624a4d29:42009
25/04/14 15:41:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/14 15:41:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 2f7b624a4d29, 42009, None)
25/04/14 15:41:06 INFO BlockManagerMasterEndpoint: Registering block manager 2f7b624a4d29:42009 with 1048.8 MiB RAM, BlockManagerId(driver, 2f7b624a4d29, 42009, None)
25/04/14 15:41:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 2f7b624a4d29, 42009, None)
25/04/14 15:41:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 2f7b624a4d29, 42009, None)
25/04/14 15:41:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250414154106-0001/0 is now RUNNING
25/04/14 15:41:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250414154106-0001/2 is now RUNNING
25/04/14 15:41:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250414154106-0001/1 is now RUNNING
25/04/14 15:41:06 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/14 15:41:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/04/14 15:41:07 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/04/14 15:41:09 INFO InMemoryFileIndex: It took 106 ms to list leaf files for 1 paths.
25/04/14 15:41:10 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.7:37842) with ID 2,  ResourceProfileId 0
25/04/14 15:41:10 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:47888) with ID 1,  ResourceProfileId 0
25/04/14 15:41:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.7:41411 with 127.2 MiB RAM, BlockManagerId(2, 172.20.0.7, 41411, None)
25/04/14 15:41:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:39233 with 127.2 MiB RAM, BlockManagerId(1, 172.20.0.5, 39233, None)
25/04/14 15:41:10 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.8:38098) with ID 0,  ResourceProfileId 0
25/04/14 15:41:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.8:33307 with 127.2 MiB RAM, BlockManagerId(0, 172.20.0.8, 33307, None)
25/04/14 15:41:10 INFO SparkContext: Starting job: sql at <unknown>:0
25/04/14 15:41:10 INFO DAGScheduler: Got job 0 (sql at <unknown>:0) with 1 output partitions
25/04/14 15:41:10 INFO DAGScheduler: Final stage: ResultStage 0 (sql at <unknown>:0)
25/04/14 15:41:10 INFO DAGScheduler: Parents of final stage: List()
25/04/14 15:41:10 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at sql at <unknown>:0), which has no missing parents
25/04/14 15:41:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.7 KiB, free 1048.7 MiB)
25/04/14 15:41:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 1048.7 MiB)
25/04/14 15:41:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 2f7b624a4d29:42009 (size: 37.4 KiB, free: 1048.8 MiB)
25/04/14 15:41:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/14 15:41:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.8, executor 0, partition 0, PROCESS_LOCAL, 9213 bytes) 
25/04/14 15:41:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.8:33307 (size: 37.4 KiB, free: 127.2 MiB)
25/04/14 15:41:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 773 ms on 172.20.0.8 (executor 0) (1/1)
25/04/14 15:41:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/14 15:41:11 INFO DAGScheduler: ResultStage 0 (sql at <unknown>:0) finished in 0.883 s
25/04/14 15:41:11 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/14 15:41:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/14 15:41:11 INFO DAGScheduler: Job 0 finished: sql at <unknown>:0, took 0.916215 s
25/04/14 15:41:12 INFO CodeGenerator: Code generated in 157.86679 ms
25/04/14 15:41:12 INFO CodeGenerator: Code generated in 10.685209 ms
25/04/14 15:41:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 2f7b624a4d29:42009 in memory (size: 37.4 KiB, free: 1048.8 MiB)
25/04/14 15:41:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.8:33307 in memory (size: 37.4 KiB, free: 127.2 MiB)
25/04/14 15:41:12 INFO InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
25/04/14 15:41:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/14 15:41:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/14 15:41:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/14 15:41:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/14 15:41:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(`Subscription Date`)
25/04/14 15:41:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Subscription Date#31),(year(Subscription Date#31) = 2021)
25/04/14 15:41:13 INFO CodeGenerator: Code generated in 34.251904 ms
25/04/14 15:41:13 INFO CodeGenerator: Code generated in 44.638767 ms
25/04/14 15:41:13 INFO CodeGenerator: Code generated in 39.761291 ms
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 201.6 KiB, free 1048.6 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 201.5 KiB, free 1048.2 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 201.6 KiB, free 1048.2 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 1048.1 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1048.1 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1048.1 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 2f7b624a4d29:42009 (size: 34.9 KiB, free: 1048.8 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 2f7b624a4d29:42009 (size: 35.0 KiB, free: 1048.7 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 2f7b624a4d29:42009 (size: 35.0 KiB, free: 1048.7 MiB)
25/04/14 15:41:13 INFO SparkContext: Created broadcast 1 from collect at /mnt/apps/jobs/SparkDataQuality.py:110
25/04/14 15:41:13 INFO SparkContext: Created broadcast 3 from collectToPython at <unknown>:0
25/04/14 15:41:13 INFO SparkContext: Created broadcast 2 from collectToPython at <unknown>:0
25/04/14 15:41:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/14 15:41:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/14 15:41:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/14 15:41:13 INFO DAGScheduler: Registering RDD 13 (collectToPython at <unknown>:0) as input to shuffle 0
25/04/14 15:41:13 INFO DAGScheduler: Got map stage job 2 (collectToPython at <unknown>:0) with 1 output partitions
25/04/14 15:41:13 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (collectToPython at <unknown>:0)
25/04/14 15:41:13 INFO DAGScheduler: Parents of final stage: List()
25/04/14 15:41:13 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:13 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at collectToPython at <unknown>:0), which has no missing parents
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 21.5 KiB, free 1048.1 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 1048.1 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 2f7b624a4d29:42009 (size: 9.3 KiB, free: 1048.7 MiB)
25/04/14 15:41:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/14 15:41:13 INFO DAGScheduler: Registering RDD 11 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) as input to shuffle 1
25/04/14 15:41:13 INFO DAGScheduler: Got map stage job 3 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) with 1 output partitions
25/04/14 15:41:13 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (collect at /mnt/apps/jobs/SparkDataQuality.py:110)
25/04/14 15:41:13 INFO DAGScheduler: Parents of final stage: List()
25/04/14 15:41:13 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:13 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at collect at /mnt/apps/jobs/SparkDataQuality.py:110), which has no missing parents
25/04/14 15:41:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.8, executor 0, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 17.0 KiB, free 1048.1 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.1 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 2f7b624a4d29:42009 (size: 7.8 KiB, free: 1048.7 MiB)
25/04/14 15:41:13 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at collect at /mnt/apps/jobs/SparkDataQuality.py:110) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/14 15:41:13 INFO DAGScheduler: Registering RDD 12 (collectToPython at <unknown>:0) as input to shuffle 2
25/04/14 15:41:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/14 15:41:13 INFO DAGScheduler: Got map stage job 1 (collectToPython at <unknown>:0) with 1 output partitions
25/04/14 15:41:13 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collectToPython at <unknown>:0)
25/04/14 15:41:13 INFO DAGScheduler: Parents of final stage: List()
25/04/14 15:41:13 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:13 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[12] at collectToPython at <unknown>:0), which has no missing parents
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 18.6 KiB, free 1048.0 MiB)
25/04/14 15:41:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1048.0 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 2f7b624a4d29:42009 (size: 8.3 KiB, free: 1048.7 MiB)
25/04/14 15:41:13 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[12] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/14 15:41:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.7, executor 2, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.8:33307 (size: 9.3 KiB, free: 127.2 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:39233 (size: 7.8 KiB, free: 127.2 MiB)
25/04/14 15:41:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.7:41411 (size: 8.3 KiB, free: 127.2 MiB)
25/04/14 15:41:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.8:33307 (size: 35.0 KiB, free: 127.2 MiB)
25/04/14 15:41:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.5:39233 (size: 34.9 KiB, free: 127.2 MiB)
25/04/14 15:41:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.7:41411 (size: 35.0 KiB, free: 127.2 MiB)
25/04/14 15:41:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1317 ms on 172.20.0.8 (executor 0) (1/1)
25/04/14 15:41:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/14 15:41:14 INFO DAGScheduler: ShuffleMapStage 1 (collectToPython at <unknown>:0) finished in 1.363 s
25/04/14 15:41:14 INFO DAGScheduler: looking for newly runnable stages
25/04/14 15:41:14 INFO DAGScheduler: running: Set(ShuffleMapStage 2, ShuffleMapStage 3)
25/04/14 15:41:14 INFO DAGScheduler: waiting: Set()
25/04/14 15:41:14 INFO DAGScheduler: failed: Set()
25/04/14 15:41:14 INFO CodeGenerator: Code generated in 19.142813 ms
25/04/14 15:41:14 INFO SparkContext: Starting job: collectToPython at <unknown>:0
25/04/14 15:41:14 INFO DAGScheduler: Got job 4 (collectToPython at <unknown>:0) with 1 output partitions
25/04/14 15:41:14 INFO DAGScheduler: Final stage: ResultStage 5 (collectToPython at <unknown>:0)
25/04/14 15:41:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/14 15:41:14 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:14 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at collectToPython at <unknown>:0), which has no missing parents
25/04/14 15:41:14 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.9 KiB, free 1048.0 MiB)
25/04/14 15:41:14 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 1048.0 MiB)
25/04/14 15:41:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 2f7b624a4d29:42009 (size: 6.8 KiB, free: 1048.7 MiB)
25/04/14 15:41:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 2f7b624a4d29:42009 in memory (size: 9.3 KiB, free: 1048.7 MiB)
25/04/14 15:41:14 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:14 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/14 15:41:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.8:33307 in memory (size: 9.3 KiB, free: 127.2 MiB)
25/04/14 15:41:14 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.20.0.8, executor 0, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/14 15:41:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.8:33307 (size: 6.8 KiB, free: 127.2 MiB)
25/04/14 15:41:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.8:38098
25/04/14 15:41:15 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 205 ms on 172.20.0.8 (executor 0) (1/1)
25/04/14 15:41:15 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/14 15:41:15 INFO DAGScheduler: ResultStage 5 (collectToPython at <unknown>:0) finished in 0.242 s
25/04/14 15:41:15 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/14 15:41:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/14 15:41:15 INFO DAGScheduler: Job 4 finished: collectToPython at <unknown>:0, took 0.260262 s
2025-04-14 15:41:15,095 - INFO - Closing down clientserver connection
25/04/14 15:41:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1892 ms on 172.20.0.5 (executor 1) (1/1)
25/04/14 15:41:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/14 15:41:15 INFO DAGScheduler: ShuffleMapStage 2 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) finished in 1.909 s
25/04/14 15:41:15 INFO DAGScheduler: looking for newly runnable stages
25/04/14 15:41:15 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
25/04/14 15:41:15 INFO DAGScheduler: waiting: Set()
25/04/14 15:41:15 INFO DAGScheduler: failed: Set()
25/04/14 15:41:15 INFO CodeGenerator: Code generated in 22.567937 ms
25/04/14 15:41:15 INFO SparkContext: Starting job: collect at /mnt/apps/jobs/SparkDataQuality.py:110
25/04/14 15:41:15 INFO DAGScheduler: Got job 5 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) with 1 output partitions
25/04/14 15:41:15 INFO DAGScheduler: Final stage: ResultStage 7 (collect at /mnt/apps/jobs/SparkDataQuality.py:110)
25/04/14 15:41:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/14 15:41:15 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:15 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[19] at collect at /mnt/apps/jobs/SparkDataQuality.py:110), which has no missing parents
25/04/14 15:41:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.5 KiB, free 1048.0 MiB)
25/04/14 15:41:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.0 MiB)
25/04/14 15:41:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 2f7b624a4d29:42009 (size: 5.9 KiB, free: 1048.7 MiB)
25/04/14 15:41:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[19] at collect at /mnt/apps/jobs/SparkDataQuality.py:110) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:15 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/14 15:41:15 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/14 15:41:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.5:39233 (size: 5.9 KiB, free: 127.2 MiB)
25/04/14 15:41:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.5:47888
25/04/14 15:41:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 2169 ms on 172.20.0.7 (executor 2) (1/1)
25/04/14 15:41:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/14 15:41:15 INFO DAGScheduler: ShuffleMapStage 3 (collectToPython at <unknown>:0) finished in 2.187 s
25/04/14 15:41:15 INFO DAGScheduler: looking for newly runnable stages
25/04/14 15:41:15 INFO DAGScheduler: running: Set(ResultStage 7)
25/04/14 15:41:15 INFO DAGScheduler: waiting: Set()
25/04/14 15:41:15 INFO DAGScheduler: failed: Set()
25/04/14 15:41:15 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 240 ms on 172.20.0.5 (executor 1) (1/1)
25/04/14 15:41:15 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/14 15:41:15 INFO DAGScheduler: ResultStage 7 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) finished in 0.258 s
25/04/14 15:41:15 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/14 15:41:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/14 15:41:15 INFO DAGScheduler: Job 5 finished: collect at /mnt/apps/jobs/SparkDataQuality.py:110, took 0.266039 s
25/04/14 15:41:15 INFO SparkContext: Starting job: collectToPython at <unknown>:0
25/04/14 15:41:15 INFO DAGScheduler: Got job 6 (collectToPython at <unknown>:0) with 1 output partitions
25/04/14 15:41:15 INFO DAGScheduler: Final stage: ResultStage 9 (collectToPython at <unknown>:0)
25/04/14 15:41:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/14 15:41:15 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:15 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at collectToPython at <unknown>:0), which has no missing parents
2025-04-14 15:41:15,664 - INFO - Closing down clientserver connection
25/04/14 15:41:15 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.5 KiB, free 1048.0 MiB)
25/04/14 15:41:15 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.0 MiB)
25/04/14 15:41:15 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 2f7b624a4d29:42009 (size: 5.9 KiB, free: 1048.7 MiB)
25/04/14 15:41:15 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:15 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/14 15:41:15 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.20.0.7, executor 2, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/14 15:41:15 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.7:41411 (size: 5.9 KiB, free: 127.2 MiB)
25/04/14 15:41:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.7:37842
25/04/14 15:41:15 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 190 ms on 172.20.0.7 (executor 2) (1/1)
25/04/14 15:41:15 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/14 15:41:15 INFO DAGScheduler: ResultStage 9 (collectToPython at <unknown>:0) finished in 0.202 s
25/04/14 15:41:15 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/14 15:41:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/14 15:41:15 INFO DAGScheduler: Job 6 finished: collectToPython at <unknown>:0, took 0.209285 s
2025-04-14 15:41:15,875 - INFO - Closing down clientserver connection
25/04/14 15:41:16 INFO CodeGenerator: Code generated in 17.695526 ms
25/04/14 15:41:16 INFO SparkContext: Starting job: showString at <unknown>:0
25/04/14 15:41:16 INFO DAGScheduler: Got job 7 (showString at <unknown>:0) with 1 output partitions
25/04/14 15:41:16 INFO DAGScheduler: Final stage: ResultStage 10 (showString at <unknown>:0)
25/04/14 15:41:16 INFO DAGScheduler: Parents of final stage: List()
25/04/14 15:41:16 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:16 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[29] at showString at <unknown>:0), which has no missing parents
25/04/14 15:41:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 16.2 KiB, free 1048.0 MiB)
25/04/14 15:41:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.0 MiB)
25/04/14 15:41:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 2f7b624a4d29:42009 (size: 7.8 KiB, free: 1048.7 MiB)
25/04/14 15:41:16 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[29] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/14 15:41:16 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/14 15:41:16 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (172.20.0.8, executor 0, partition 0, PROCESS_LOCAL, 9171 bytes) 
25/04/14 15:41:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.8:33307 (size: 7.8 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 933 ms on 172.20.0.8 (executor 0) (1/1)
25/04/14 15:41:17 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/14 15:41:17 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 49337
25/04/14 15:41:17 INFO DAGScheduler: ResultStage 10 (showString at <unknown>:0) finished in 0.958 s
25/04/14 15:41:17 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/14 15:41:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/14 15:41:17 INFO DAGScheduler: Job 7 finished: showString at <unknown>:0, took 0.963418 s
25/04/14 15:41:17 INFO SparkContext: Starting job: showString at <unknown>:0
25/04/14 15:41:17 INFO DAGScheduler: Got job 8 (showString at <unknown>:0) with 2 output partitions
25/04/14 15:41:17 INFO DAGScheduler: Final stage: ResultStage 11 (showString at <unknown>:0)
25/04/14 15:41:17 INFO DAGScheduler: Parents of final stage: List()
25/04/14 15:41:17 INFO DAGScheduler: Missing parents: List()
25/04/14 15:41:17 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[29] at showString at <unknown>:0), which has no missing parents
25/04/14 15:41:17 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 16.2 KiB, free 1048.0 MiB)
25/04/14 15:41:17 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.0 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 2f7b624a4d29:42009 (size: 7.8 KiB, free: 1048.6 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 2f7b624a4d29:42009 in memory (size: 5.9 KiB, free: 1048.7 MiB)
25/04/14 15:41:17 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/04/14 15:41:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[29] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1, 2))
25/04/14 15:41:17 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks resource profile 0
25/04/14 15:41:17 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 9119 bytes) 
25/04/14 15:41:17 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 9) (172.20.0.8, executor 0, partition 2, PROCESS_LOCAL, 9159 bytes) 
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.5:39233 in memory (size: 5.9 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 2f7b624a4d29:42009 in memory (size: 7.8 KiB, free: 1048.7 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.0.8:33307 in memory (size: 7.8 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:39233 (size: 7.8 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.8:33307 (size: 7.8 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 2f7b624a4d29:42009 in memory (size: 8.3 KiB, free: 1048.7 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.7:41411 in memory (size: 8.3 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 2f7b624a4d29:42009 in memory (size: 7.8 KiB, free: 1048.7 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:39233 in memory (size: 7.8 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 2f7b624a4d29:42009 in memory (size: 5.9 KiB, free: 1048.7 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.7:41411 in memory (size: 5.9 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 2f7b624a4d29:42009 in memory (size: 6.8 KiB, free: 1048.7 MiB)
25/04/14 15:41:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.8:33307 in memory (size: 6.8 KiB, free: 127.2 MiB)
25/04/14 15:41:17 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 9) in 147 ms on 172.20.0.8 (executor 0) (1/2)
25/04/14 15:41:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 996 ms on 172.20.0.5 (executor 1) (2/2)
25/04/14 15:41:18 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/14 15:41:18 INFO DAGScheduler: ResultStage 11 (showString at <unknown>:0) finished in 1.016 s
25/04/14 15:41:18 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/14 15:41:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/14 15:41:18 INFO DAGScheduler: Job 8 finished: showString at <unknown>:0, took 1.019336 s
25/04/14 15:41:18 INFO CodeGenerator: Code generated in 11.781365 ms
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+
|BatchName  |DqcId   |StartTime                 |EndTime                   |Duration    |Scripts                                                                   |Run|Result     |Status|
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+
|BATCH_RTNPF|DQ000002|2025-04-14 15:41:12.606105|2025-04-14 15:41:12.917101|0.31 seconds|SELECT SUM(CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2))) CNT FROM RTRNPF|1  |18004181.76|Failed|
|BATCH_RTNPF|DQ000001|2025-04-14 15:41:12.605035|2025-04-14 15:41:12.894461|0.29 seconds|SELECT COUNT(1) CNT FROM RTRNPF                                           |1  |18         |Failed|
|BATCH_RTNPF|DQ000002|2025-04-14 15:41:12.605295|2025-04-14 15:41:12.925281|0.32 seconds|SELECT COUNT(1) CNT FROM RTRNPF WHERE YEAR(`Subscription Date`) = '2021'  |1  |7          |Failed|
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+

2025-04-14 15:41:18,076 - INFO - None
25/04/14 15:41:18 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/04/14 15:41:18 INFO SparkUI: Stopped Spark web UI at http://2f7b624a4d29:4040
25/04/14 15:41:18 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/14 15:41:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/04/14 15:41:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/14 15:41:18 INFO MemoryStore: MemoryStore cleared
25/04/14 15:41:18 INFO BlockManager: BlockManager stopped
25/04/14 15:41:18 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/14 15:41:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/14 15:41:18 INFO SparkContext: Successfully stopped SparkContext
2025-04-14 15:41:19,053 - INFO - Closing down clientserver connection
25/04/14 15:41:19 INFO ShutdownHookManager: Shutdown hook called
25/04/14 15:41:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-06f9ed9f-0fc0-4e1a-b994-68c6a956e4e7/pyspark-a33dd0df-af5f-424b-889f-5b969bb546ea
25/04/14 15:41:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-c6aa075d-5bcb-4d3f-af9f-5b477f855781
25/04/14 15:41:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-06f9ed9f-0fc0-4e1a-b994-68c6a956e4e7
Mon Apr 14 15:41:19 UTC 2025 - BASH - Spark job 'BATCH_RTNPF' completed
