+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
|    |  BatchName  |  DqcId   |                                  Scripts                                   | Run | RefTable | SP |
+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
| 8  | BATCH_RTNPF | DQ000001 |                      SELECT COUNT(1) CNT FROM RTRNPF                       |  1  |   nan    | 0  |
| 9  | BATCH_RTNPF | DQ000002 |  SELECT COUNT(1) CNT FROM RTRNPF WHERE YEAR(`Subscription Date`) = '2021'  |  1  |   nan    | 0  |
| 10 | BATCH_RTNPF | DQ000002 | SELECT SUM(CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2))) CNT FROM RTRNPF |  1  |   nan    | 0  |
+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
+---+-------------+---------+
|   |  BatchName  | JobName |
+---+-------------+---------+
| 0 | BATCH_RTNPF | RTRNPF  |
+---+-------------+---------+
25/04/05 01:04:13 INFO SparkContext: Running Spark version 3.5.4
25/04/05 01:04:13 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
25/04/05 01:04:13 INFO SparkContext: Java version 17.0.14
25/04/05 01:04:13 INFO ResourceUtils: ==============================================================
25/04/05 01:04:13 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/05 01:04:13 INFO ResourceUtils: ==============================================================
25/04/05 01:04:13 INFO SparkContext: Submitted application: BATCH_RTNPF_DQC
25/04/05 01:04:13 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 512, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/05 01:04:13 INFO ResourceProfile: Limiting resource is cpu
25/04/05 01:04:13 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/05 01:04:13 INFO SecurityManager: Changing view acls to: spark,root
25/04/05 01:04:13 INFO SecurityManager: Changing modify acls to: spark,root
25/04/05 01:04:13 INFO SecurityManager: Changing view acls groups to: 
25/04/05 01:04:13 INFO SecurityManager: Changing modify acls groups to: 
25/04/05 01:04:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, root; groups with view permissions: EMPTY; users with modify permissions: spark, root; groups with modify permissions: EMPTY
25/04/05 01:04:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/05 01:04:13 INFO Utils: Successfully started service 'sparkDriver' on port 45823.
25/04/05 01:04:13 INFO SparkEnv: Registering MapOutputTracker
25/04/05 01:04:13 INFO SparkEnv: Registering BlockManagerMaster
25/04/05 01:04:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/05 01:04:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/05 01:04:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/05 01:04:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5031fda2-d1f6-426d-b8bd-dda1c0189680
25/04/05 01:04:14 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/04/05 01:04:14 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/05 01:04:14 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/04/05 01:04:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/05 01:04:14 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/05 01:04:14 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/05 01:04:14 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.2:7077 after 24 ms (0 ms spent in bootstraps)
25/04/05 01:04:14 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250405010414-0002
25/04/05 01:04:14 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250405010414-0002/0 on worker-20250405010102-172.19.0.8-37855 (172.19.0.8:37855) with 1 core(s)
25/04/05 01:04:14 INFO StandaloneSchedulerBackend: Granted executor ID app-20250405010414-0002/0 on hostPort 172.19.0.8:37855 with 1 core(s), 512.0 MiB RAM
25/04/05 01:04:14 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250405010414-0002/1 on worker-20250405010059-172.19.0.4-43489 (172.19.0.4:43489) with 1 core(s)
25/04/05 01:04:14 INFO StandaloneSchedulerBackend: Granted executor ID app-20250405010414-0002/1 on hostPort 172.19.0.4:43489 with 1 core(s), 512.0 MiB RAM
25/04/05 01:04:14 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250405010414-0002/2 on worker-20250405010102-172.19.0.7-39135 (172.19.0.7:39135) with 1 core(s)
25/04/05 01:04:14 INFO StandaloneSchedulerBackend: Granted executor ID app-20250405010414-0002/2 on hostPort 172.19.0.7:39135 with 1 core(s), 512.0 MiB RAM
25/04/05 01:04:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37775.
25/04/05 01:04:14 INFO NettyBlockTransferService: Server created on 265a8904746d:37775
25/04/05 01:04:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/05 01:04:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 265a8904746d, 37775, None)
25/04/05 01:04:14 INFO BlockManagerMasterEndpoint: Registering block manager 265a8904746d:37775 with 1048.8 MiB RAM, BlockManagerId(driver, 265a8904746d, 37775, None)
25/04/05 01:04:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 265a8904746d, 37775, None)
25/04/05 01:04:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 265a8904746d, 37775, None)
25/04/05 01:04:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250405010414-0002/0 is now RUNNING
25/04/05 01:04:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250405010414-0002/1 is now RUNNING
25/04/05 01:04:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250405010414-0002/2 is now RUNNING
25/04/05 01:04:14 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/05 01:04:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/04/05 01:04:15 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/04/05 01:04:17 INFO InMemoryFileIndex: It took 105 ms to list leaf files for 1 paths.
25/04/05 01:04:18 INFO SparkContext: Starting job: sql at <unknown>:0
25/04/05 01:04:18 INFO DAGScheduler: Got job 0 (sql at <unknown>:0) with 1 output partitions
25/04/05 01:04:18 INFO DAGScheduler: Final stage: ResultStage 0 (sql at <unknown>:0)
25/04/05 01:04:18 INFO DAGScheduler: Parents of final stage: List()
25/04/05 01:04:18 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at sql at <unknown>:0), which has no missing parents
25/04/05 01:04:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.7 KiB, free 1048.7 MiB)
25/04/05 01:04:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 1048.7 MiB)
25/04/05 01:04:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 265a8904746d:37775 (size: 37.4 KiB, free: 1048.8 MiB)
25/04/05 01:04:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/05 01:04:20 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.8:57362) with ID 0,  ResourceProfileId 0
25/04/05 01:04:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.8:44857 with 127.2 MiB RAM, BlockManagerId(0, 172.19.0.8, 44857, None)
25/04/05 01:04:20 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.4:44198) with ID 1,  ResourceProfileId 0
25/04/05 01:04:20 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.7:35180) with ID 2,  ResourceProfileId 0
25/04/05 01:04:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.4:45103 with 127.2 MiB RAM, BlockManagerId(1, 172.19.0.4, 45103, None)
25/04/05 01:04:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.19.0.8, executor 0, partition 0, PROCESS_LOCAL, 9213 bytes) 
25/04/05 01:04:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.7:39501 with 127.2 MiB RAM, BlockManagerId(2, 172.19.0.7, 39501, None)
25/04/05 01:04:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.19.0.8:44857 (size: 37.4 KiB, free: 127.2 MiB)
25/04/05 01:04:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1289 ms on 172.19.0.8 (executor 0) (1/1)
25/04/05 01:04:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/05 01:04:22 INFO DAGScheduler: ResultStage 0 (sql at <unknown>:0) finished in 3.286 s
25/04/05 01:04:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 01:04:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/05 01:04:22 INFO DAGScheduler: Job 0 finished: sql at <unknown>:0, took 3.403815 s
25/04/05 01:04:23 INFO CodeGenerator: Code generated in 235.10408 ms
25/04/05 01:04:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 265a8904746d:37775 in memory (size: 37.4 KiB, free: 1048.8 MiB)
25/04/05 01:04:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.19.0.8:44857 in memory (size: 37.4 KiB, free: 127.2 MiB)
25/04/05 01:04:23 INFO CodeGenerator: Code generated in 17.497673 ms
25/04/05 01:04:24 INFO InMemoryFileIndex: It took 28 ms to list leaf files for 1 paths.
25/04/05 01:04:24 INFO FileSourceStrategy: Pushed Filters: 
25/04/05 01:04:24 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/05 01:04:24 INFO FileSourceStrategy: Pushed Filters: 
25/04/05 01:04:24 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/05 01:04:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(`Subscription Date`)
25/04/05 01:04:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Subscription Date#31),(year(Subscription Date#31) = 2021)
25/04/05 01:04:24 INFO CodeGenerator: Code generated in 48.786809 ms
25/04/05 01:04:24 INFO CodeGenerator: Code generated in 47.305444 ms
25/04/05 01:04:24 INFO CodeGenerator: Code generated in 55.302517 ms
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 201.6 KiB, free 1048.6 MiB)
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 201.6 KiB, free 1048.4 MiB)
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 201.5 KiB, free 1048.2 MiB)
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1048.2 MiB)
25/04/05 01:04:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 265a8904746d:37775 (size: 35.0 KiB, free: 1048.8 MiB)
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1048.1 MiB)
25/04/05 01:04:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 265a8904746d:37775 (size: 35.0 KiB, free: 1048.7 MiB)
25/04/05 01:04:24 INFO SparkContext: Created broadcast 3 from collectToPython at <unknown>:0
25/04/05 01:04:24 INFO SparkContext: Created broadcast 1 from collectToPython at <unknown>:0
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 1048.1 MiB)
25/04/05 01:04:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 265a8904746d:37775 (size: 34.9 KiB, free: 1048.7 MiB)
25/04/05 01:04:24 INFO SparkContext: Created broadcast 2 from collect at /mnt/apps/jobs/SparkDataQuality.py:110
25/04/05 01:04:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/05 01:04:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/05 01:04:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/05 01:04:24 INFO DAGScheduler: Registering RDD 12 (collectToPython at <unknown>:0) as input to shuffle 2
25/04/05 01:04:24 INFO DAGScheduler: Got map stage job 1 (collectToPython at <unknown>:0) with 1 output partitions
25/04/05 01:04:24 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (collectToPython at <unknown>:0)
25/04/05 01:04:24 INFO DAGScheduler: Parents of final stage: List()
25/04/05 01:04:24 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at collectToPython at <unknown>:0), which has no missing parents
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 21.4 KiB, free 1048.1 MiB)
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 1048.1 MiB)
25/04/05 01:04:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 265a8904746d:37775 (size: 9.3 KiB, free: 1048.7 MiB)
25/04/05 01:04:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/05 01:04:24 INFO DAGScheduler: Registering RDD 11 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) as input to shuffle 1
25/04/05 01:04:24 INFO DAGScheduler: Got map stage job 2 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) with 1 output partitions
25/04/05 01:04:24 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (collect at /mnt/apps/jobs/SparkDataQuality.py:110)
25/04/05 01:04:24 INFO DAGScheduler: Parents of final stage: List()
25/04/05 01:04:24 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:24 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at collect at /mnt/apps/jobs/SparkDataQuality.py:110), which has no missing parents
25/04/05 01:04:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.19.0.4, executor 1, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 17.0 KiB, free 1048.1 MiB)
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.1 MiB)
25/04/05 01:04:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 265a8904746d:37775 (size: 7.8 KiB, free: 1048.7 MiB)
25/04/05 01:04:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at collect at /mnt/apps/jobs/SparkDataQuality.py:110) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/05 01:04:24 INFO DAGScheduler: Registering RDD 13 (collectToPython at <unknown>:0) as input to shuffle 0
25/04/05 01:04:24 INFO DAGScheduler: Got map stage job 3 (collectToPython at <unknown>:0) with 1 output partitions
25/04/05 01:04:24 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collectToPython at <unknown>:0)
25/04/05 01:04:24 INFO DAGScheduler: Parents of final stage: List()
25/04/05 01:04:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.19.0.7, executor 2, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/05 01:04:24 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:24 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at collectToPython at <unknown>:0), which has no missing parents
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 18.6 KiB, free 1048.0 MiB)
25/04/05 01:04:24 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1048.0 MiB)
25/04/05 01:04:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 265a8904746d:37775 (size: 8.3 KiB, free: 1048.7 MiB)
25/04/05 01:04:24 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/05 01:04:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.19.0.8, executor 0, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/05 01:04:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.19.0.8:44857 (size: 8.3 KiB, free: 127.2 MiB)
25/04/05 01:04:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.19.0.4:45103 (size: 9.3 KiB, free: 127.2 MiB)
25/04/05 01:04:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.19.0.7:39501 (size: 7.8 KiB, free: 127.2 MiB)
25/04/05 01:04:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.19.0.8:44857 (size: 35.0 KiB, free: 127.2 MiB)
25/04/05 01:04:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.19.0.4:45103 (size: 35.0 KiB, free: 127.2 MiB)
25/04/05 01:04:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.19.0.7:39501 (size: 34.9 KiB, free: 127.2 MiB)
25/04/05 01:04:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1672 ms on 172.19.0.8 (executor 0) (1/1)
25/04/05 01:04:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/05 01:04:26 INFO DAGScheduler: ShuffleMapStage 3 (collectToPython at <unknown>:0) finished in 1.697 s
25/04/05 01:04:26 INFO DAGScheduler: looking for newly runnable stages
25/04/05 01:04:26 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 2)
25/04/05 01:04:26 INFO DAGScheduler: waiting: Set()
25/04/05 01:04:26 INFO DAGScheduler: failed: Set()
25/04/05 01:04:26 INFO CodeGenerator: Code generated in 19.105736 ms
25/04/05 01:04:26 INFO SparkContext: Starting job: collectToPython at <unknown>:0
25/04/05 01:04:26 INFO DAGScheduler: Got job 4 (collectToPython at <unknown>:0) with 1 output partitions
25/04/05 01:04:26 INFO DAGScheduler: Final stage: ResultStage 5 (collectToPython at <unknown>:0)
25/04/05 01:04:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/05 01:04:26 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:26 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at collectToPython at <unknown>:0), which has no missing parents
25/04/05 01:04:26 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.5 KiB, free 1048.0 MiB)
25/04/05 01:04:26 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 265a8904746d:37775 in memory (size: 8.3 KiB, free: 1048.7 MiB)
25/04/05 01:04:26 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.0 MiB)
25/04/05 01:04:26 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.19.0.8:44857 in memory (size: 8.3 KiB, free: 127.2 MiB)
25/04/05 01:04:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 265a8904746d:37775 (size: 5.9 KiB, free: 1048.7 MiB)
25/04/05 01:04:26 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:26 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/05 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.19.0.8, executor 0, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/05 01:04:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.19.0.8:44857 (size: 5.9 KiB, free: 127.2 MiB)
25/04/05 01:04:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.19.0.8:57362
25/04/05 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 440 ms on 172.19.0.8 (executor 0) (1/1)
25/04/05 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/05 01:04:27 INFO DAGScheduler: ResultStage 5 (collectToPython at <unknown>:0) finished in 0.541 s
25/04/05 01:04:27 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 01:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/05 01:04:27 INFO DAGScheduler: Job 4 finished: collectToPython at <unknown>:0, took 0.574158 s
2025-04-05 01:04:27,377 - INFO - Closing down clientserver connection
25/04/05 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2605 ms on 172.19.0.7 (executor 2) (1/1)
25/04/05 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/05 01:04:27 INFO DAGScheduler: ShuffleMapStage 2 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) finished in 2.632 s
25/04/05 01:04:27 INFO DAGScheduler: looking for newly runnable stages
25/04/05 01:04:27 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
25/04/05 01:04:27 INFO DAGScheduler: waiting: Set()
25/04/05 01:04:27 INFO DAGScheduler: failed: Set()
25/04/05 01:04:27 INFO SparkContext: Starting job: collect at /mnt/apps/jobs/SparkDataQuality.py:110
25/04/05 01:04:27 INFO DAGScheduler: Got job 5 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) with 1 output partitions
25/04/05 01:04:27 INFO DAGScheduler: Final stage: ResultStage 7 (collect at /mnt/apps/jobs/SparkDataQuality.py:110)
25/04/05 01:04:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/05 01:04:27 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:27 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[19] at collect at /mnt/apps/jobs/SparkDataQuality.py:110), which has no missing parents
25/04/05 01:04:27 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.5 KiB, free 1048.0 MiB)
25/04/05 01:04:27 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.0 MiB)
25/04/05 01:04:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 265a8904746d:37775 (size: 5.9 KiB, free: 1048.7 MiB)
25/04/05 01:04:27 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[19] at collect at /mnt/apps/jobs/SparkDataQuality.py:110) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:27 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/05 01:04:27 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.19.0.7, executor 2, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/05 01:04:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.19.0.7:39501 (size: 5.9 KiB, free: 127.2 MiB)
25/04/05 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2957 ms on 172.19.0.4 (executor 1) (1/1)
25/04/05 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/05 01:04:27 INFO DAGScheduler: ShuffleMapStage 1 (collectToPython at <unknown>:0) finished in 3.043 s
25/04/05 01:04:27 INFO DAGScheduler: looking for newly runnable stages
25/04/05 01:04:27 INFO DAGScheduler: running: Set(ResultStage 7)
25/04/05 01:04:27 INFO DAGScheduler: waiting: Set()
25/04/05 01:04:27 INFO DAGScheduler: failed: Set()
25/04/05 01:04:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.19.0.7:35180
25/04/05 01:04:27 INFO CodeGenerator: Code generated in 30.458742 ms
25/04/05 01:04:27 INFO SparkContext: Starting job: collectToPython at <unknown>:0
25/04/05 01:04:27 INFO DAGScheduler: Got job 6 (collectToPython at <unknown>:0) with 1 output partitions
25/04/05 01:04:27 INFO DAGScheduler: Final stage: ResultStage 9 (collectToPython at <unknown>:0)
25/04/05 01:04:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/05 01:04:27 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:27 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at collectToPython at <unknown>:0), which has no missing parents
25/04/05 01:04:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 14.9 KiB, free 1048.0 MiB)
25/04/05 01:04:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 1048.0 MiB)
25/04/05 01:04:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 265a8904746d:37775 (size: 6.8 KiB, free: 1048.7 MiB)
25/04/05 01:04:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:28 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/05 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.19.0.4, executor 1, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/05 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 368 ms on 172.19.0.7 (executor 2) (1/1)
25/04/05 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/05 01:04:28 INFO DAGScheduler: ResultStage 7 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) finished in 0.400 s
25/04/05 01:04:28 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/05 01:04:28 INFO DAGScheduler: Job 5 finished: collect at /mnt/apps/jobs/SparkDataQuality.py:110, took 0.413348 s
25/04/05 01:04:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.19.0.4:45103 (size: 6.8 KiB, free: 127.2 MiB)
2025-04-05 01:04:28,090 - INFO - Closing down clientserver connection
25/04/05 01:04:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.19.0.4:44198
25/04/05 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 275 ms on 172.19.0.4 (executor 1) (1/1)
25/04/05 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/05 01:04:28 INFO DAGScheduler: ResultStage 9 (collectToPython at <unknown>:0) finished in 0.295 s
25/04/05 01:04:28 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/05 01:04:28 INFO DAGScheduler: Job 6 finished: collectToPython at <unknown>:0, took 0.303280 s
2025-04-05 01:04:28,304 - INFO - Closing down clientserver connection
25/04/05 01:04:28 INFO CodeGenerator: Code generated in 19.690911 ms
25/04/05 01:04:28 INFO SparkContext: Starting job: showString at <unknown>:0
25/04/05 01:04:28 INFO DAGScheduler: Got job 7 (showString at <unknown>:0) with 1 output partitions
25/04/05 01:04:28 INFO DAGScheduler: Final stage: ResultStage 10 (showString at <unknown>:0)
25/04/05 01:04:28 INFO DAGScheduler: Parents of final stage: List()
25/04/05 01:04:28 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:28 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[29] at showString at <unknown>:0), which has no missing parents
25/04/05 01:04:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 16.2 KiB, free 1048.0 MiB)
25/04/05 01:04:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.0 MiB)
25/04/05 01:04:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 265a8904746d:37775 (size: 7.8 KiB, free: 1048.7 MiB)
25/04/05 01:04:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[29] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/05 01:04:28 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/05 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (172.19.0.7, executor 2, partition 0, PROCESS_LOCAL, 9159 bytes) 
25/04/05 01:04:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.19.0.7:39501 (size: 7.8 KiB, free: 127.1 MiB)
25/04/05 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 1898 ms on 172.19.0.7 (executor 2) (1/1)
25/04/05 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/05 01:04:30 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 44461
25/04/05 01:04:30 INFO DAGScheduler: ResultStage 10 (showString at <unknown>:0) finished in 1.923 s
25/04/05 01:04:30 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/05 01:04:30 INFO DAGScheduler: Job 7 finished: showString at <unknown>:0, took 1.931133 s
25/04/05 01:04:30 INFO SparkContext: Starting job: showString at <unknown>:0
25/04/05 01:04:30 INFO DAGScheduler: Got job 8 (showString at <unknown>:0) with 2 output partitions
25/04/05 01:04:30 INFO DAGScheduler: Final stage: ResultStage 11 (showString at <unknown>:0)
25/04/05 01:04:30 INFO DAGScheduler: Parents of final stage: List()
25/04/05 01:04:30 INFO DAGScheduler: Missing parents: List()
25/04/05 01:04:30 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[29] at showString at <unknown>:0), which has no missing parents
25/04/05 01:04:30 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 16.2 KiB, free 1048.0 MiB)
25/04/05 01:04:30 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1047.9 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 265a8904746d:37775 (size: 7.8 KiB, free: 1048.6 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 265a8904746d:37775 in memory (size: 5.9 KiB, free: 1048.7 MiB)
25/04/05 01:04:30 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/04/05 01:04:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[29] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1, 2))
25/04/05 01:04:30 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks resource profile 0
25/04/05 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8) (172.19.0.8, executor 0, partition 1, PROCESS_LOCAL, 9119 bytes) 
25/04/05 01:04:30 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 9) (172.19.0.4, executor 1, partition 2, PROCESS_LOCAL, 9171 bytes) 
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.19.0.7:39501 in memory (size: 5.9 KiB, free: 127.2 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 265a8904746d:37775 in memory (size: 5.9 KiB, free: 1048.7 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.19.0.8:44857 in memory (size: 5.9 KiB, free: 127.2 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.19.0.4:45103 (size: 7.8 KiB, free: 127.1 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.19.0.8:44857 (size: 7.8 KiB, free: 127.2 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.19.0.4:45103 in memory (size: 6.8 KiB, free: 127.1 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 265a8904746d:37775 in memory (size: 6.8 KiB, free: 1048.7 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 265a8904746d:37775 in memory (size: 7.8 KiB, free: 1048.7 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.19.0.7:39501 in memory (size: 7.8 KiB, free: 127.2 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 265a8904746d:37775 in memory (size: 9.3 KiB, free: 1048.7 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.19.0.4:45103 in memory (size: 9.3 KiB, free: 127.2 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 265a8904746d:37775 in memory (size: 7.8 KiB, free: 1048.7 MiB)
25/04/05 01:04:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.19.0.7:39501 in memory (size: 7.8 KiB, free: 127.2 MiB)
25/04/05 01:04:33 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 3472 ms on 172.19.0.8 (executor 0) (1/2)
25/04/05 01:04:33 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 9) in 3501 ms on 172.19.0.4 (executor 1) (2/2)
25/04/05 01:04:33 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/05 01:04:33 INFO DAGScheduler: ResultStage 11 (showString at <unknown>:0) finished in 3.523 s
25/04/05 01:04:33 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 01:04:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/05 01:04:33 INFO DAGScheduler: Job 8 finished: showString at <unknown>:0, took 1.241647 s
25/04/05 01:04:33 INFO CodeGenerator: Code generated in 12.519446 ms
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+
|BatchName  |DqcId   |StartTime                 |EndTime                   |Duration    |Scripts                                                                   |Run|Result     |Status|
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+
|BATCH_RTNPF|DQ000002|2025-04-05 01:04:23.799952|2025-04-05 01:04:24.222357|0.42 seconds|SELECT COUNT(1) CNT FROM RTRNPF WHERE YEAR(`Subscription Date`) = '2021'  |1  |7          |Failed|
|BATCH_RTNPF|DQ000001|2025-04-05 01:04:23.799477|2025-04-05 01:04:24.154668|0.36 seconds|SELECT COUNT(1) CNT FROM RTRNPF                                           |1  |18         |Failed|
|BATCH_RTNPF|DQ000002|2025-04-05 01:04:23.80051 |2025-04-05 01:04:24.209433|0.41 seconds|SELECT SUM(CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2))) CNT FROM RTRNPF|1  |18004181.76|Failed|
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+

2025-04-05 01:04:33,992 - INFO - None
25/04/05 01:04:33 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/04/05 01:04:34 INFO SparkUI: Stopped Spark web UI at http://265a8904746d:4041
25/04/05 01:04:34 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/05 01:04:34 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/04/05 01:04:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/05 01:04:34 INFO MemoryStore: MemoryStore cleared
25/04/05 01:04:34 INFO BlockManager: BlockManager stopped
25/04/05 01:04:34 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/05 01:04:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/05 01:04:34 INFO SparkContext: Successfully stopped SparkContext
2025-04-05 01:04:34,964 - INFO - Closing down clientserver connection
25/04/05 01:04:35 INFO ShutdownHookManager: Shutdown hook called
25/04/05 01:04:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-d6470732-0648-40cc-9096-c764863a2010
25/04/05 01:04:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-8d7bb318-43c6-40da-bfbc-f14eaef593f7
25/04/05 01:04:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-8d7bb318-43c6-40da-bfbc-f14eaef593f7/pyspark-5b7194b3-ca95-4173-9b37-6a662725989f
Sat Apr  5 01:04:35 UTC 2025 - BASH - Spark job 'BATCH_RTNPF' completed
