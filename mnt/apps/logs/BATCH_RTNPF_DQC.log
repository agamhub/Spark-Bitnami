+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
|    |  BatchName  |  DqcId   |                                  Scripts                                   | Run | RefTable | SP |
+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
| 8  | BATCH_RTNPF | DQ000001 |                      SELECT COUNT(1) CNT FROM RTRNPF                       |  1  |   nan    | 0  |
| 9  | BATCH_RTNPF | DQ000002 |  SELECT COUNT(1) CNT FROM RTRNPF WHERE YEAR(`Subscription Date`) = '2021'  |  1  |   nan    | 0  |
| 10 | BATCH_RTNPF | DQ000002 | SELECT SUM(CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2))) CNT FROM RTRNPF |  1  |   nan    | 0  |
+----+-------------+----------+----------------------------------------------------------------------------+-----+----------+----+
+---+-------------+---------+
|   |  BatchName  | JobName |
+---+-------------+---------+
| 0 | BATCH_RTNPF | RTRNPF  |
+---+-------------+---------+
25/04/20 08:34:33 INFO SparkContext: Running Spark version 3.5.4
25/04/20 08:34:33 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
25/04/20 08:34:33 INFO SparkContext: Java version 17.0.14
25/04/20 08:34:33 INFO ResourceUtils: ==============================================================
25/04/20 08:34:33 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/20 08:34:33 INFO ResourceUtils: ==============================================================
25/04/20 08:34:33 INFO SparkContext: Submitted application: BATCH_RTNPF_DQC
25/04/20 08:34:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 512, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/20 08:34:33 INFO ResourceProfile: Limiting resource is cpu
25/04/20 08:34:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/20 08:34:33 INFO SecurityManager: Changing view acls to: spark,root
25/04/20 08:34:33 INFO SecurityManager: Changing modify acls to: spark,root
25/04/20 08:34:33 INFO SecurityManager: Changing view acls groups to: 
25/04/20 08:34:33 INFO SecurityManager: Changing modify acls groups to: 
25/04/20 08:34:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, root; groups with view permissions: EMPTY; users with modify permissions: spark, root; groups with modify permissions: EMPTY
25/04/20 08:34:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/20 08:34:33 INFO Utils: Successfully started service 'sparkDriver' on port 43573.
25/04/20 08:34:33 INFO SparkEnv: Registering MapOutputTracker
25/04/20 08:34:33 INFO SparkEnv: Registering BlockManagerMaster
25/04/20 08:34:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/20 08:34:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/20 08:34:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/20 08:34:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ae8ac4f6-fab9-47e9-b8d8-58784a8ab626
25/04/20 08:34:33 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/04/20 08:34:33 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/20 08:34:33 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/04/20 08:34:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/20 08:34:33 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/20 08:34:33 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 23 ms (0 ms spent in bootstraps)
25/04/20 08:34:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250420083433-0009
25/04/20 08:34:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250420083433-0009/0 on worker-20250420075815-172.20.0.8-40709 (172.20.0.8:40709) with 1 core(s)
25/04/20 08:34:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250420083433-0009/0 on hostPort 172.20.0.8:40709 with 1 core(s), 512.0 MiB RAM
25/04/20 08:34:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250420083433-0009/1 on worker-20250420075815-172.20.0.7-45749 (172.20.0.7:45749) with 1 core(s)
25/04/20 08:34:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250420083433-0009/1 on hostPort 172.20.0.7:45749 with 1 core(s), 512.0 MiB RAM
25/04/20 08:34:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250420083433-0009/2 on worker-20250420075814-172.20.0.5-37159 (172.20.0.5:37159) with 1 core(s)
25/04/20 08:34:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250420083433-0009/2 on hostPort 172.20.0.5:37159 with 1 core(s), 512.0 MiB RAM
25/04/20 08:34:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38221.
25/04/20 08:34:34 INFO NettyBlockTransferService: Server created on c397a49c5146:38221
25/04/20 08:34:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/20 08:34:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c397a49c5146, 38221, None)
25/04/20 08:34:34 INFO BlockManagerMasterEndpoint: Registering block manager c397a49c5146:38221 with 1048.8 MiB RAM, BlockManagerId(driver, c397a49c5146, 38221, None)
25/04/20 08:34:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c397a49c5146, 38221, None)
25/04/20 08:34:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c397a49c5146, 38221, None)
25/04/20 08:34:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250420083433-0009/1 is now RUNNING
25/04/20 08:34:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250420083433-0009/2 is now RUNNING
25/04/20 08:34:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250420083433-0009/0 is now RUNNING
25/04/20 08:34:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/20 08:34:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/04/20 08:34:34 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/04/20 08:34:37 INFO InMemoryFileIndex: It took 66 ms to list leaf files for 1 paths.
25/04/20 08:34:37 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.7:59422) with ID 1,  ResourceProfileId 0
25/04/20 08:34:37 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.8:50376) with ID 0,  ResourceProfileId 0
25/04/20 08:34:37 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:45552) with ID 2,  ResourceProfileId 0
25/04/20 08:34:37 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.7:36547 with 127.2 MiB RAM, BlockManagerId(1, 172.20.0.7, 36547, None)
25/04/20 08:34:37 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.8:43957 with 127.2 MiB RAM, BlockManagerId(0, 172.20.0.8, 43957, None)
25/04/20 08:34:37 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:43421 with 127.2 MiB RAM, BlockManagerId(2, 172.20.0.5, 43421, None)
25/04/20 08:34:37 INFO SparkContext: Starting job: sql at <unknown>:0
25/04/20 08:34:37 INFO DAGScheduler: Got job 0 (sql at <unknown>:0) with 1 output partitions
25/04/20 08:34:37 INFO DAGScheduler: Final stage: ResultStage 0 (sql at <unknown>:0)
25/04/20 08:34:37 INFO DAGScheduler: Parents of final stage: List()
25/04/20 08:34:37 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:37 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at sql at <unknown>:0), which has no missing parents
25/04/20 08:34:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.7 KiB, free 1048.7 MiB)
25/04/20 08:34:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 1048.7 MiB)
25/04/20 08:34:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c397a49c5146:38221 (size: 37.4 KiB, free: 1048.8 MiB)
25/04/20 08:34:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/20 08:34:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 9213 bytes) 
25/04/20 08:34:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.5:43421 (size: 37.4 KiB, free: 127.2 MiB)
25/04/20 08:34:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 619 ms on 172.20.0.5 (executor 2) (1/1)
25/04/20 08:34:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/20 08:34:38 INFO DAGScheduler: ResultStage 0 (sql at <unknown>:0) finished in 0.733 s
25/04/20 08:34:38 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/20 08:34:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/20 08:34:38 INFO DAGScheduler: Job 0 finished: sql at <unknown>:0, took 0.766183 s
25/04/20 08:34:39 INFO CodeGenerator: Code generated in 192.080894 ms
25/04/20 08:34:39 INFO CodeGenerator: Code generated in 16.165567 ms
25/04/20 08:34:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on c397a49c5146:38221 in memory (size: 37.4 KiB, free: 1048.8 MiB)
25/04/20 08:34:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.5:43421 in memory (size: 37.4 KiB, free: 127.2 MiB)
25/04/20 08:34:39 INFO InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
25/04/20 08:34:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/20 08:34:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/20 08:34:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/20 08:34:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/20 08:34:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(`Subscription Date`)
25/04/20 08:34:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Subscription Date#31),(year(Subscription Date#31) = 2021)
25/04/20 08:34:40 INFO CodeGenerator: Code generated in 36.871296 ms
25/04/20 08:34:40 INFO CodeGenerator: Code generated in 46.202354 ms
25/04/20 08:34:40 INFO CodeGenerator: Code generated in 39.244401 ms
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 201.5 KiB, free 1048.4 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 201.6 KiB, free 1048.4 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 201.6 KiB, free 1048.2 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 1048.2 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on c397a49c5146:38221 (size: 35.0 KiB, free: 1048.8 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 1048.1 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 1048.1 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c397a49c5146:38221 (size: 34.9 KiB, free: 1048.7 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on c397a49c5146:38221 (size: 34.9 KiB, free: 1048.7 MiB)
25/04/20 08:34:40 INFO SparkContext: Created broadcast 3 from collectToPython at <unknown>:0
25/04/20 08:34:40 INFO SparkContext: Created broadcast 1 from collect at /mnt/apps/jobs/SparkDataQuality.py:110
25/04/20 08:34:40 INFO SparkContext: Created broadcast 2 from collectToPython at <unknown>:0
25/04/20 08:34:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/20 08:34:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/20 08:34:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/20 08:34:40 INFO DAGScheduler: Registering RDD 11 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) as input to shuffle 1
25/04/20 08:34:40 INFO DAGScheduler: Got map stage job 3 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) with 1 output partitions
25/04/20 08:34:40 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (collect at /mnt/apps/jobs/SparkDataQuality.py:110)
25/04/20 08:34:40 INFO DAGScheduler: Parents of final stage: List()
25/04/20 08:34:40 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at collect at /mnt/apps/jobs/SparkDataQuality.py:110), which has no missing parents
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 17.0 KiB, free 1048.1 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.1 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on c397a49c5146:38221 (size: 7.8 KiB, free: 1048.7 MiB)
25/04/20 08:34:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at collect at /mnt/apps/jobs/SparkDataQuality.py:110) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/20 08:34:40 INFO DAGScheduler: Registering RDD 13 (collectToPython at <unknown>:0) as input to shuffle 2
25/04/20 08:34:40 INFO DAGScheduler: Got map stage job 1 (collectToPython at <unknown>:0) with 1 output partitions
25/04/20 08:34:40 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (collectToPython at <unknown>:0)
25/04/20 08:34:40 INFO DAGScheduler: Parents of final stage: List()
25/04/20 08:34:40 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:40 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at collectToPython at <unknown>:0), which has no missing parents
25/04/20 08:34:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.0.7, executor 1, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.6 KiB, free 1048.1 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 1048.1 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on c397a49c5146:38221 (size: 8.3 KiB, free: 1048.7 MiB)
25/04/20 08:34:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/20 08:34:40 INFO DAGScheduler: Registering RDD 12 (collectToPython at <unknown>:0) as input to shuffle 0
25/04/20 08:34:40 INFO DAGScheduler: Got map stage job 2 (collectToPython at <unknown>:0) with 1 output partitions
25/04/20 08:34:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/20 08:34:40 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collectToPython at <unknown>:0)
25/04/20 08:34:40 INFO DAGScheduler: Parents of final stage: List()
25/04/20 08:34:40 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:40 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[12] at collectToPython at <unknown>:0), which has no missing parents
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 21.4 KiB, free 1048.0 MiB)
25/04/20 08:34:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 1048.0 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on c397a49c5146:38221 (size: 9.3 KiB, free: 1048.7 MiB)
25/04/20 08:34:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[12] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/20 08:34:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.20.0.8, executor 0, partition 0, PROCESS_LOCAL, 9672 bytes) 
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:43421 (size: 8.3 KiB, free: 127.2 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.7:36547 (size: 7.8 KiB, free: 127.2 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.8:43957 (size: 9.3 KiB, free: 127.2 MiB)
25/04/20 08:34:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.5:43421 (size: 34.9 KiB, free: 127.2 MiB)
25/04/20 08:34:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.7:36547 (size: 34.9 KiB, free: 127.2 MiB)
25/04/20 08:34:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.8:43957 (size: 35.0 KiB, free: 127.2 MiB)
25/04/20 08:34:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1154 ms on 172.20.0.5 (executor 2) (1/1)
25/04/20 08:34:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/20 08:34:41 INFO DAGScheduler: ShuffleMapStage 2 (collectToPython at <unknown>:0) finished in 1.174 s
25/04/20 08:34:41 INFO DAGScheduler: looking for newly runnable stages
25/04/20 08:34:41 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 3)
25/04/20 08:34:41 INFO DAGScheduler: waiting: Set()
25/04/20 08:34:41 INFO DAGScheduler: failed: Set()
25/04/20 08:34:41 INFO CodeGenerator: Code generated in 14.810253 ms
25/04/20 08:34:41 INFO SparkContext: Starting job: collectToPython at <unknown>:0
25/04/20 08:34:41 INFO DAGScheduler: Got job 4 (collectToPython at <unknown>:0) with 1 output partitions
25/04/20 08:34:41 INFO DAGScheduler: Final stage: ResultStage 5 (collectToPython at <unknown>:0)
25/04/20 08:34:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/20 08:34:41 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:41 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at collectToPython at <unknown>:0), which has no missing parents
25/04/20 08:34:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.5 KiB, free 1048.0 MiB)
25/04/20 08:34:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.0 MiB)
25/04/20 08:34:41 INFO BlockManagerInfo: Removed broadcast_5_piece0 on c397a49c5146:38221 in memory (size: 8.3 KiB, free: 1048.7 MiB)
25/04/20 08:34:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on c397a49c5146:38221 (size: 5.9 KiB, free: 1048.7 MiB)
25/04/20 08:34:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/20 08:34:41 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:43421 in memory (size: 8.3 KiB, free: 127.2 MiB)
25/04/20 08:34:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/20 08:34:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.5:43421 (size: 5.9 KiB, free: 127.2 MiB)
25/04/20 08:34:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.5:45552
25/04/20 08:34:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 244 ms on 172.20.0.5 (executor 2) (1/1)
25/04/20 08:34:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/20 08:34:41 INFO DAGScheduler: ResultStage 5 (collectToPython at <unknown>:0) finished in 0.284 s
25/04/20 08:34:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/20 08:34:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/20 08:34:41 INFO DAGScheduler: Job 4 finished: collectToPython at <unknown>:0, took 0.300579 s
2025-04-20 08:34:41,862 - INFO - Closing down clientserver connection
25/04/20 08:34:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1602 ms on 172.20.0.7 (executor 1) (1/1)
25/04/20 08:34:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/20 08:34:41 INFO DAGScheduler: ShuffleMapStage 1 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) finished in 1.647 s
25/04/20 08:34:41 INFO DAGScheduler: looking for newly runnable stages
25/04/20 08:34:41 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
25/04/20 08:34:41 INFO DAGScheduler: waiting: Set()
25/04/20 08:34:41 INFO DAGScheduler: failed: Set()
25/04/20 08:34:41 INFO SparkContext: Starting job: collect at /mnt/apps/jobs/SparkDataQuality.py:110
25/04/20 08:34:41 INFO DAGScheduler: Got job 5 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) with 1 output partitions
25/04/20 08:34:41 INFO DAGScheduler: Final stage: ResultStage 7 (collect at /mnt/apps/jobs/SparkDataQuality.py:110)
25/04/20 08:34:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/20 08:34:41 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:41 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[19] at collect at /mnt/apps/jobs/SparkDataQuality.py:110), which has no missing parents
25/04/20 08:34:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.5 KiB, free 1048.0 MiB)
25/04/20 08:34:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 1048.0 MiB)
25/04/20 08:34:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on c397a49c5146:38221 (size: 5.9 KiB, free: 1048.7 MiB)
25/04/20 08:34:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[19] at collect at /mnt/apps/jobs/SparkDataQuality.py:110) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:41 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/20 08:34:41 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.20.0.7, executor 1, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/20 08:34:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.7:36547 (size: 5.9 KiB, free: 127.2 MiB)
25/04/20 08:34:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.7:59422
25/04/20 08:34:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 257 ms on 172.20.0.7 (executor 1) (1/1)
25/04/20 08:34:42 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/20 08:34:42 INFO DAGScheduler: ResultStage 7 (collect at /mnt/apps/jobs/SparkDataQuality.py:110) finished in 0.273 s
25/04/20 08:34:42 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/20 08:34:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/20 08:34:42 INFO DAGScheduler: Job 5 finished: collect at /mnt/apps/jobs/SparkDataQuality.py:110, took 0.280544 s
2025-04-20 08:34:42,211 - INFO - Closing down clientserver connection
25/04/20 08:34:42 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1927 ms on 172.20.0.8 (executor 0) (1/1)
25/04/20 08:34:42 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/20 08:34:42 INFO DAGScheduler: ShuffleMapStage 3 (collectToPython at <unknown>:0) finished in 1.945 s
25/04/20 08:34:42 INFO DAGScheduler: looking for newly runnable stages
25/04/20 08:34:42 INFO DAGScheduler: running: Set()
25/04/20 08:34:42 INFO DAGScheduler: waiting: Set()
25/04/20 08:34:42 INFO DAGScheduler: failed: Set()
25/04/20 08:34:42 INFO CodeGenerator: Code generated in 17.460457 ms
25/04/20 08:34:42 INFO SparkContext: Starting job: collectToPython at <unknown>:0
25/04/20 08:34:42 INFO DAGScheduler: Got job 6 (collectToPython at <unknown>:0) with 1 output partitions
25/04/20 08:34:42 INFO DAGScheduler: Final stage: ResultStage 9 (collectToPython at <unknown>:0)
25/04/20 08:34:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/20 08:34:42 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:42 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at collectToPython at <unknown>:0), which has no missing parents
25/04/20 08:34:42 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 14.9 KiB, free 1048.0 MiB)
25/04/20 08:34:42 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 1048.0 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on c397a49c5146:38221 (size: 6.8 KiB, free: 1048.7 MiB)
25/04/20 08:34:42 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at collectToPython at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:42 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/20 08:34:42 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.20.0.8, executor 0, partition 0, NODE_LOCAL, 9003 bytes) 
25/04/20 08:34:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.8:43957 (size: 6.8 KiB, free: 127.2 MiB)
25/04/20 08:34:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.8:50376
25/04/20 08:34:42 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 191 ms on 172.20.0.8 (executor 0) (1/1)
25/04/20 08:34:42 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/20 08:34:42 INFO DAGScheduler: ResultStage 9 (collectToPython at <unknown>:0) finished in 0.200 s
25/04/20 08:34:42 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/20 08:34:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/20 08:34:42 INFO DAGScheduler: Job 6 finished: collectToPython at <unknown>:0, took 0.204261 s
2025-04-20 08:34:42,518 - INFO - Closing down clientserver connection
25/04/20 08:34:42 INFO CodeGenerator: Code generated in 18.704181 ms
25/04/20 08:34:42 INFO SparkContext: Starting job: showString at <unknown>:0
25/04/20 08:34:42 INFO DAGScheduler: Got job 7 (showString at <unknown>:0) with 1 output partitions
25/04/20 08:34:42 INFO DAGScheduler: Final stage: ResultStage 10 (showString at <unknown>:0)
25/04/20 08:34:42 INFO DAGScheduler: Parents of final stage: List()
25/04/20 08:34:42 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:42 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[29] at showString at <unknown>:0), which has no missing parents
25/04/20 08:34:42 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 16.2 KiB, free 1048.0 MiB)
25/04/20 08:34:42 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.0 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on c397a49c5146:38221 (size: 7.8 KiB, free: 1048.7 MiB)
25/04/20 08:34:42 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_7_piece0 on c397a49c5146:38221 in memory (size: 5.9 KiB, free: 1048.7 MiB)
25/04/20 08:34:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[29] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/04/20 08:34:42 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.5:43421 in memory (size: 5.9 KiB, free: 127.2 MiB)
25/04/20 08:34:42 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 9159 bytes) 
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_8_piece0 on c397a49c5146:38221 in memory (size: 5.9 KiB, free: 1048.7 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.7:36547 in memory (size: 5.9 KiB, free: 127.2 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.5:43421 (size: 7.8 KiB, free: 127.2 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_4_piece0 on c397a49c5146:38221 in memory (size: 7.8 KiB, free: 1048.7 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.7:36547 in memory (size: 7.8 KiB, free: 127.2 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_9_piece0 on c397a49c5146:38221 in memory (size: 6.8 KiB, free: 1048.7 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.8:43957 in memory (size: 6.8 KiB, free: 127.2 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_6_piece0 on c397a49c5146:38221 in memory (size: 9.3 KiB, free: 1048.7 MiB)
25/04/20 08:34:42 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.8:43957 in memory (size: 9.3 KiB, free: 127.2 MiB)
25/04/20 08:34:43 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 943 ms on 172.20.0.5 (executor 2) (1/1)
25/04/20 08:34:43 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/20 08:34:43 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 47393
25/04/20 08:34:43 INFO DAGScheduler: ResultStage 10 (showString at <unknown>:0) finished in 0.972 s
25/04/20 08:34:43 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/20 08:34:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/20 08:34:43 INFO DAGScheduler: Job 7 finished: showString at <unknown>:0, took 0.978091 s
25/04/20 08:34:43 INFO SparkContext: Starting job: showString at <unknown>:0
25/04/20 08:34:43 INFO DAGScheduler: Got job 8 (showString at <unknown>:0) with 2 output partitions
25/04/20 08:34:43 INFO DAGScheduler: Final stage: ResultStage 11 (showString at <unknown>:0)
25/04/20 08:34:43 INFO DAGScheduler: Parents of final stage: List()
25/04/20 08:34:43 INFO DAGScheduler: Missing parents: List()
25/04/20 08:34:43 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[29] at showString at <unknown>:0), which has no missing parents
25/04/20 08:34:43 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 16.2 KiB, free 1048.1 MiB)
25/04/20 08:34:43 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1048.1 MiB)
25/04/20 08:34:43 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on c397a49c5146:38221 (size: 7.8 KiB, free: 1048.7 MiB)
25/04/20 08:34:43 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
25/04/20 08:34:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[29] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1, 2))
25/04/20 08:34:43 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks resource profile 0
25/04/20 08:34:43 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8) (172.20.0.7, executor 1, partition 1, PROCESS_LOCAL, 9119 bytes) 
25/04/20 08:34:43 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 9) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 9171 bytes) 
25/04/20 08:34:43 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:43421 (size: 7.8 KiB, free: 127.2 MiB)
25/04/20 08:34:43 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.7:36547 (size: 7.8 KiB, free: 127.2 MiB)
25/04/20 08:34:43 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 9) in 122 ms on 172.20.0.5 (executor 2) (1/2)
25/04/20 08:34:44 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 842 ms on 172.20.0.7 (executor 1) (2/2)
25/04/20 08:34:44 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/20 08:34:44 INFO DAGScheduler: ResultStage 11 (showString at <unknown>:0) finished in 0.850 s
25/04/20 08:34:44 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/20 08:34:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/20 08:34:44 INFO DAGScheduler: Job 8 finished: showString at <unknown>:0, took 0.853760 s
25/04/20 08:34:44 INFO CodeGenerator: Code generated in 9.110356 ms
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+
|BatchName  |DqcId   |StartTime                 |EndTime                   |Duration    |Scripts                                                                   |Run|Result     |Status|
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+
|BATCH_RTNPF|DQ000002|2025-04-20 08:34:39.55084 |2025-04-20 08:34:39.829868|0.28 seconds|SELECT COUNT(1) CNT FROM RTRNPF WHERE YEAR(`Subscription Date`) = '2021'  |1  |7          |Failed|
|BATCH_RTNPF|DQ000001|2025-04-20 08:34:39.550415|2025-04-20 08:34:39.803173|0.25 seconds|SELECT COUNT(1) CNT FROM RTRNPF                                           |1  |18         |Failed|
|BATCH_RTNPF|DQ000002|2025-04-20 08:34:39.551136|2025-04-20 08:34:39.822251|0.27 seconds|SELECT SUM(CAST(REPLACE(Budget,',','.') AS DECIMAL(18,2))) CNT FROM RTRNPF|1  |18004181.76|Failed|
+-----------+--------+--------------------------+--------------------------+------------+--------------------------------------------------------------------------+---+-----------+------+

2025-04-20 08:34:44,538 - INFO - None
25/04/20 08:34:44 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/04/20 08:34:44 INFO SparkUI: Stopped Spark web UI at http://c397a49c5146:4040
25/04/20 08:34:44 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/20 08:34:44 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
25/04/20 08:34:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/20 08:34:44 INFO MemoryStore: MemoryStore cleared
25/04/20 08:34:44 INFO BlockManager: BlockManager stopped
25/04/20 08:34:44 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/20 08:34:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/20 08:34:44 INFO SparkContext: Successfully stopped SparkContext
2025-04-20 08:34:45,518 - INFO - Closing down clientserver connection
25/04/20 08:34:45 INFO ShutdownHookManager: Shutdown hook called
25/04/20 08:34:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-a0ec50aa-c9bf-4aa7-a5aa-93fa4232d692/pyspark-007388f5-28cd-4893-bbee-9d98fe4d7a8c
25/04/20 08:34:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-a0ec50aa-c9bf-4aa7-a5aa-93fa4232d692
25/04/20 08:34:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-ce838b73-9dc4-46e6-8575-b279f0c6b7a1
Sun Apr 20 08:34:45 UTC 2025 - BASH - Spark job 'BATCH_RTNPF' completed
