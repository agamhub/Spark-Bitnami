[2025-02-01T14:48:37.143+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:48:37.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:48:37.145+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:48:37.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:48:37.167+0000] {processor.py:925} INFO - DAG(s) 'hello_world' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:48:37.283+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:48:37.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:48:37.299+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:48:37.299+0000] {dag.py:4180} INFO - Setting next_dagrun for hello_world to None, run_after=None
[2025-02-01T14:48:37.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.181 seconds
[2025-02-01T14:49:07.497+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:07.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:49:07.500+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:07.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:07.513+0000] {processor.py:925} INFO - DAG(s) 'hello_world' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:07.537+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:07.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:49:07.550+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:07.550+0000] {dag.py:4180} INFO - Setting next_dagrun for hello_world to None, run_after=None
[2025-02-01T14:49:07.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.112 seconds
[2025-02-01T14:49:12.556+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:12.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:49:12.559+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:12.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:12.582+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:12.576+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:49:12.585+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:12.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.050 seconds
[2025-02-01T14:49:15.583+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:15.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:49:15.588+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:15.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:15.608+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:15.603+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:49:15.615+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:15.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.052 seconds
[2025-02-01T14:49:45.821+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:45.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:49:45.824+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:45.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:45.836+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:49:45.832+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:49:45.839+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:49:45.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.038 seconds
[2025-02-01T14:50:09.968+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:09.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:50:09.971+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:09.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:09.991+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:09.986+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:50:09.995+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:10.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.047 seconds
[2025-02-01T14:50:40.162+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:40.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:50:40.163+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:40.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:40.176+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:40.171+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:50:40.179+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:40.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.036 seconds
[2025-02-01T14:50:42.193+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:42.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:50:42.195+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:42.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:42.215+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:42.209+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:50:42.218+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:42.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T14:50:46.273+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:46.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:50:46.275+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:46.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:46.288+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:46.287+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 19
    start >> end
IndentationError: unexpected indent
[2025-02-01T14:50:46.289+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:46.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T14:50:47.301+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:47.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:50:47.302+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:47.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:47.321+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:50:47.316+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:50:47.325+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:50:47.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T14:51:06.458+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:06.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:06.459+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:06.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:06.471+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:06.470+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 12
    ) AS dag:
      ^^
SyntaxError: invalid syntax
[2025-02-01T14:51:06.471+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:06.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.032 seconds
[2025-02-01T14:51:07.475+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:07.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:07.477+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:07.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:07.496+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:07.491+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:51:07.499+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:07.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T14:51:21.606+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:21.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:21.608+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:21.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:21.627+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:21.622+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:51:21.639+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:21.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.053 seconds
[2025-02-01T14:51:22.727+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:22.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:22.729+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:22.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:22.747+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:22.742+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:51:22.751+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:22.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T14:51:25.774+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:25.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:25.776+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:25.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:25.799+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:25.794+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:51:25.803+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:25.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.051 seconds
[2025-02-01T14:51:31.861+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:31.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:31.863+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:31.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:31.876+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:31.875+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    start >> end
IndentationError: unexpected indent
[2025-02-01T14:51:31.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:31.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.058 seconds
[2025-02-01T14:51:52.000+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:52.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:52.002+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:52.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:52.015+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:52.014+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    start >> end
IndentationError: unexpected indent
[2025-02-01T14:51:52.016+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:52.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.065 seconds
[2025-02-01T14:51:57.067+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:57.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:51:57.069+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:57.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:57.084+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:51:57.082+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    start >> end
IndentationError: unexpected indent
[2025-02-01T14:51:57.084+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:51:57.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T14:52:15.227+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:15.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:52:15.229+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:15.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:15.242+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:15.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    start >> end
IndentationError: unexpected indent
[2025-02-01T14:52:15.243+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:15.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T14:52:29.339+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:29.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:52:29.341+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:29.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:29.355+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:29.354+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 34
    start >> end
IndentationError: unexpected indent
[2025-02-01T14:52:29.355+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:29.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.036 seconds
[2025-02-01T14:52:39.416+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:39.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:52:39.418+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:39.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:39.432+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:39.431+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 34
    start >> [python_job, scala_job, java_job] >> end
IndentationError: unexpected indent
[2025-02-01T14:52:39.432+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:39.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.058 seconds
[2025-02-01T14:52:40.466+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:40.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:52:40.469+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:40.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:40.489+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:40.484+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:52:40.493+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:40.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T14:52:43.536+0000] {processor.py:186} INFO - Started process (PID=303) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:43.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:52:43.538+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:43.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:43.560+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:43.554+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:52:43.563+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:43.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T14:52:46.580+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:46.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:52:46.582+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:46.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:46.603+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:52:46.598+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 9, in <module>
    start_date=pendulum.datetime(2023, 10, 26, tz="UTC"),
               ^^^^^^^^
NameError: name 'pendulum' is not defined
[2025-02-01T14:52:46.607+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:52:46.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.047 seconds
[2025-02-01T14:53:06.772+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:06.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:53:06.774+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:06.797+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:06.902+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.901+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T14:53:06.911+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.910+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T14:53:06.916+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.916+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T14:53:06.923+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.922+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T14:53:06.928+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.927+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T14:53:06.933+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.933+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T14:53:06.938+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.938+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T14:53:06.939+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:53:06.951+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.951+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T14:53:06.952+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:06.952+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:53:07.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.351 seconds
[2025-02-01T14:53:07.789+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:07.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:53:07.791+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:07.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:07.812+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:07.822+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:07.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:53:07.835+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:07.835+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:53:07.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T14:53:37.980+0000] {processor.py:186} INFO - Started process (PID=323) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:37.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:53:37.982+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:37.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:37.998+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:53:38.020+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:38.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:53:38.033+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:53:38.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:53:38.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T14:54:08.189+0000] {processor.py:186} INFO - Started process (PID=339) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:54:08.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:54:08.191+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:54:08.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:54:08.208+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:54:08.233+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:54:08.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:54:08.247+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:54:08.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:54:08.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T14:54:38.382+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:54:38.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:54:38.384+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:54:38.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:54:38.399+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:54:38.422+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:54:38.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:54:38.435+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:54:38.435+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:54:38.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T14:55:08.605+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:55:08.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:55:08.606+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:55:08.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:55:08.628+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:55:08.650+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:55:08.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:55:08.662+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:55:08.662+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:55:08.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T14:55:38.786+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:55:38.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:55:38.788+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:55:38.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:55:38.802+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:55:38.824+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:55:38.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:55:38.838+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:55:38.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:55:38.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T14:56:09.024+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:56:09.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:56:09.026+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:56:09.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:56:09.041+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:56:09.062+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:56:09.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:56:09.076+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:56:09.076+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:56:09.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T14:56:39.202+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:56:39.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:56:39.204+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:56:39.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:56:39.218+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:56:39.239+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:56:39.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:56:39.253+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:56:39.252+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:56:39.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T14:57:09.433+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:57:09.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:57:09.435+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:57:09.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:57:09.448+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:57:09.468+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:57:09.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:57:09.480+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:57:09.480+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:57:09.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.066 seconds
[2025-02-01T14:57:39.622+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:57:39.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:57:39.625+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:57:39.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:57:39.641+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:57:39.667+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:57:39.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:57:39.680+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:57:39.679+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:57:39.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T14:58:09.824+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:58:09.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:58:09.825+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:58:09.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:58:09.839+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:58:09.865+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:58:09.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:58:09.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:58:09.877+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:58:09.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T14:58:40.057+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:58:40.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:58:40.059+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:58:40.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:58:40.072+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:58:40.101+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:58:40.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:58:40.113+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:58:40.113+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:58:40.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T14:59:10.233+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:59:10.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:59:10.235+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:59:10.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:59:10.253+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:59:10.286+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:59:10.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:59:10.299+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:59:10.299+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:59:10.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T14:59:40.458+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:59:40.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T14:59:40.460+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:59:40.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:59:40.474+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T14:59:40.505+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:59:40.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T14:59:40.518+0000] {logging_mixin.py:190} INFO - [2025-02-01T14:59:40.518+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T14:59:40.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T15:00:10.643+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:00:10.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:00:10.645+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:00:10.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:00:10.659+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:00:10.687+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:00:10.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:00:10.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:00:10.700+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:00:10.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T15:01:48.860+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:01:48.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:01:48.863+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:01:48.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:01:48.879+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:01:48.926+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:01:48.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:01:48.942+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:01:48.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:01:48.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.109 seconds
[2025-02-01T15:02:19.045+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:02:19.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:02:19.048+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:02:19.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:02:19.064+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:02:19.088+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:02:19.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:02:19.102+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:02:19.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:02:19.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T15:02:49.309+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:02:49.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:02:49.312+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:02:49.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:02:49.325+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:02:49.346+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:02:49.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:02:49.358+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:02:49.358+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:02:49.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T15:03:19.481+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:03:19.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:03:19.483+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:03:19.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:03:19.496+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:03:19.517+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:03:19.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:03:19.530+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:03:19.530+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:03:19.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T15:03:49.715+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:03:49.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:03:49.717+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:03:49.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:03:49.732+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:03:49.753+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:03:49.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:03:49.765+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:03:49.764+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:03:49.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T15:04:13.905+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:04:13.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:04:13.909+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:04:13.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:04:13.925+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:04:13.950+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:04:13.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:04:13.964+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:04:13.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:04:13.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T15:04:44.088+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:04:44.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:04:44.090+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:04:44.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:04:44.105+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:04:44.128+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:04:44.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:04:44.142+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:04:44.142+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:04:44.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T15:05:14.334+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:05:14.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:05:14.337+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:05:14.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:05:14.353+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:05:14.377+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:05:14.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:05:14.390+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:05:14.390+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:05:14.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T15:05:44.519+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:05:44.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:05:44.522+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:05:44.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:05:44.539+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:05:44.566+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:05:44.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:05:44.582+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:05:44.582+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:05:44.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T15:06:14.752+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:06:14.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:06:14.754+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:06:14.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:06:14.769+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:06:14.791+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:06:14.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:06:14.805+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:06:14.804+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:06:14.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T15:06:44.931+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:06:44.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:06:44.933+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:06:44.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:06:44.948+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:06:44.969+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:06:44.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:06:44.982+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:06:44.982+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:06:45.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.095 seconds
[2025-02-01T15:07:15.188+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:07:15.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:07:15.191+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:07:15.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:07:15.205+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:07:15.228+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:07:15.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:07:15.241+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:07:15.241+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:07:15.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T15:28:53.181+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:28:53.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:28:53.183+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:28:53.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:28:53.199+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:28:53.243+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:28:53.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:28:53.256+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:28:53.256+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:28:53.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T15:29:23.374+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:29:23.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:29:23.378+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:29:23.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:29:23.392+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:29:23.417+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:29:23.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:29:23.431+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:29:23.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:29:23.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T15:29:53.620+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:29:53.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:29:53.622+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:29:53.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:29:53.638+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:29:53.662+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:29:53.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:29:53.676+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:29:53.676+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:29:53.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T15:30:23.808+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:30:23.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:30:23.811+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:30:23.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:30:23.834+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:30:23.862+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:30:23.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:30:23.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:30:23.878+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:30:23.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T15:30:54.041+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:30:54.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:30:54.043+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:30:54.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:30:54.061+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:30:54.085+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:30:54.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:30:54.101+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:30:54.101+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:30:54.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T15:31:24.238+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:31:24.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:31:24.241+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:31:24.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:31:24.255+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:31:24.278+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:31:24.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:31:24.290+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:31:24.290+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:31:24.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T15:31:54.454+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:31:54.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:31:54.457+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:31:54.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:31:54.470+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:31:54.491+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:31:54.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:31:54.503+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:31:54.503+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:31:54.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T15:32:24.647+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:32:24.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:32:24.651+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:32:24.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:32:24.670+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:32:24.699+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:32:24.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:32:24.713+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:32:24.713+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:32:24.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.091 seconds
[2025-02-01T15:32:54.876+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:32:54.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:32:54.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:32:54.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:32:54.894+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:32:54.916+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:32:54.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:32:54.928+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:32:54.928+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:32:54.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T15:33:25.052+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:33:25.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:33:25.054+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:33:25.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:33:25.068+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:33:25.089+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:33:25.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:33:25.101+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:33:25.101+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:33:25.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T15:33:55.302+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:33:55.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:33:55.304+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:33:55.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:33:55.320+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:33:55.342+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:33:55.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:33:55.355+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:33:55.355+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:33:55.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T15:34:25.480+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:34:25.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:34:25.483+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:34:25.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:34:25.499+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:34:25.523+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:34:25.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:34:25.535+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:34:25.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:34:25.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T15:34:55.702+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:34:55.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:34:55.704+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:34:55.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:34:55.718+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:34:55.740+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:34:55.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:34:55.752+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:34:55.752+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:34:55.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T15:35:25.881+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:35:25.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:35:25.883+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:35:25.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:35:25.897+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:35:25.921+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:35:25.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:35:25.934+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:35:25.934+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:35:25.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T15:35:56.121+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:35:56.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:35:56.124+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:35:56.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:35:56.138+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:35:56.158+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:35:56.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:35:56.171+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:35:56.171+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:35:56.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.094 seconds
[2025-02-01T15:36:26.301+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:36:26.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:36:26.303+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:36:26.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:36:26.317+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:36:26.340+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:36:26.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:36:26.354+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:36:26.353+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:36:26.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T15:36:56.551+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:36:56.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:36:56.554+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:36:56.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:36:56.569+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:36:56.592+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:36:56.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:36:56.605+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:36:56.605+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:36:56.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T15:38:27.614+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:38:27.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:38:27.617+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:38:27.633+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:38:27.763+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.763+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T15:38:27.773+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.773+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T15:38:27.780+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.779+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T15:38:27.787+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.786+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T15:38:27.792+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.792+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T15:38:27.798+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.798+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T15:38:27.804+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.804+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T15:38:27.804+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:38:27.818+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.817+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T15:38:27.819+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:27.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:38:27.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.230 seconds
[2025-02-01T15:38:58.018+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:38:58.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:38:58.021+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:58.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:38:58.035+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:38:58.057+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:58.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:38:58.070+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:38:58.069+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:38:58.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T15:39:28.188+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:39:28.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:39:28.190+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:39:28.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:39:28.205+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:39:28.231+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:39:28.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:39:28.246+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:39:28.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:39:28.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T15:39:58.409+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:39:58.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:39:58.411+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:39:58.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:39:58.424+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:39:58.445+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:39:58.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:39:58.457+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:39:58.457+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:39:58.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T15:40:28.590+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:40:28.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:40:28.593+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:40:28.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:40:28.608+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:40:28.632+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:40:28.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:40:28.646+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:40:28.645+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:40:28.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T15:41:30.610+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:41:30.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:41:30.612+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:41:30.628+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:41:30.753+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.752+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T15:41:30.766+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.765+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T15:41:30.774+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.773+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T15:41:30.781+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.781+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T15:41:30.788+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.787+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T15:41:30.795+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.794+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T15:41:30.802+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.802+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T15:41:30.803+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:41:30.817+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.817+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T15:41:30.818+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:41:30.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:41:30.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.233 seconds
[2025-02-01T15:42:01.023+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:42:01.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:42:01.026+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:42:01.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:42:01.041+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:42:01.065+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:42:01.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:42:01.079+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:42:01.078+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:42:01.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T15:44:02.567+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:44:02.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:44:02.569+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:44:02.585+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:44:02.706+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.706+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T15:44:02.714+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.714+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T15:44:02.719+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.719+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T15:44:02.725+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.725+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T15:44:02.730+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.730+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T15:44:02.736+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.735+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T15:44:02.741+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.741+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T15:44:02.742+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:44:02.753+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.753+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T15:44:02.754+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:02.754+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:44:02.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.207 seconds
[2025-02-01T15:44:32.947+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:44:32.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:44:32.949+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:32.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:44:32.963+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:44:32.984+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:32.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:44:32.996+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:44:32.996+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:44:33.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T15:45:03.123+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:45:03.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:45:03.126+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:45:03.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:45:03.141+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:45:03.165+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:45:03.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:45:03.179+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:45:03.178+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:45:03.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T15:45:33.366+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:45:33.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:45:33.369+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:45:33.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:45:33.384+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:45:33.407+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:45:33.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:45:33.420+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:45:33.420+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:45:33.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.131 seconds
[2025-02-01T15:46:03.555+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:46:03.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:46:03.558+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:46:03.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:46:03.573+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:46:03.598+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:46:03.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:46:03.614+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:46:03.614+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:46:03.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T15:46:33.726+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:46:33.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:46:33.729+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:46:33.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:46:33.742+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:46:33.763+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:46:33.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:46:33.775+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:46:33.775+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:46:33.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T15:47:03.974+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:47:03.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:47:03.977+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:47:03.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:47:03.991+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:47:04.012+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:47:04.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:47:04.025+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:47:04.025+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:47:04.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T15:47:34.153+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:47:34.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:47:34.156+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:47:34.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:47:34.172+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:47:34.195+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:47:34.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:47:34.208+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:47:34.208+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:47:34.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T15:48:04.379+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:48:04.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:48:04.382+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:48:04.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:48:04.397+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:48:04.423+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:48:04.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:48:04.437+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:48:04.436+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:48:04.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T15:48:34.564+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:48:34.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:48:34.567+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:48:34.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:48:34.580+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:48:34.601+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:48:34.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:48:34.614+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:48:34.613+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:48:34.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T15:49:04.812+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:49:04.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:49:04.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:49:04.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:49:04.828+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:49:04.848+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:49:04.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:49:04.861+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:49:04.860+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:49:04.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T15:49:34.984+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:49:34.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:49:34.986+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:49:34.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:49:35.000+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:49:35.021+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:49:35.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:49:35.033+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:49:35.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:49:35.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T15:50:05.238+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:50:05.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:50:05.240+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:50:05.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:50:05.255+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:50:05.277+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:50:05.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:50:05.290+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:50:05.290+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:50:05.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T15:50:35.431+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:50:35.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:50:35.434+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:50:35.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:50:35.453+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:50:35.477+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:50:35.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:50:35.490+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:50:35.490+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:50:35.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T15:51:05.646+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:51:05.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:51:05.648+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:51:05.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:51:05.664+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:51:05.686+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:51:05.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:51:05.698+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:51:05.698+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:51:05.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T15:51:35.841+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:51:35.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:51:35.843+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:51:35.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:51:35.857+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:51:35.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:51:35.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:51:35.891+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:51:35.891+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:51:35.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T15:52:06.055+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:52:06.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:52:06.058+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:52:06.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:52:06.073+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:52:06.097+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:52:06.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:52:06.111+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:52:06.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:52:06.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T15:52:36.246+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:52:36.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:52:36.249+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:52:36.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:52:36.264+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:52:36.288+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:52:36.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:52:36.301+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:52:36.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:52:36.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T15:53:06.466+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:06.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:53:06.469+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:06.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:06.483+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:06.504+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:06.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:53:06.516+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:06.516+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:53:06.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T15:53:10.527+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:10.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:53:10.529+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:10.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:10.554+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:10.681+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:10.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:53:10.695+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:10.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:53:10.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.200 seconds
[2025-02-01T15:53:19.643+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:19.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:53:19.647+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:19.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:19.671+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:19.682+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:19.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:53:19.696+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:19.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:53:19.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T15:53:22.828+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:22.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:53:22.830+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:22.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:22.852+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:22.861+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:22.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:53:22.875+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:22.874+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:53:22.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T15:53:23.844+0000] {processor.py:186} INFO - Started process (PID=421) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:23.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:53:23.847+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:23.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:23.861+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:23.871+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:23.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:53:23.884+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:23.884+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:53:23.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.065 seconds
[2025-02-01T15:53:54.107+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:54.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:53:54.110+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:54.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:54.125+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:53:54.237+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:54.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:53:54.250+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:53:54.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:53:54.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.167 seconds
[2025-02-01T15:54:24.310+0000] {processor.py:186} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:54:24.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:54:24.313+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:54:24.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:54:24.328+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:54:24.351+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:54:24.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:54:24.393+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:54:24.393+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:54:24.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T15:54:54.482+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:54:54.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:54:54.485+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:54:54.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:54:54.500+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:54:54.525+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:54:54.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:54:54.538+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:54:54.537+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:54:54.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T15:55:08.675+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:55:08.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:55:08.678+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:55:08.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:55:08.693+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:55:08.718+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:55:08.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:55:08.730+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:55:08.730+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:55:08.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T15:55:38.864+0000] {processor.py:186} INFO - Started process (PID=661) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:55:38.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:55:38.867+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:55:38.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:55:38.886+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:55:38.920+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:55:38.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:55:38.935+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:55:38.934+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:55:38.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T15:56:09.123+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:56:09.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:56:09.126+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:56:09.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:56:09.143+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:56:09.177+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:56:09.177+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:56:09.190+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:56:09.189+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:56:09.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T15:56:39.301+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:56:39.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:56:39.303+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:56:39.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:56:39.318+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:56:39.347+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:56:39.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:56:39.361+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:56:39.360+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:56:39.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T15:57:09.545+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:57:09.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:57:09.547+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:57:09.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:57:09.560+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:57:09.587+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:57:09.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:57:09.599+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:57:09.599+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:57:09.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T15:57:39.727+0000] {processor.py:186} INFO - Started process (PID=681) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:57:39.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:57:39.730+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:57:39.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:57:39.745+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:57:39.775+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:57:39.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:57:39.790+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:57:39.789+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:57:39.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T15:58:09.955+0000] {processor.py:186} INFO - Started process (PID=686) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:09.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:58:09.958+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:58:09.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:09.973+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:10.004+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:58:10.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T15:58:10.017+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:58:10.017+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T15:58:10.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T15:58:16.366+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:16.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:58:16.368+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:58:16.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:16.393+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:58:16.385+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^
NameError: name 'SparkSubmitOperator' is not defined
[2025-02-01T15:58:16.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:16.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.056 seconds
[2025-02-01T15:58:46.539+0000] {processor.py:186} INFO - Started process (PID=696) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:46.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:58:46.542+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:58:46.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:46.560+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:58:46.553+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^
NameError: name 'SparkSubmitOperator' is not defined
[2025-02-01T15:58:46.565+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:58:46.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.047 seconds
[2025-02-01T15:59:16.765+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:59:16.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:59:16.767+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:59:16.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:59:16.784+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:59:16.777+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^
NameError: name 'SparkSubmitOperator' is not defined
[2025-02-01T15:59:16.789+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:59:16.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T15:59:46.941+0000] {processor.py:186} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:59:46.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T15:59:46.945+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:59:46.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:59:46.963+0000] {logging_mixin.py:190} INFO - [2025-02-01T15:59:46.956+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = SparkSubmitOperator(
                 ^^^^^^^^^^^^^^^^^^^
NameError: name 'SparkSubmitOperator' is not defined
[2025-02-01T15:59:46.969+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T15:59:46.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.049 seconds
[2025-02-01T16:00:01.061+0000] {processor.py:186} INFO - Started process (PID=711) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:01.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:01.064+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:01.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:01.086+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:01.081+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 489, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'image'
[2025-02-01T16:00:01.087+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:01.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.051 seconds
[2025-02-01T16:00:07.126+0000] {processor.py:186} INFO - Started process (PID=716) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:07.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:07.129+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:07.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:07.154+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:07.148+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'application': 'jobs/first_DAG_jobs.py'}
[2025-02-01T16:00:07.156+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:07.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.059 seconds
[2025-02-01T16:00:10.208+0000] {processor.py:186} INFO - Started process (PID=721) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:10.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:10.210+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:10.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:10.231+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:10.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'application': 'jobs/first_DAG_jobs.py'}
[2025-02-01T16:00:10.232+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:10.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T16:00:16.280+0000] {processor.py:186} INFO - Started process (PID=726) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:16.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:16.281+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:16.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:16.305+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:16.300+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'application': 'jobs/first_DAG_jobs.py'}
[2025-02-01T16:00:16.306+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:16.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.048 seconds
[2025-02-01T16:00:20.341+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:20.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:20.343+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:20.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:20.363+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:20.359+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'application': 'jobs/first_DAG_jobs.py'}
[2025-02-01T16:00:20.364+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:20.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.046 seconds
[2025-02-01T16:00:47.541+0000] {processor.py:186} INFO - Started process (PID=736) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:47.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:47.543+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:47.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:47.563+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:47.559+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'ommand': ['spark-submit', '--master', 'spark://<spark-master-hostname>:7077', 'my_spark_app.py'], 'volumes': ['/path/to/your/data:/data']}
[2025-02-01T16:00:47.563+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:47.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.065 seconds
[2025-02-01T16:00:49.575+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:49.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:49.577+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:49.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:49.598+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:49.594+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/path/to/your/data:/data']}
[2025-02-01T16:00:49.620+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:49.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T16:00:55.692+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:55.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:00:55.694+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:55.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:55.716+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:00:55.711+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/path/to/your/data:/data']}
[2025-02-01T16:00:55.717+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:00:55.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.067 seconds
[2025-02-01T16:01:25.891+0000] {processor.py:186} INFO - Started process (PID=751) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:01:25.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:01:25.893+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:01:25.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:01:25.909+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:01:25.905+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/path/to/your/data:/data']}
[2025-02-01T16:01:25.910+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:01:25.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.041 seconds
[2025-02-01T16:01:41.994+0000] {processor.py:186} INFO - Started process (PID=756) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:01:41.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:01:41.996+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:01:41.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:01:42.017+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:01:42.012+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/path/to/your/data:/data']}
[2025-02-01T16:01:42.018+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:01:42.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T16:02:12.217+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:12.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:02:12.220+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:12.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:12.241+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:12.237+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:02:12.242+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:12.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T16:02:13.237+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:13.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:02:13.240+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:13.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:13.260+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:13.256+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/path/to/your/data:/data']}
[2025-02-01T16:02:13.261+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:13.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T16:02:14.306+0000] {processor.py:186} INFO - Started process (PID=771) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:14.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:02:14.307+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:14.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:14.328+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:14.324+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:02:14.329+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:14.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T16:02:44.485+0000] {processor.py:186} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:44.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:02:44.487+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:44.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:44.499+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:02:44.496+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:02:44.500+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:02:44.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T16:03:14.673+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:03:14.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:03:14.675+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:03:14.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:03:14.690+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:03:14.685+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:03:14.691+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:03:14.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.037 seconds
[2025-02-01T16:03:44.855+0000] {processor.py:186} INFO - Started process (PID=786) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:03:44.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:03:44.857+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:03:44.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:03:44.872+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:03:44.868+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:03:44.873+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:03:44.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.037 seconds
[2025-02-01T16:04:15.079+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:04:15.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:04:15.081+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:04:15.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:04:15.095+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:04:15.091+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:04:15.096+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:04:15.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.037 seconds
[2025-02-01T16:04:45.268+0000] {processor.py:186} INFO - Started process (PID=796) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:04:45.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:04:45.273+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:04:45.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:04:45.294+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:04:45.289+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:04:45.295+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:04:45.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.052 seconds
[2025-02-01T16:05:03.389+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:03.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:05:03.391+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:03.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:03.411+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:03.407+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:05:03.412+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:03.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T16:05:24.563+0000] {processor.py:186} INFO - Started process (PID=806) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:24.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:05:24.565+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:24.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:24.591+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:24.586+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:05:24.592+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:24.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.054 seconds
[2025-02-01T16:05:28.643+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:28.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:05:28.645+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:28.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:28.667+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:28.663+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:05:28.668+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:28.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.045 seconds
[2025-02-01T16:05:33.694+0000] {processor.py:186} INFO - Started process (PID=816) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:33.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:05:33.696+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:33.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:33.718+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:05:33.713+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:05:33.719+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:05:33.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.045 seconds
[2025-02-01T16:06:03.915+0000] {processor.py:186} INFO - Started process (PID=821) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:06:03.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:06:03.917+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:06:03.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:06:03.930+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:06:03.926+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:06:03.930+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:06:03.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.056 seconds
[2025-02-01T16:06:34.098+0000] {processor.py:186} INFO - Started process (PID=826) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:06:34.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:06:34.100+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:06:34.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:06:34.114+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:06:34.110+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:06:34.114+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:06:34.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T16:07:04.303+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:04.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:07:04.304+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:04.304+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:04.318+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:04.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:07:04.319+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:04.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T16:07:06.341+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:06.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:07:06.344+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:06.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:06.367+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:06.362+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:07:06.368+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:06.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.048 seconds
[2025-02-01T16:07:36.585+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:36.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:07:36.587+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:36.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:36.600+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:36.597+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:07:36.601+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:36.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.057 seconds
[2025-02-01T16:07:40.703+0000] {processor.py:186} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:40.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:07:40.705+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:40.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:40.725+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:07:40.721+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:07:40.726+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:07:40.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T16:08:10.881+0000] {processor.py:186} INFO - Started process (PID=851) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:10.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:08:10.883+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:08:10.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:10.897+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:08:10.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:08:10.898+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:10.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.036 seconds
[2025-02-01T16:08:41.083+0000] {processor.py:186} INFO - Started process (PID=856) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:41.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:08:41.085+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:08:41.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:41.100+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:08:41.096+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:08:41.101+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:41.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T16:08:50.160+0000] {processor.py:186} INFO - Started process (PID=861) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:50.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:08:50.162+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:08:50.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:50.193+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:08:50.357+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:08:50.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:08:50.370+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:08:50.369+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:08:50.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.239 seconds
[2025-02-01T16:09:20.576+0000] {processor.py:186} INFO - Started process (PID=866) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:20.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:09:20.578+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:20.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:20.599+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:20.623+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:20.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:09:20.637+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:20.637+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:09:20.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T16:09:25.609+0000] {processor.py:186} INFO - Started process (PID=871) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:25.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:09:25.610+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:25.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:25.632+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:25.627+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:09:25.633+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:25.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T16:09:27.640+0000] {processor.py:186} INFO - Started process (PID=876) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:27.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:09:27.642+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:27.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:27.669+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:27.693+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:27.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:09:27.708+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:27.708+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:09:27.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T16:09:57.864+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:57.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:09:57.866+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:57.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:57.884+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:09:57.906+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:57.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:09:57.921+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:09:57.921+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:09:57.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.082 seconds
[2025-02-01T16:10:27.072+0000] {processor.py:186} INFO - Started process (PID=892) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:27.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:10:27.074+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:10:27.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:27.115+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:10:27.110+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:10:27.116+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:27.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T16:10:29.130+0000] {processor.py:186} INFO - Started process (PID=897) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:29.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:10:29.132+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:10:29.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:29.155+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:10:29.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:10:29.155+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:29.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.048 seconds
[2025-02-01T16:10:47.289+0000] {processor.py:186} INFO - Started process (PID=902) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:47.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:10:47.291+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:10:47.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:47.318+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:10:47.313+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:10:47.319+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:10:47.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T16:11:17.475+0000] {processor.py:186} INFO - Started process (PID=907) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:17.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:17.476+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:17.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:17.492+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:17.487+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:17.493+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:17.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T16:11:45.705+0000] {processor.py:186} INFO - Started process (PID=912) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:45.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:45.707+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:45.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:45.730+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:45.725+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:\\Repo\\Spark-Bitnami\\jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:45.732+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/spark_airflow.py:27 SyntaxWarning: invalid escape sequence '\R'
[2025-02-01T16:11:45.733+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:45.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.049 seconds
[2025-02-01T16:11:48.747+0000] {processor.py:186} INFO - Started process (PID=917) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:48.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:48.749+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:48.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:48.797+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:48.792+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['\\Repo\\Spark-Bitnami\\jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:48.799+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/spark_airflow.py:27 SyntaxWarning: invalid escape sequence '\R'
[2025-02-01T16:11:48.799+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:48.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T16:11:49.810+0000] {processor.py:186} INFO - Started process (PID=922) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:49.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:49.812+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:49.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:49.834+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:49.829+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:\\Repo\\Spark-Bitnami\\jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:49.836+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/spark_airflow.py:27 SyntaxWarning: invalid escape sequence '\R'
[2025-02-01T16:11:49.837+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:49.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.050 seconds
[2025-02-01T16:11:50.875+0000] {processor.py:186} INFO - Started process (PID=927) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:50.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:50.877+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:50.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:50.897+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:50.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:Repo\\Spark-Bitnami\\jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:50.899+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/spark_airflow.py:27 SyntaxWarning: invalid escape sequence '\S'
[2025-02-01T16:11:50.899+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:50.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T16:11:55.938+0000] {processor.py:186} INFO - Started process (PID=932) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:55.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:55.941+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:55.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:55.962+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:55.958+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:/Repo\\Spark-Bitnami\\jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:55.964+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/spark_airflow.py:27 SyntaxWarning: invalid escape sequence '\S'
[2025-02-01T16:11:55.964+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:55.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.050 seconds
[2025-02-01T16:11:56.992+0000] {processor.py:186} INFO - Started process (PID=937) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:56.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:56.995+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:56.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:57.018+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:57.014+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:/Repo/Spark-Bitnami\\jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:57.024+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/spark_airflow.py:27 SyntaxWarning: invalid escape sequence '\j'
[2025-02-01T16:11:57.025+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:57.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.054 seconds
[2025-02-01T16:11:59.098+0000] {processor.py:186} INFO - Started process (PID=942) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:59.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:11:59.100+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:59.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:59.125+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:11:59.121+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:11:59.126+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:11:59.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.052 seconds
[2025-02-01T16:12:29.283+0000] {processor.py:186} INFO - Started process (PID=947) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:12:29.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:12:29.285+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:12:29.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:12:29.301+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:12:29.296+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:12:29.302+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:12:29.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.041 seconds
[2025-02-01T16:12:59.492+0000] {processor.py:186} INFO - Started process (PID=952) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:12:59.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:12:59.493+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:12:59.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:12:59.506+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:12:59.502+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['D:/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:12:59.507+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:12:59.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.033 seconds
[2025-02-01T16:13:15.601+0000] {processor.py:186} INFO - Started process (PID=957) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:13:15.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:13:15.603+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:13:15.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:13:15.624+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:13:15.620+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/host/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:13:15.624+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:13:15.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.066 seconds
[2025-02-01T16:13:43.809+0000] {processor.py:186} INFO - Started process (PID=962) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:13:43.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:13:43.811+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:13:43.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:13:43.836+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:13:43.932+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:13:43.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:13:43.944+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:13:43.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:13:43.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.160 seconds
[2025-02-01T16:14:14.050+0000] {processor.py:186} INFO - Started process (PID=967) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:14:14.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:14:14.053+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:14:14.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:14:14.080+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:14:14.110+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:14:14.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:14:14.125+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:14:14.124+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:14:14.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.103 seconds
[2025-02-01T16:14:44.323+0000] {processor.py:186} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:14:44.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:14:44.325+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:14:44.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:14:44.348+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:14:44.372+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:14:44.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:14:44.386+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:14:44.386+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:14:44.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T16:15:06.469+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:06.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:15:06.471+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:06.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:06.495+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:06.516+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:06.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:15:06.530+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:06.530+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:15:06.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.108 seconds
[2025-02-01T16:15:08.557+0000] {processor.py:186} INFO - Started process (PID=982) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:08.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:15:08.559+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:08.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:08.584+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:08.606+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:08.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:15:08.618+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:08.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:15:08.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T16:15:10.639+0000] {processor.py:186} INFO - Started process (PID=987) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:10.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:15:10.642+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:10.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:10.680+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:10.708+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:10.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:15:10.723+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:10.723+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:15:10.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.114 seconds
[2025-02-01T16:15:11.697+0000] {processor.py:186} INFO - Started process (PID=992) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:11.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:15:11.699+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:11.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:11.722+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:11.746+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:11.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:15:11.758+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:11.758+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:15:11.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T16:15:41.970+0000] {processor.py:186} INFO - Started process (PID=997) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:41.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:15:41.972+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:41.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:41.991+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:15:42.016+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:42.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:15:42.031+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:15:42.031+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:15:42.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T16:16:12.163+0000] {processor.py:186} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:16:12.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:16:12.166+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:16:12.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:16:12.183+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:16:12.206+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:16:12.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:16:12.220+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:16:12.220+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:16:12.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T16:16:42.416+0000] {processor.py:186} INFO - Started process (PID=1043) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:16:42.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:16:42.418+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:16:42.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:16:42.436+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:16:42.457+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:16:42.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:16:42.471+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:16:42.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:16:42.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T16:17:12.601+0000] {processor.py:186} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:17:12.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:17:12.603+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:17:12.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:17:12.622+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:17:12.649+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:17:12.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:17:12.667+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:17:12.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:17:12.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T16:17:42.862+0000] {processor.py:186} INFO - Started process (PID=1074) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:17:42.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:17:42.864+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:17:42.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:17:42.881+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:17:42.901+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:17:42.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:17:42.914+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:17:42.913+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:17:42.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T16:18:13.047+0000] {processor.py:186} INFO - Started process (PID=1079) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:18:13.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:18:13.050+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:18:13.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:18:13.074+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:18:13.104+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:18:13.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:18:13.119+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:18:13.119+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:18:13.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T16:18:43.276+0000] {processor.py:186} INFO - Started process (PID=1084) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:18:43.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:18:43.278+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:18:43.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:18:43.294+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:18:43.315+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:18:43.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:18:43.327+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:18:43.327+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:18:43.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T16:19:13.514+0000] {processor.py:186} INFO - Started process (PID=1089) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:19:13.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:19:13.516+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:19:13.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:19:13.533+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:19:13.555+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:19:13.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:19:13.568+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:19:13.567+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:19:13.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T16:19:43.693+0000] {processor.py:186} INFO - Started process (PID=1094) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:19:43.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:19:43.695+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:19:43.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:19:43.712+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:19:43.733+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:19:43.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:19:43.747+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:19:43.746+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:19:43.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T16:20:13.931+0000] {processor.py:186} INFO - Started process (PID=1099) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:20:13.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:20:13.933+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:20:13.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:20:13.951+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:20:13.974+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:20:13.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:20:13.986+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:20:13.986+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:20:14.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T16:20:44.111+0000] {processor.py:186} INFO - Started process (PID=1104) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:20:44.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:20:44.112+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:20:44.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:20:44.129+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:20:44.151+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:20:44.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:20:44.164+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:20:44.163+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:20:44.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T16:21:14.347+0000] {processor.py:186} INFO - Started process (PID=1109) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:21:14.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:21:14.349+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:21:14.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:21:14.366+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:21:14.389+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:21:14.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:21:14.402+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:21:14.402+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:21:14.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T16:21:44.529+0000] {processor.py:186} INFO - Started process (PID=1114) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:21:44.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:21:44.530+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:21:44.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:21:44.547+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:21:44.568+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:21:44.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:21:44.580+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:21:44.580+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:21:44.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T16:22:14.756+0000] {processor.py:186} INFO - Started process (PID=1119) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:22:14.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:22:14.758+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:22:14.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:22:14.775+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:22:14.796+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:22:14.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:22:14.810+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:22:14.810+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:22:14.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T16:22:44.945+0000] {processor.py:186} INFO - Started process (PID=1124) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:22:44.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:22:44.948+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:22:44.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:22:44.966+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:22:44.990+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:22:44.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:22:45.004+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:22:45.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:22:45.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T16:23:15.175+0000] {processor.py:186} INFO - Started process (PID=1129) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:23:15.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:23:15.177+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:23:15.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:23:15.193+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:23:15.215+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:23:15.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:23:15.227+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:23:15.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:23:15.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T16:23:45.360+0000] {processor.py:186} INFO - Started process (PID=1134) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:23:45.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:23:45.361+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:23:45.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:23:45.378+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:23:45.399+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:23:45.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:23:45.411+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:23:45.411+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:23:45.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T16:24:15.603+0000] {processor.py:186} INFO - Started process (PID=1139) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:24:15.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:24:15.605+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:24:15.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:24:15.623+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:24:15.646+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:24:15.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:24:15.665+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:24:15.664+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:24:15.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.091 seconds
[2025-02-01T16:24:45.792+0000] {processor.py:186} INFO - Started process (PID=1144) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:24:45.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:24:45.794+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:24:45.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:24:45.816+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:24:45.840+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:24:45.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:24:45.855+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:24:45.854+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:24:45.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.112 seconds
[2025-02-01T16:25:16.042+0000] {processor.py:186} INFO - Started process (PID=1149) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:25:16.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:25:16.044+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:25:16.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:25:16.060+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:25:16.083+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:25:16.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:25:16.096+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:25:16.096+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:25:16.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T16:25:46.232+0000] {processor.py:186} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:25:46.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:25:46.233+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:25:46.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:25:46.250+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:25:46.270+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:25:46.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:25:46.283+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:25:46.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:25:46.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T16:26:16.450+0000] {processor.py:186} INFO - Started process (PID=1159) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:26:16.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:26:16.452+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:26:16.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:26:16.469+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:26:16.490+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:26:16.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:26:16.503+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:26:16.503+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:26:16.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T16:26:46.642+0000] {processor.py:186} INFO - Started process (PID=1164) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:26:46.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:26:46.644+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:26:46.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:26:46.662+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:26:46.684+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:26:46.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:26:46.696+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:26:46.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:26:46.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T16:27:16.888+0000] {processor.py:186} INFO - Started process (PID=1169) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:27:16.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:27:16.890+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:27:16.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:27:16.909+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:27:16.932+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:27:16.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:27:16.945+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:27:16.945+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:27:16.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T16:27:47.081+0000] {processor.py:186} INFO - Started process (PID=1174) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:27:47.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:27:47.082+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:27:47.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:27:47.098+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:27:47.120+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:27:47.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:27:47.133+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:27:47.133+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:27:47.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.095 seconds
[2025-02-01T16:28:17.319+0000] {processor.py:186} INFO - Started process (PID=1179) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:28:17.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:28:17.321+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:28:17.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:28:17.338+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:28:17.358+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:28:17.358+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:28:17.372+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:28:17.371+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:28:17.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T16:28:47.511+0000] {processor.py:186} INFO - Started process (PID=1184) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:28:47.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:28:47.513+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:28:47.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:28:47.529+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:28:47.553+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:28:47.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:28:47.566+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:28:47.566+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:28:47.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.123 seconds
[2025-02-01T16:29:17.751+0000] {processor.py:186} INFO - Started process (PID=1189) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:29:17.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:29:17.753+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:29:17.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:29:17.771+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:29:17.792+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:29:17.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:29:17.806+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:29:17.805+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:29:17.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T16:29:47.972+0000] {processor.py:186} INFO - Started process (PID=1194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:29:47.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:29:47.974+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:29:47.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:29:47.991+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:29:48.012+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:29:48.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:29:48.025+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:29:48.024+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:29:48.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.120 seconds
[2025-02-01T16:30:18.188+0000] {processor.py:186} INFO - Started process (PID=1199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:30:18.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:30:18.190+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:30:18.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:30:18.206+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:30:18.228+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:30:18.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:30:18.241+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:30:18.241+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:30:18.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T16:30:48.435+0000] {processor.py:186} INFO - Started process (PID=1204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:30:48.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:30:48.437+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:30:48.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:30:48.454+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:30:48.474+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:30:48.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:30:48.487+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:30:48.487+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:30:48.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T16:31:18.619+0000] {processor.py:186} INFO - Started process (PID=1209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:31:18.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:31:18.621+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:31:18.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:31:18.638+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:31:18.659+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:31:18.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:31:18.671+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:31:18.671+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:31:18.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T16:31:48.845+0000] {processor.py:186} INFO - Started process (PID=1214) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:31:48.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:31:48.847+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:31:48.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:31:48.865+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:31:48.887+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:31:48.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:31:48.902+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:31:48.902+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:31:48.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.091 seconds
[2025-02-01T16:32:19.027+0000] {processor.py:186} INFO - Started process (PID=1219) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:32:19.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:32:19.029+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:32:19.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:32:19.046+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:32:19.067+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:32:19.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:32:19.080+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:32:19.079+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:32:19.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T16:32:49.269+0000] {processor.py:186} INFO - Started process (PID=1224) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:32:49.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:32:49.271+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:32:49.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:32:49.287+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:32:49.308+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:32:49.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:32:49.320+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:32:49.320+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:32:49.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T16:33:19.453+0000] {processor.py:186} INFO - Started process (PID=1229) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:33:19.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:33:19.456+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:33:19.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:33:19.473+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:33:19.495+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:33:19.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:33:19.508+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:33:19.508+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:33:19.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T16:33:49.696+0000] {processor.py:186} INFO - Started process (PID=1234) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:33:49.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:33:49.698+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:33:49.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:33:49.716+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:33:49.739+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:33:49.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:33:49.753+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:33:49.753+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:33:49.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T16:35:25.911+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:35:25.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:35:25.915+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:25.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:35:25.932+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:35:26.050+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.049+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T16:35:26.059+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.058+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T16:35:26.067+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.067+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T16:35:26.075+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.075+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T16:35:26.081+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.080+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T16:35:26.086+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.085+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T16:35:26.091+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.090+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T16:35:26.091+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:35:26.102+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.101+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T16:35:26.102+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:26.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:35:26.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.212 seconds
[2025-02-01T16:35:56.295+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:35:56.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:35:56.298+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:56.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:35:56.316+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:35:56.338+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:56.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:35:56.352+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:35:56.352+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:35:56.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T16:36:26.477+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:36:26.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:36:26.480+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:36:26.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:36:26.498+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:36:26.521+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:36:26.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:36:26.536+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:36:26.536+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:36:26.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.082 seconds
[2025-02-01T16:36:56.748+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:36:56.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:36:56.750+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:36:56.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:36:56.768+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:36:56.790+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:36:56.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:36:56.804+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:36:56.803+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:36:56.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T16:37:26.938+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:37:26.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:37:26.941+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:37:26.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:37:26.960+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:37:26.984+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:37:26.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:37:26.999+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:37:26.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:37:27.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T16:37:57.168+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:37:57.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:37:57.171+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:37:57.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:37:57.190+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:37:57.213+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:37:57.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:37:57.226+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:37:57.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:37:57.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T16:38:15.315+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:15.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:38:15.317+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:15.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:15.344+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:15.372+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:15.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:38:15.386+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:15.386+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:38:15.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.124 seconds
[2025-02-01T16:38:17.500+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:17.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:38:17.504+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:17.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:17.529+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:17.524+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/host/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:38:17.529+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:17.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.054 seconds
[2025-02-01T16:38:26.559+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:26.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:38:26.562+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:26.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:26.585+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:26.581+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:38:26.586+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:26.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T16:38:56.811+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:56.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:38:56.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:56.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:56.828+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:38:56.824+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:38:56.829+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:38:56.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.038 seconds
[2025-02-01T16:39:06.931+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:06.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:39:06.934+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:06.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:06.954+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:06.950+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/host/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:39:06.955+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:06.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.045 seconds
[2025-02-01T16:39:12.968+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:12.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:39:12.971+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:12.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:12.991+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:12.987+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:39:12.992+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:13.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.067 seconds
[2025-02-01T16:39:14.045+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:14.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:39:14.049+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:14.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:14.073+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:14.068+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:39:14.074+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:14.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.050 seconds
[2025-02-01T16:39:44.259+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:44.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:39:44.261+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:44.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:44.276+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:44.272+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:39:44.277+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:44.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.039 seconds
[2025-02-01T16:39:55.337+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:55.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:39:55.339+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:55.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:55.360+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:55.356+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/host/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:39:55.361+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:55.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T16:39:59.405+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:59.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:39:59.407+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:59.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:59.428+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:39:59.424+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:39:59.429+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:39:59.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T16:40:00.443+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:40:00.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:40:00.446+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:40:00.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:40:00.463+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:40:00.458+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:40:00.465+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:40:00.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.050 seconds
[2025-02-01T16:40:30.679+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:40:30.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:40:30.682+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:40:30.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:40:30.698+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:40:30.694+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:40:30.699+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:40:30.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.066 seconds
[2025-02-01T16:41:00.866+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:00.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:41:00.868+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:41:00.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:00.883+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:41:00.879+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:41:00.884+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:00.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.039 seconds
[2025-02-01T16:41:29.091+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:29.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:41:29.093+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:41:29.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:29.116+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:41:29.111+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/home/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:41:29.117+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:29.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.047 seconds
[2025-02-01T16:41:33.132+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:33.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:41:33.134+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:41:33.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:33.158+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:41:33.153+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/home/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:41:33.159+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:41:33.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.048 seconds
[2025-02-01T16:42:00.355+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:00.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:42:00.357+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:00.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:00.382+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:00.377+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volume': ['/home/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:42:00.383+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:00.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T16:42:08.419+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:08.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:42:08.421+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:08.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:08.444+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:08.439+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/home/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:42:08.445+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:08.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T16:42:21.589+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:21.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:42:21.591+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:21.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:21.616+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:21.612+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/bitnami/spark/jobs']}
[2025-02-01T16:42:21.617+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:21.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.049 seconds
[2025-02-01T16:42:35.686+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:35.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:42:35.688+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:35.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:35.710+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:35.705+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/home/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T16:42:35.711+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:35.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T16:42:37.769+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:37.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:42:37.772+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:37.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:37.802+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:42:38.080+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:38.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:42:38.092+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:42:38.092+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:42:38.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.354 seconds
[2025-02-01T16:43:08.314+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:08.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:43:08.316+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:08.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:08.334+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:08.496+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:08.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:43:08.509+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:08.509+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:43:08.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.221 seconds
[2025-02-01T16:43:38.720+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:38.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:43:38.722+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:38.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:38.742+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:38.770+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:38.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:43:38.785+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:38.785+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:43:38.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.117 seconds
[2025-02-01T16:43:57.829+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:57.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:43:57.831+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:57.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:57.854+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:43:57.877+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:57.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:43:57.890+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:43:57.889+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:43:57.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T16:44:28.137+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:44:28.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:44:28.139+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:44:28.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:44:28.156+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:44:28.178+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:44:28.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:44:28.191+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:44:28.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:44:28.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T16:44:58.322+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:44:58.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:44:58.324+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:44:58.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:44:58.343+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:44:58.366+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:44:58.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:44:58.522+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:44:58.522+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:44:58.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.221 seconds
[2025-02-01T16:45:14.487+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:14.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:45:14.489+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:14.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:14.512+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:14.507+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    dag = DAG(**kwargs)
                ^^^^^^
NameError: name 'kwargs' is not defined
[2025-02-01T16:45:14.515+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:14.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.048 seconds
[2025-02-01T16:45:28.598+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:28.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:45:28.600+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:28.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:28.623+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:28.644+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:28.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:45:28.798+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:28.798+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:45:28.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.223 seconds
[2025-02-01T16:45:29.864+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:29.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:45:29.866+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:29.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:29.891+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:29.912+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:29.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:45:30.054+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:30.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:45:30.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.215 seconds
[2025-02-01T16:45:41.179+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:41.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:45:41.182+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:41.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:41.212+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:45:41.401+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:41.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:45:41.415+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:45:41.415+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:45:41.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.266 seconds
[2025-02-01T16:46:11.627+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:46:11.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:46:11.629+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:46:11.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:46:11.651+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:46:11.676+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:46:11.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:46:11.689+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:46:11.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:46:11.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T16:46:41.800+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:46:41.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:46:41.802+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:46:41.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:46:41.819+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:46:41.841+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:46:41.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:46:41.854+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:46:41.854+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:46:41.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.109 seconds
[2025-02-01T16:47:12.055+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:47:12.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:47:12.058+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:47:12.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:47:12.082+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:47:12.108+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:47:12.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:47:12.123+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:47:12.123+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:47:12.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T16:47:42.235+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:47:42.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:47:42.237+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:47:42.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:47:42.253+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:47:42.275+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:47:42.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:47:42.288+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:47:42.288+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:47:42.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.235 seconds
[2025-02-01T16:48:12.650+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:48:12.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:48:12.652+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:48:12.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:48:12.671+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:48:12.695+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:48:12.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:48:12.848+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:48:12.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:48:12.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.242 seconds
[2025-02-01T16:48:43.069+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:48:43.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:48:43.070+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:48:43.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:48:43.086+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:48:43.241+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:48:43.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:48:43.252+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:48:43.252+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:48:43.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.205 seconds
[2025-02-01T16:49:45.862+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:49:45.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:49:45.867+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:49:45.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:49:45.887+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:49:45.928+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:49:45.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:49:45.943+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:49:45.942+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:49:45.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.108 seconds
[2025-02-01T16:50:16.069+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:16.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:50:16.072+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:16.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:16.092+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:16.115+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:16.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:50:16.129+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:16.129+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:50:16.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.107 seconds
[2025-02-01T16:50:46.300+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:46.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:50:46.303+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:46.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:46.320+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:46.342+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:46.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:50:46.355+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:46.354+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:50:46.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T16:50:47.343+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:47.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:50:47.345+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:47.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:47.368+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:50:47.389+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:47.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:50:47.403+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:50:47.403+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:50:47.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.112 seconds
[2025-02-01T16:51:17.608+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:51:17.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:51:17.610+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:51:17.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:51:17.627+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:51:17.648+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:51:17.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:51:17.660+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:51:17.660+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:51:17.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T16:51:47.796+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:51:47.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:51:47.799+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:51:47.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:51:47.815+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:51:47.837+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:51:47.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:51:47.850+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:51:47.850+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:51:47.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T16:52:18.046+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:18.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:52:18.048+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:18.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:18.064+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:18.086+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:18.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:52:18.098+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:18.098+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:52:18.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.123 seconds
[2025-02-01T16:52:23.100+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:23.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:52:23.102+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:23.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:23.125+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:23.376+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:23.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:52:23.387+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:23.386+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:52:23.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.308 seconds
[2025-02-01T16:52:24.232+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:24.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:52:24.236+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:24.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:24.261+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:24.271+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:24.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:52:24.284+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:24.284+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:52:24.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T16:52:54.407+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:54.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:52:54.409+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:54.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:54.426+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:52:54.450+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:54.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:52:54.462+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:52:54.462+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:52:54.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T16:53:24.652+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:53:24.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:53:24.654+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:53:24.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:53:24.672+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:53:24.693+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:53:24.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:53:24.706+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:53:24.706+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:53:24.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.265 seconds
[2025-02-01T16:53:55.095+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:53:55.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:53:55.098+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:53:55.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:53:55.114+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:53:55.137+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:53:55.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:53:55.287+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:53:55.287+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:53:55.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.212 seconds
[2025-02-01T16:54:25.491+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:54:25.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:54:25.494+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:54:25.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:54:25.513+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:54:25.537+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:54:25.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:54:25.717+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:54:25.716+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:54:25.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.253 seconds
[2025-02-01T16:54:55.925+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:54:55.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:54:55.927+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:54:55.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:54:55.943+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:54:55.966+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:54:55.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:54:55.978+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:54:55.978+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:54:55.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T16:55:26.107+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:55:26.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:55:26.110+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:55:26.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:55:26.129+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:55:26.153+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:55:26.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:55:26.166+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:55:26.166+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:55:26.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.107 seconds
[2025-02-01T16:55:56.336+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:55:56.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:55:56.339+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:55:56.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:55:56.355+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:55:56.376+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:55:56.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:55:56.388+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:55:56.388+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:55:56.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T16:56:26.563+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:26.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:56:26.566+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:26.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:26.588+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:26.612+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:26.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:56:26.627+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:26.627+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:56:26.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.231 seconds
[2025-02-01T16:56:33.873+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:33.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:56:33.875+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:33.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:33.888+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:33.887+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 30
    auto
    ^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-02-01T16:56:33.888+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:33.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.036 seconds
[2025-02-01T16:56:36.913+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:36.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:56:36.918+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:36.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:36.938+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:36.936+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 30
    auto_remove=True
                
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-02-01T16:56:36.939+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:36.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.053 seconds
[2025-02-01T16:56:39.989+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:39.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:56:39.992+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:39.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:40.020+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:56:40.052+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:40.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:56:40.214+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:56:40.214+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:56:40.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.251 seconds
[2025-02-01T16:57:10.426+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:57:10.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:57:10.428+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:57:10.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:57:10.446+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:57:10.467+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:57:10.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:57:10.605+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:57:10.604+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:57:10.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.222 seconds
[2025-02-01T16:57:40.828+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:57:40.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:57:40.831+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:57:40.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:57:40.848+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:57:40.870+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:57:40.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:57:40.883+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:57:40.883+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:57:40.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T16:58:11.007+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:58:11.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:58:11.010+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:58:11.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:58:11.028+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:58:11.049+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:58:11.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:58:11.062+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:58:11.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:58:11.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T16:58:41.266+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:58:41.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:58:41.269+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:58:41.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:58:41.287+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:58:41.310+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:58:41.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:58:41.323+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:58:41.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:58:41.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T16:59:11.442+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:59:11.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:59:11.445+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:59:11.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:59:11.461+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:59:11.483+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:59:11.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:59:11.496+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:59:11.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:59:11.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.208 seconds
[2025-02-01T16:59:41.826+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:59:41.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T16:59:41.829+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:59:41.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:59:41.848+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T16:59:41.872+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:59:41.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T16:59:42.035+0000] {logging_mixin.py:190} INFO - [2025-02-01T16:59:42.035+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T16:59:42.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.256 seconds
[2025-02-01T17:00:12.284+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:00:12.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:00:12.287+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:00:12.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:00:12.309+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:00:12.470+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:00:12.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:00:12.481+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:00:12.481+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:00:12.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.243 seconds
[2025-02-01T17:00:42.682+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:00:42.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:00:42.685+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:00:42.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:00:42.702+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:00:42.723+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:00:42.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:00:42.736+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:00:42.736+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:00:42.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T17:01:00.805+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:00.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:01:00.808+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:00.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:00.851+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:00.823+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 22, in <module>
    api_version=auto,
                ^^^^
NameError: name 'auto' is not defined
[2025-02-01T17:01:00.853+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:00.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.067 seconds
[2025-02-01T17:01:06.915+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:06.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:01:06.917+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:06.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:06.927+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:06.927+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 22
    api_version='auto,
                ^
SyntaxError: unterminated string literal (detected at line 22)
[2025-02-01T17:01:06.928+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:06.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.032 seconds
[2025-02-01T17:01:08.957+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:08.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:01:08.960+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:08.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:08.988+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:09.013+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:09.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:01:09.028+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:09.027+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:01:09.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.125 seconds
[2025-02-01T17:01:39.155+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:39.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:01:39.158+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:39.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:39.174+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:01:39.198+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:39.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:01:39.211+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:01:39.210+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:01:39.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T17:02:09.416+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:09.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:02:09.418+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:09.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:09.434+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:09.456+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:09.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:02:09.469+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:09.468+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:02:09.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.200 seconds
[2025-02-01T17:02:39.785+0000] {processor.py:186} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:39.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:02:39.787+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:39.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:39.804+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:39.826+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:39.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:02:39.968+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:39.968+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:02:39.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.202 seconds
[2025-02-01T17:02:44.826+0000] {processor.py:186} INFO - Started process (PID=375) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:44.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:02:44.828+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:44.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:44.852+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:02:44.874+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:44.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:02:45.013+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:02:45.013+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:02:45.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.208 seconds
[2025-02-01T17:03:15.220+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:03:15.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:03:15.222+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:03:15.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:03:15.239+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:03:15.384+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:03:15.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:03:15.395+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:03:15.394+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:03:15.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.195 seconds
[2025-02-01T17:03:45.591+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:03:45.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:03:45.594+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:03:45.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:03:45.610+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:03:45.632+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:03:45.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:03:45.645+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:03:45.645+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:03:45.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T17:04:15.762+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:15.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:04:15.765+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:15.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:15.783+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:15.806+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:15.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:04:15.819+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:15.818+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:04:15.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T17:04:37.977+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:37.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:04:37.980+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:37.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:38.007+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:38.307+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:38.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:04:38.318+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:38.318+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:04:38.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.369 seconds
[2025-02-01T17:04:47.076+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:47.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:04:47.079+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:47.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:47.103+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:47.114+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:47.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:04:47.128+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:47.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:04:47.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T17:04:48.090+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:48.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:04:48.092+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:48.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:48.117+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:48.128+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:48.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:04:48.143+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:48.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:04:48.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T17:04:59.258+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:59.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:04:59.260+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:59.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:59.286+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:04:59.296+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:59.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:04:59.308+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:04:59.308+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:04:59.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.118 seconds
[2025-02-01T17:05:29.436+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:05:29.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:05:29.439+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:05:29.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:05:29.457+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:05:29.696+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:05:29.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:05:29.707+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:05:29.707+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:05:29.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.293 seconds
[2025-02-01T17:05:59.921+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:05:59.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:05:59.924+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:05:59.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:05:59.944+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:06:00.107+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:06:00.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:06:00.120+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:06:00.120+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:06:00.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.246 seconds
[2025-02-01T17:30:20.781+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:30:20.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:30:20.785+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:30:20.811+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:30:20.943+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.942+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T17:30:20.952+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.951+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T17:30:20.957+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.957+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T17:30:20.966+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.966+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T17:30:20.972+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.972+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T17:30:20.981+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.981+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T17:30:20.990+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.990+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T17:30:20.991+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:20.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:30:21.003+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:21.003+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T17:30:21.004+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:21.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:30:21.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.245 seconds
[2025-02-01T17:30:51.206+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:30:51.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:30:51.208+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:51.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:30:51.225+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:30:51.247+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:51.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:30:51.259+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:30:51.259+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:30:51.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T17:31:21.378+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:31:21.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:31:21.382+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:31:21.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:31:21.407+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:31:21.437+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:31:21.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:31:21.456+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:31:21.456+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:31:21.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.115 seconds
[2025-02-01T17:33:34.485+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:33:34.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:33:34.490+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:33:34.507+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:33:34.614+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.613+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T17:33:34.623+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.622+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T17:33:34.629+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.629+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T17:33:34.635+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.635+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T17:33:34.641+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.641+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T17:33:34.647+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.646+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T17:33:34.653+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.652+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T17:33:34.653+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:33:34.664+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.664+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T17:33:34.665+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:33:34.665+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:33:34.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.202 seconds
[2025-02-01T17:34:04.857+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:34:04.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:34:04.859+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:34:04.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:34:04.875+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:34:04.899+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:34:04.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:34:04.911+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:34:04.911+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:34:04.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T17:34:35.028+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:34:35.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:34:35.030+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:34:35.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:34:35.047+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:34:35.068+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:34:35.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:34:35.082+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:34:35.082+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:34:35.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T17:35:05.263+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:35:05.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:35:05.266+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:35:05.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:35:05.285+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:35:05.308+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:35:05.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:35:05.322+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:35:05.322+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:35:05.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T17:36:22.743+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:36:22.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:36:22.748+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:36:22.767+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:36:22.892+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.891+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T17:36:22.901+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.901+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T17:36:22.907+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.907+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T17:36:22.914+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.914+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T17:36:22.920+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.919+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T17:36:22.926+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.925+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T17:36:22.932+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.932+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T17:36:22.933+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:36:22.945+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.945+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T17:36:22.946+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:22.946+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:36:22.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.225 seconds
[2025-02-01T17:36:53.152+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:36:53.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:36:53.155+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:53.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:36:53.173+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:36:53.196+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:53.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:36:53.209+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:36:53.209+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:36:53.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T17:37:23.331+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:37:23.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:37:23.334+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:37:23.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:37:23.354+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:37:23.378+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:37:23.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:37:23.393+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:37:23.392+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:37:23.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.108 seconds
[2025-02-01T17:37:53.571+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:37:53.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:37:53.574+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:37:53.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:37:53.593+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:37:53.616+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:37:53.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:37:53.630+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:37:53.630+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:37:53.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T17:40:21.887+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:40:21.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:40:21.892+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:40:21.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:40:21.912+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:40:21.908+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T17:40:21.913+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:40:21.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T17:41:44.980+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:41:44.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:41:44.983+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:41:44.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:41:44.999+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:41:44.995+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T17:41:45.000+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:41:45.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T17:42:15.162+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:42:15.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:42:15.165+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:42:15.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:42:15.180+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:42:15.176+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T17:42:15.181+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:42:15.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T17:42:45.349+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:42:45.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:42:45.352+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:42:45.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:42:45.367+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:42:45.363+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T17:42:45.368+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:42:45.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.039 seconds
[2025-02-01T17:43:15.534+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:15.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:43:15.537+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:15.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:15.551+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:15.548+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T17:43:15.552+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:15.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.038 seconds
[2025-02-01T17:43:33.658+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:33.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:43:33.661+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:33.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:33.674+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:33.673+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    volumes=[//mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs"],  # Example: Ubuntu WSL, D: drive
                                                                               ^
SyntaxError: unterminated string literal (detected at line 29)
[2025-02-01T17:43:33.675+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:33.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.039 seconds
[2025-02-01T17:43:34.697+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:34.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:43:34.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:34.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:34.712+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:34.711+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    volumes=[/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs"],  # Example: Ubuntu WSL, D: drive
                                                                              ^
SyntaxError: unterminated string literal (detected at line 29)
[2025-02-01T17:43:34.712+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:34.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T17:43:36.754+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:36.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:43:36.757+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:36.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:36.768+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:36.767+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    volumes=['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs"],  # Example: Ubuntu WSL, D: drive
             ^
SyntaxError: unterminated string literal (detected at line 29)
[2025-02-01T17:43:36.768+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:36.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.038 seconds
[2025-02-01T17:43:41.807+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:41.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:43:41.810+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:41.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:41.831+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:41.827+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T17:43:41.832+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:41.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.045 seconds
[2025-02-01T17:43:42.851+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:42.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:43:42.853+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:42.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:42.875+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:42.871+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T17:43:42.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:42.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T17:43:55.977+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:55.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:43:55.980+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:55.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:56.005+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:43:56.293+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.293+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T17:43:56.302+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.302+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T17:43:56.309+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.308+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T17:43:56.315+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.314+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T17:43:56.322+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.321+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T17:43:56.327+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.327+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T17:43:56.332+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.332+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T17:43:56.332+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:43:56.343+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.343+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T17:43:56.343+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:43:56.343+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:43:56.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.386 seconds
[2025-02-01T17:44:26.537+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:44:26.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:44:26.539+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:44:26.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:44:26.556+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:44:26.579+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:44:26.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:44:26.591+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:44:26.591+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:44:26.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T17:44:56.712+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:44:56.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:44:56.715+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:44:56.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:44:56.731+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:44:56.752+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:44:56.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:44:56.764+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:44:56.764+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:44:56.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T17:45:26.941+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:45:26.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:45:26.944+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:45:26.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:45:26.960+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:45:26.981+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:45:26.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:45:26.994+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:45:26.994+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:45:27.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.231 seconds
[2025-02-01T17:45:57.338+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:45:57.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:45:57.340+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:45:57.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:45:57.356+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:45:57.378+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:45:57.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:45:57.532+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:45:57.531+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:45:57.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.238 seconds
[2025-02-01T17:46:27.747+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:46:27.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:46:27.749+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:46:27.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:46:27.766+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:46:27.928+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:46:27.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:46:27.939+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:46:27.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:46:27.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.211 seconds
[2025-02-01T17:46:58.129+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:46:58.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:46:58.132+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:46:58.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:46:58.150+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:46:58.173+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:46:58.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:46:58.186+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:46:58.186+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:46:58.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T17:47:04.184+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:47:04.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:47:04.186+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:47:04.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:47:04.211+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:47:04.234+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:47:04.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:47:04.247+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:47:04.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:47:04.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T17:47:34.431+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:47:34.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:47:34.434+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:47:34.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:47:34.454+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:47:34.479+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:47:34.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:47:34.493+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:47:34.493+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:47:34.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T17:48:04.617+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:48:04.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:48:04.621+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:48:04.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:48:04.642+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:48:04.666+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:48:04.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:48:04.680+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:48:04.680+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:48:04.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T17:48:34.862+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:48:34.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:48:34.866+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:48:34.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:48:34.885+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:48:34.909+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:48:34.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:48:35.063+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:48:35.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:48:35.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.222 seconds
[2025-02-01T17:49:05.261+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:49:05.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:49:05.264+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:49:05.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:49:05.280+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:49:05.301+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:49:05.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:49:05.445+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:49:05.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:49:05.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.204 seconds
[2025-02-01T17:49:35.640+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:49:35.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:49:35.643+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:49:35.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:49:35.661+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:49:35.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:49:35.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:49:35.824+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:49:35.824+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:49:35.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.205 seconds
[2025-02-01T17:50:06.022+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:50:06.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:50:06.025+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:50:06.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:50:06.042+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:50:06.065+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:50:06.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:50:06.078+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:50:06.078+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:50:06.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.137 seconds
[2025-02-01T17:50:36.198+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:50:36.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:50:36.200+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:50:36.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:50:36.216+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:50:36.239+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:50:36.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:50:36.252+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:50:36.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:50:36.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T17:51:06.371+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:51:06.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:51:06.374+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:51:06.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:51:06.391+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:51:06.415+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:51:06.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:51:06.428+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:51:06.427+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:51:06.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.218 seconds
[2025-02-01T17:51:36.634+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:51:36.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:51:36.636+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:51:36.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:51:36.653+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:51:36.675+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:51:36.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:51:36.819+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:51:36.819+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:51:36.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.205 seconds
[2025-02-01T17:52:06.929+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:52:06.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:52:06.931+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:52:06.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:52:06.954+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:52:07.109+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:52:07.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:52:07.120+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:52:07.119+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:52:07.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.215 seconds
[2025-02-01T17:52:37.197+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:52:37.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:52:37.200+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:52:37.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:52:37.217+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:52:37.240+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:52:37.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:52:37.253+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:52:37.253+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:52:37.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T17:53:07.365+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:53:07.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:53:07.368+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:53:07.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:53:07.384+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:53:07.406+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:53:07.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:53:07.419+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:53:07.418+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:53:07.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T17:53:37.599+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:53:37.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:53:37.602+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:53:37.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:53:37.618+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:53:37.639+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:53:37.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:53:37.651+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:53:37.651+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:53:37.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T17:54:07.775+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:54:07.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:54:07.777+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:54:07.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:54:07.794+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:54:07.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:54:07.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:54:07.827+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:54:07.827+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:54:08.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.231 seconds
[2025-02-01T17:54:38.178+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:54:38.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:54:38.180+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:54:38.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:54:38.196+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:54:38.217+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:54:38.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:54:38.354+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:54:38.353+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:54:38.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.194 seconds
[2025-02-01T17:55:08.548+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:55:08.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:55:08.551+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:55:08.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:55:08.569+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:55:08.733+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:55:08.732+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:55:08.743+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:55:08.743+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:55:08.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.240 seconds
[2025-02-01T17:55:38.962+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:55:38.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:55:38.965+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:55:38.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:55:38.983+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:55:39.005+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:55:39.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:55:39.017+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:55:39.017+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:55:39.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T17:56:09.135+0000] {processor.py:186} INFO - Started process (PID=370) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:56:09.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:56:09.138+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:56:09.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:56:09.154+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:56:09.175+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:56:09.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:56:09.187+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:56:09.187+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:56:09.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T17:56:39.367+0000] {processor.py:186} INFO - Started process (PID=375) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:56:39.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:56:39.370+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:56:39.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:56:39.387+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:56:39.409+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:56:39.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:56:39.422+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:56:39.421+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:56:39.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T17:57:09.581+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:57:09.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:57:09.586+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:57:09.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:57:09.613+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:57:09.640+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:57:09.640+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:57:09.835+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:57:09.835+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:57:09.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.279 seconds
[2025-02-01T17:57:40.030+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:57:40.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:57:40.033+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:57:40.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:57:40.048+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:57:40.070+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:57:40.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:57:40.222+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:57:40.222+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:57:40.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.213 seconds
[2025-02-01T17:58:10.406+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:58:10.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:58:10.409+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:58:10.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:58:10.425+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:58:10.569+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:58:10.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:58:10.580+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:58:10.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:58:10.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.191 seconds
[2025-02-01T17:58:40.772+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:58:40.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:58:40.775+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:58:40.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:58:40.793+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:58:40.822+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:58:40.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:58:40.836+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:58:40.836+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:58:40.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.091 seconds
[2025-02-01T17:59:10.943+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:59:10.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:59:10.945+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:59:10.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:59:10.962+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:59:10.983+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:59:10.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:59:10.995+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:59:10.995+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:59:11.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T17:59:41.193+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:59:41.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T17:59:41.195+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:59:41.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:59:41.212+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T17:59:41.232+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:59:41.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T17:59:41.245+0000] {logging_mixin.py:190} INFO - [2025-02-01T17:59:41.245+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T17:59:41.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.200 seconds
[2025-02-01T18:00:11.572+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:00:11.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:00:11.574+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:00:11.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:00:11.590+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:00:11.613+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:00:11.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:00:11.750+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:00:11.750+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:00:11.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.196 seconds
[2025-02-01T18:00:41.940+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:00:41.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:00:41.943+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:00:41.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:00:41.959+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:00:42.107+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:00:42.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:00:42.118+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:00:42.118+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:00:42.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.198 seconds
[2025-02-01T18:01:12.309+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:01:12.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:01:12.311+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:01:12.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:01:12.453+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:01:12.471+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:01:12.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:01:12.482+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:01:12.482+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:01:12.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.191 seconds
[2025-02-01T18:01:42.671+0000] {processor.py:186} INFO - Started process (PID=425) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:01:42.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:01:42.674+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:01:42.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:01:42.691+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:01:42.713+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:01:42.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:01:42.725+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:01:42.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:01:42.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T18:02:12.875+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:02:12.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:02:12.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:02:12.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:02:12.894+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:02:12.914+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:02:12.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:02:12.926+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:02:12.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:02:12.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T18:02:43.075+0000] {processor.py:186} INFO - Started process (PID=435) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:02:43.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:02:43.078+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:02:43.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:02:43.094+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:02:43.114+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:02:43.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:02:43.127+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:02:43.127+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:02:43.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.201 seconds
[2025-02-01T18:03:13.442+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:03:13.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:03:13.445+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:03:13.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:03:13.464+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:03:13.487+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:03:13.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:03:13.639+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:03:13.638+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:03:13.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.218 seconds
[2025-02-01T18:03:43.849+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:03:43.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:03:43.851+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:03:43.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:03:43.870+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:03:44.033+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:03:44.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:03:44.044+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:03:44.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:03:44.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.217 seconds
[2025-02-01T18:04:14.251+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:04:14.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:04:14.253+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:04:14.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:04:14.270+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:04:14.291+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:04:14.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:04:14.307+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:04:14.306+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:04:14.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T18:04:44.430+0000] {processor.py:186} INFO - Started process (PID=455) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:04:44.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:04:44.433+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:04:44.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:04:44.449+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:04:44.471+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:04:44.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:04:44.483+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:04:44.482+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:04:44.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T18:05:14.650+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:05:14.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:05:14.653+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:05:14.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:05:14.671+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:05:14.694+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:05:14.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:05:14.707+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:05:14.707+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:05:14.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T18:05:44.812+0000] {processor.py:186} INFO - Started process (PID=465) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:05:44.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:05:44.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:05:44.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:05:44.831+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:05:44.854+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:05:44.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:05:45.013+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:05:45.013+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:05:45.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.222 seconds
[2025-02-01T18:06:15.216+0000] {processor.py:186} INFO - Started process (PID=470) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:06:15.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:06:15.218+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:06:15.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:06:15.239+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:06:15.275+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:06:15.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:06:15.416+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:06:15.415+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:06:15.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.227 seconds
[2025-02-01T18:06:45.619+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:06:45.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:06:45.623+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:06:45.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:06:45.639+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:06:45.790+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:06:45.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:06:45.802+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:06:45.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:06:45.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.204 seconds
[2025-02-01T18:07:15.923+0000] {processor.py:186} INFO - Started process (PID=480) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:07:15.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:07:15.925+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:07:15.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:07:15.943+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:07:15.964+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:07:15.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:07:15.976+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:07:15.976+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:07:16.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T18:07:46.203+0000] {processor.py:186} INFO - Started process (PID=485) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:07:46.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:07:46.206+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:07:46.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:07:46.222+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:07:46.243+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:07:46.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:07:46.255+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:07:46.255+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:07:46.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T18:08:16.393+0000] {processor.py:186} INFO - Started process (PID=490) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:08:16.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:08:16.395+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:08:16.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:08:16.412+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:08:16.434+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:08:16.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:08:16.448+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:08:16.447+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:08:16.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T18:08:46.652+0000] {processor.py:186} INFO - Started process (PID=495) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:08:46.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:08:46.655+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:08:46.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:08:46.673+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:08:46.695+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:08:46.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:08:46.710+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:08:46.709+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:08:46.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T18:09:16.871+0000] {processor.py:186} INFO - Started process (PID=500) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:09:16.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:09:16.874+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:09:16.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:09:16.895+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:09:16.919+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:09:16.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:09:16.932+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:09:16.931+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:09:16.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T18:09:47.142+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:09:47.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:09:47.146+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:09:47.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:09:47.164+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:09:47.186+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:09:47.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:09:47.200+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:09:47.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:09:47.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T18:10:17.339+0000] {processor.py:186} INFO - Started process (PID=510) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:10:17.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:10:17.342+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:10:17.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:10:17.362+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:10:17.387+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:10:17.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:10:17.401+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:10:17.401+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:10:17.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T18:10:47.610+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:10:47.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:10:47.613+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:10:47.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:10:47.632+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:10:47.657+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:10:47.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:10:47.678+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:10:47.677+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:10:47.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.159 seconds
[2025-02-01T18:11:17.956+0000] {processor.py:186} INFO - Started process (PID=520) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:11:17.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:11:17.958+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:11:17.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:11:17.979+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:11:18.003+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:11:18.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:11:18.017+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:11:18.017+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:11:18.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.107 seconds
[2025-02-01T18:11:48.180+0000] {processor.py:186} INFO - Started process (PID=525) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:11:48.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:11:48.183+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:11:48.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:11:48.202+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:11:48.228+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:11:48.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:11:48.243+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:11:48.242+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:11:48.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.120 seconds
[2025-02-01T18:12:18.419+0000] {processor.py:186} INFO - Started process (PID=530) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:12:18.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:12:18.421+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:12:18.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:12:18.439+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:12:18.462+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:12:18.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:12:18.475+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:12:18.475+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:12:18.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T18:12:48.662+0000] {processor.py:186} INFO - Started process (PID=535) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:12:48.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:12:48.665+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:12:48.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:12:48.682+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:12:48.704+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:12:48.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:12:48.717+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:12:48.717+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:12:48.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T18:13:18.862+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:13:18.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:13:18.865+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:13:18.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:13:18.890+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:13:18.919+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:13:18.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:13:18.932+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:13:18.932+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:13:18.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T18:13:49.102+0000] {processor.py:186} INFO - Started process (PID=545) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:13:49.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:13:49.106+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:13:49.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:13:49.125+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:13:49.150+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:13:49.149+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:13:49.164+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:13:49.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:13:49.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T18:14:19.323+0000] {processor.py:186} INFO - Started process (PID=550) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:14:19.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:14:19.326+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:14:19.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:14:19.345+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:14:19.368+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:14:19.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:14:19.381+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:14:19.381+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:14:19.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T18:14:49.555+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:14:49.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:14:49.558+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:14:49.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:14:49.578+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:14:49.604+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:14:49.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:14:49.620+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:14:49.620+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:14:49.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.095 seconds
[2025-02-01T18:15:19.781+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:15:19.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:15:19.786+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:15:19.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:15:19.812+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:15:19.841+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:15:19.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:15:19.850+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:15:19.849+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:15:19.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.111 seconds
[2025-02-01T18:15:49.974+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:15:49.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:15:49.977+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:15:49.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:15:49.998+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:15:50.025+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:15:50.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:15:50.040+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:15:50.040+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:15:50.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.094 seconds
[2025-02-01T18:16:20.184+0000] {processor.py:186} INFO - Started process (PID=570) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:16:20.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:16:20.187+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:16:20.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:16:20.212+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:16:20.243+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:16:20.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:16:20.256+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:16:20.256+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:16:20.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T18:16:50.437+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:16:50.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:16:50.439+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:16:50.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:16:50.456+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:16:50.477+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:16:50.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:16:50.490+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:16:50.490+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:16:50.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T18:17:20.638+0000] {processor.py:186} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:17:20.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:17:20.641+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:17:20.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:17:20.660+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:17:20.684+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:17:20.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:17:20.699+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:17:20.698+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:17:20.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T18:17:50.875+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:17:50.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:17:50.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:17:50.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:17:50.896+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:17:50.922+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:17:50.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:17:50.937+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:17:50.937+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:17:50.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T18:18:21.133+0000] {processor.py:186} INFO - Started process (PID=590) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:18:21.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:18:21.137+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:18:21.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:18:21.160+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:18:21.184+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:18:21.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:18:21.198+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:18:21.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:18:21.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T18:18:51.371+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:18:51.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:18:51.374+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:18:51.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:18:51.391+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:18:51.413+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:18:51.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:18:51.427+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:18:51.427+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:18:51.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T18:19:21.597+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:19:21.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:19:21.599+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:19:21.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:19:21.619+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:19:21.642+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:19:21.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:19:21.656+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:19:21.656+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:19:21.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T18:19:51.845+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:19:51.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:19:51.849+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:19:51.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:19:51.867+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:19:51.889+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:19:51.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:19:51.903+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:19:51.903+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:19:51.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T18:20:22.075+0000] {processor.py:186} INFO - Started process (PID=610) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:20:22.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:20:22.078+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:20:22.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:20:22.097+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:20:22.122+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:20:22.122+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:20:22.136+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:20:22.135+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:20:22.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T18:20:52.314+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:20:52.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:20:52.316+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:20:52.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:20:52.333+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:20:52.364+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:20:52.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:20:52.383+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:20:52.383+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:20:52.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T18:21:22.519+0000] {processor.py:186} INFO - Started process (PID=620) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:21:22.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:21:22.522+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:21:22.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:21:22.541+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:21:22.565+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:21:22.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:21:22.579+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:21:22.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:21:22.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T18:21:52.795+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:21:52.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:21:52.798+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:21:52.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:21:52.814+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:21:52.835+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:21:52.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:21:52.847+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:21:52.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:21:52.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T18:22:22.992+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:22:22.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:22:22.994+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:22:22.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:22:23.013+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:22:23.036+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:22:23.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:22:23.049+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:22:23.049+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:22:23.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T18:22:53.231+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:22:53.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:22:53.235+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:22:53.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:22:53.254+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:22:53.277+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:22:53.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:22:53.291+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:22:53.291+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:22:53.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T18:23:23.449+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:23:23.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:23:23.452+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:23:23.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:23:23.473+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:23:23.504+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:23:23.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:23:23.522+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:23:23.522+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:23:23.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T18:23:53.697+0000] {processor.py:186} INFO - Started process (PID=645) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:23:53.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:23:53.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:23:53.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:23:53.720+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:23:53.744+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:23:53.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:23:53.759+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:23:53.759+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:23:53.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.111 seconds
[2025-02-01T18:24:23.924+0000] {processor.py:186} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:24:23.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:24:23.927+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:24:23.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:24:23.948+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:24:23.975+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:24:23.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:24:23.991+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:24:23.990+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:24:24.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T18:24:54.167+0000] {processor.py:186} INFO - Started process (PID=655) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:24:54.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:24:54.169+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:24:54.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:24:54.186+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:24:54.207+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:24:54.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:24:54.219+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:24:54.219+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:24:54.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T18:25:24.372+0000] {processor.py:186} INFO - Started process (PID=660) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:25:24.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:25:24.374+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:25:24.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:25:24.390+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:25:24.412+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:25:24.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:25:24.427+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:25:24.426+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:25:24.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T18:25:54.613+0000] {processor.py:186} INFO - Started process (PID=665) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:25:54.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:25:54.616+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:25:54.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:25:54.636+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:25:54.661+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:25:54.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:25:54.677+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:25:54.676+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:25:54.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T18:26:24.819+0000] {processor.py:186} INFO - Started process (PID=670) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:26:24.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:26:24.822+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:26:24.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:26:24.840+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:26:24.862+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:26:24.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:26:24.874+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:26:24.874+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:26:24.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T18:26:55.115+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:26:55.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:26:55.119+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:26:55.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:26:55.136+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:26:55.156+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:26:55.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:26:55.168+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:26:55.168+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:26:55.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T18:27:25.312+0000] {processor.py:186} INFO - Started process (PID=680) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:27:25.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:27:25.314+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:27:25.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:27:25.331+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:27:25.353+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:27:25.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:27:25.366+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:27:25.365+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:27:25.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T18:27:55.573+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:27:55.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:27:55.575+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:27:55.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:27:55.594+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:27:55.618+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:27:55.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:27:55.632+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:27:55.631+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:27:55.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T18:39:10.310+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:39:10.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:39:10.314+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:39:10.339+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:39:10.454+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.454+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T18:39:10.463+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.462+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T18:39:10.468+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.468+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T18:39:10.474+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.474+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T18:39:10.479+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.479+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T18:39:10.484+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.484+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T18:39:10.489+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.489+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T18:39:10.490+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:39:10.501+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.501+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T18:39:10.502+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:10.502+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:39:10.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.211 seconds
[2025-02-01T18:39:40.730+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:39:40.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:39:40.733+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:40.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:39:40.767+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:39:40.793+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:40.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:39:40.808+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:39:40.807+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:39:40.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.104 seconds
[2025-02-01T18:40:10.932+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:40:10.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:40:10.935+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:40:10.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:40:10.952+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:40:10.977+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:40:10.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:40:10.991+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:40:10.991+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:40:11.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T18:40:41.136+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:40:41.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:40:41.141+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:40:41.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:40:41.170+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:40:41.199+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:40:41.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:40:41.216+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:40:41.216+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:40:41.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.108 seconds
[2025-02-01T18:41:11.369+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:41:11.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:41:11.371+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:41:11.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:41:11.388+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:41:11.411+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:41:11.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:41:11.423+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:41:11.423+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:41:11.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T18:41:41.582+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:41:41.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:41:41.585+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:41:41.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:41:41.601+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:41:41.623+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:41:41.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:41:41.635+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:41:41.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:41:41.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T18:42:11.831+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:42:11.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:42:11.833+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:42:11.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:42:11.850+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:42:11.873+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:42:11.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:42:11.886+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:42:11.886+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:42:11.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T18:42:42.034+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:42:42.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:42:42.037+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:42:42.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:42:42.053+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:42:42.074+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:42:42.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:42:42.086+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:42:42.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:42:42.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T18:43:12.297+0000] {processor.py:186} INFO - Started process (PID=239) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:43:12.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:43:12.299+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:43:12.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:43:12.316+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:43:12.338+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:43:12.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:43:12.490+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:43:12.490+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:43:12.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.214 seconds
[2025-02-01T18:43:42.707+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:43:42.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:43:42.710+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:43:42.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:43:42.730+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:43:42.755+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:43:42.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:43:42.914+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:43:42.913+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:43:42.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.231 seconds
[2025-02-01T18:44:13.179+0000] {processor.py:186} INFO - Started process (PID=249) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:44:13.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:44:13.182+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:44:13.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:44:13.202+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:44:13.228+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:44:13.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:44:13.242+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:44:13.242+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:44:13.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T18:44:43.372+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:44:43.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:44:43.374+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:44:43.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:44:43.391+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:44:43.413+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:44:43.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:44:43.426+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:44:43.426+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:44:43.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T18:45:13.652+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:13.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:45:13.654+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:13.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:13.671+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:13.692+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:13.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:45:13.704+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:13.704+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:45:13.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T18:45:43.855+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:43.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:45:43.857+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:43.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:43.874+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:43.897+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:43.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:45:43.910+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:43.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:45:44.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.212 seconds
[2025-02-01T18:45:52.995+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:52.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:45:52.998+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:52.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:53.022+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:45:53.043+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:53.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:45:53.056+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:45:53.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:45:53.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.245 seconds
[2025-02-01T18:46:23.369+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:46:23.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:46:23.372+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:46:23.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:46:23.390+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:46:23.414+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:46:23.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:46:23.561+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:46:23.561+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:46:23.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.217 seconds
[2025-02-01T18:46:53.627+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:46:53.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:46:53.630+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:46:53.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:46:53.649+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:46:53.816+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:46:53.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:46:53.828+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:46:53.828+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:46:53.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.221 seconds
[2025-02-01T18:47:17.928+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:17.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:47:17.931+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:17.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:17.957+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:18.210+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:18.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:47:18.221+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:18.221+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:47:18.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.316 seconds
[2025-02-01T18:47:23.057+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:23.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:47:23.059+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:23.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:23.078+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:23.074+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 489, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'image'
[2025-02-01T18:47:23.079+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:23.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T18:47:24.074+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:24.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:47:24.077+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:24.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:24.099+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:24.095+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 489, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'image'
[2025-02-01T18:47:24.100+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:24.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.048 seconds
[2025-02-01T18:47:45.262+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:45.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:47:45.265+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:45.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:45.276+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:45.275+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 22
    api_version='auto',d
                       
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-02-01T18:47:45.277+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:45.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.056 seconds
[2025-02-01T18:47:46.284+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:46.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:47:46.286+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:46.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:46.305+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:47:46.302+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 489, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'image'
[2025-02-01T18:47:46.307+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:47:46.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T18:48:16.481+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:16.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:48:16.485+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:16.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:16.498+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:16.495+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 489, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'image'
[2025-02-01T18:48:16.499+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:16.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.040 seconds
[2025-02-01T18:48:26.590+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:26.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:48:26.592+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:26.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:26.616+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:26.636+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:26.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:48:26.648+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:26.648+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:48:26.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T18:48:56.832+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:56.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:48:56.835+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:56.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:56.853+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:48:56.876+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:56.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:48:57.044+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:48:57.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:48:57.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.231 seconds
[2025-02-01T18:49:27.289+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:27.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:49:27.292+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:27.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:27.312+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:27.336+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:27.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:49:27.502+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:27.501+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:49:27.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.279 seconds
[2025-02-01T18:49:46.404+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:46.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:49:46.406+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:46.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:46.429+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:46.574+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:46.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:49:46.585+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:46.585+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:49:46.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.203 seconds
[2025-02-01T18:49:48.663+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:48.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:49:48.665+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:48.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:48.690+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:48.857+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:48.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:49:48.868+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:48.868+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:49:48.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.227 seconds
[2025-02-01T18:49:49.679+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:49.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:49:49.682+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:49.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:49.706+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:49:49.857+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:49.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:49:49.869+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:49:49.868+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:49:49.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.212 seconds
[2025-02-01T18:50:20.106+0000] {processor.py:186} INFO - Started process (PID=362) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:50:20.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:50:20.109+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:50:20.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:50:20.128+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:50:20.151+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:50:20.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:50:20.164+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:50:20.163+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:50:20.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T18:50:50.306+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:50:50.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:50:50.310+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:50:50.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:50:50.333+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:50:50.364+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:50:50.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:50:50.379+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:50:50.379+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:50:50.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T18:51:07.533+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:51:07.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:51:07.536+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:51:07.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:51:07.563+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:51:07.588+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:51:07.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:51:07.602+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:51:07.602+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:51:07.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T18:51:37.750+0000] {processor.py:186} INFO - Started process (PID=383) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:51:37.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:51:37.754+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:51:37.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:51:37.775+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:51:37.800+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:51:37.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:51:37.813+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:51:37.813+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:51:37.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.216 seconds
[2025-02-01T18:52:08.027+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:52:08.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:52:08.030+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:52:08.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:52:08.047+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:52:08.073+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:52:08.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:52:08.235+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:52:08.235+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:52:08.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.231 seconds
[2025-02-01T18:52:38.356+0000] {processor.py:186} INFO - Started process (PID=393) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:52:38.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:52:38.359+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:52:38.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:52:38.381+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:52:38.540+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:52:38.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:52:38.551+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:52:38.551+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:52:38.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.214 seconds
[2025-02-01T18:53:08.632+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:53:08.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:53:08.635+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:53:08.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:53:08.652+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:53:08.675+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:53:08.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:53:08.688+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:53:08.688+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:53:08.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T18:53:38.820+0000] {processor.py:186} INFO - Started process (PID=403) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:53:38.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:53:38.823+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:53:38.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:53:38.841+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:53:38.862+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:53:38.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:53:38.874+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:53:38.874+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:53:38.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T18:54:09.083+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:54:09.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:54:09.086+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:54:09.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:54:09.102+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:54:09.123+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:54:09.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:54:09.135+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:54:09.135+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:54:09.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T18:54:39.286+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:54:39.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:54:39.288+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:54:39.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:54:39.305+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:54:39.326+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:54:39.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:54:39.472+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:54:39.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:54:39.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.207 seconds
[2025-02-01T18:55:09.565+0000] {processor.py:186} INFO - Started process (PID=418) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:55:09.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:55:09.567+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:55:09.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:55:09.583+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:55:09.604+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:55:09.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:55:09.739+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:55:09.739+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:55:09.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.194 seconds
[2025-02-01T18:55:39.898+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:55:39.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:55:39.900+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:55:39.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:55:39.918+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:55:40.075+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:55:40.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:55:40.087+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:55:40.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:55:40.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.211 seconds
[2025-02-01T18:56:10.159+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:56:10.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:56:10.161+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:56:10.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:56:10.179+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:56:10.201+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:56:10.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:56:10.214+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:56:10.214+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:56:10.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T18:56:40.376+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:56:40.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:56:40.379+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:56:40.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:56:40.410+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:56:40.437+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:56:40.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:56:40.452+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:56:40.451+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:56:40.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T18:57:10.618+0000] {processor.py:186} INFO - Started process (PID=438) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:57:10.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:57:10.621+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:57:10.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:57:10.638+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:57:10.661+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:57:10.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:57:10.674+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:57:10.674+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:57:10.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.212 seconds
[2025-02-01T18:57:40.875+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:57:40.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:57:40.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:57:40.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:57:40.897+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:57:40.921+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:57:40.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:57:41.072+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:57:41.072+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:57:41.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.217 seconds
[2025-02-01T18:58:11.224+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:58:11.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:58:11.227+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:58:11.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:58:11.243+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:58:11.383+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:58:11.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:58:11.393+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:58:11.393+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:58:11.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.187 seconds
[2025-02-01T18:58:41.446+0000] {processor.py:186} INFO - Started process (PID=453) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:58:41.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:58:41.448+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:58:41.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:58:41.465+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:58:41.486+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:58:41.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:58:41.498+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:58:41.497+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:58:41.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T18:59:11.685+0000] {processor.py:186} INFO - Started process (PID=458) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:59:11.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:59:11.688+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:59:11.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:59:11.705+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:59:11.726+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:59:11.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:59:11.740+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:59:11.739+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:59:11.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T18:59:41.894+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:59:41.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T18:59:41.896+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:59:41.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:59:41.911+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T18:59:41.931+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:59:41.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T18:59:41.943+0000] {logging_mixin.py:190} INFO - [2025-02-01T18:59:41.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T18:59:41.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:00:12.154+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:00:12.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:00:12.157+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:00:12.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:00:12.176+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:00:12.201+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:00:12.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:00:12.351+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:00:12.351+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:00:12.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.218 seconds
[2025-02-01T19:00:42.574+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:00:42.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:00:42.578+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:00:42.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:00:42.596+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:00:42.621+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:00:42.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:00:42.774+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:00:42.774+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:00:42.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.218 seconds
[2025-02-01T19:01:12.976+0000] {processor.py:186} INFO - Started process (PID=478) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:01:12.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:01:12.978+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:01:12.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:01:12.994+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:01:13.135+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:01:13.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:01:13.146+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:01:13.146+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:01:13.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.187 seconds
[2025-02-01T19:01:43.368+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:01:43.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:01:43.371+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:01:43.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:01:43.390+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:01:43.414+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:01:43.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:01:43.427+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:01:43.426+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:01:43.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T19:02:13.567+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:02:13.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:02:13.570+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:02:13.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:02:13.585+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:02:13.606+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:02:13.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:02:13.617+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:02:13.617+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:02:13.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T19:02:43.836+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:02:43.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:02:43.838+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:02:43.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:02:43.855+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:02:43.876+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:02:43.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:02:43.889+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:02:43.888+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:02:43.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T19:03:14.041+0000] {processor.py:186} INFO - Started process (PID=498) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:03:14.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:03:14.044+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:03:14.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:03:14.061+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:03:14.083+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:03:14.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:03:14.226+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:03:14.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:03:14.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.229 seconds
[2025-02-01T19:03:44.469+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:03:44.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:03:44.472+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:03:44.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:03:44.487+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:03:44.508+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:03:44.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:03:44.640+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:03:44.640+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:03:44.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.188 seconds
[2025-02-01T19:04:14.690+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:04:14.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:04:14.693+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:04:14.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:04:14.708+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:04:14.858+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:04:14.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:04:14.869+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:04:14.869+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:04:14.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.198 seconds
[2025-02-01T19:04:45.041+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:04:45.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:04:45.043+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:04:45.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:04:45.059+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:04:45.079+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:04:45.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:04:45.091+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:04:45.090+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:04:45.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T19:05:15.229+0000] {processor.py:186} INFO - Started process (PID=518) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:05:15.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:05:15.232+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:05:15.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:05:15.247+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:05:15.268+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:05:15.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:05:15.280+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:05:15.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:05:15.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T19:05:45.521+0000] {processor.py:186} INFO - Started process (PID=523) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:05:45.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:05:45.524+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:05:45.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:05:45.541+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:05:45.561+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:05:45.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:05:45.574+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:05:45.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:05:45.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T19:06:15.712+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:06:15.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:06:15.714+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:06:15.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:06:15.730+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:06:15.750+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:06:15.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:06:15.762+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:06:15.762+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:06:15.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:06:45.990+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:06:45.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:06:45.992+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:06:45.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:06:46.008+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:06:46.028+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:06:46.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:06:46.040+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:06:46.039+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:06:46.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T19:07:16.199+0000] {processor.py:186} INFO - Started process (PID=538) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:07:16.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:07:16.202+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:07:16.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:07:16.217+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:07:16.237+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:07:16.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:07:16.249+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:07:16.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:07:16.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T19:07:46.460+0000] {processor.py:186} INFO - Started process (PID=543) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:07:46.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:07:46.463+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:07:46.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:07:46.478+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:07:46.498+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:07:46.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:07:46.510+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:07:46.510+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:07:46.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T19:08:08.707+0000] {processor.py:186} INFO - Started process (PID=548) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:08:08.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:08:08.710+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:08:08.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:08:08.734+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:08:08.856+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:08:08.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:08:08.873+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:08:08.873+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:08:08.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.199 seconds
[2025-02-01T19:08:39.116+0000] {processor.py:186} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:08:39.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:08:39.120+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:08:39.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:08:39.139+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:08:39.163+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:08:39.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:08:39.179+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:08:39.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:08:39.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T19:09:09.310+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:09:09.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:09:09.313+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:09:09.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:09:09.329+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:09:09.349+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:09:09.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:09:09.362+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:09:09.362+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:09:09.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T19:09:39.636+0000] {processor.py:186} INFO - Started process (PID=569) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:09:39.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:09:39.639+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:09:39.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:09:39.662+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:09:39.692+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:09:39.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:09:39.706+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:09:39.705+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:09:39.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.116 seconds
[2025-02-01T19:10:09.821+0000] {processor.py:186} INFO - Started process (PID=574) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:09.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:10:09.824+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:09.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:09.843+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:09.865+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:09.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:10:09.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:09.877+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:10:09.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T19:10:36.108+0000] {processor.py:186} INFO - Started process (PID=579) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:36.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:10:36.111+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:36.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:36.133+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:36.154+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:36.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:10:36.166+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:36.166+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:10:36.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T19:10:51.207+0000] {processor.py:186} INFO - Started process (PID=584) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:51.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:10:51.210+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:51.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:51.236+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:10:51.404+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:51.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:10:51.416+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:10:51.416+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:10:51.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.237 seconds
[2025-02-01T19:11:21.475+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:11:21.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:11:21.477+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:11:21.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:11:21.493+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:11:21.514+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:11:21.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:11:21.527+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:11:21.527+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:11:21.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T19:11:51.678+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:11:51.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:11:51.681+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:11:51.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:11:51.698+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:11:51.720+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:11:51.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:11:51.733+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:11:51.733+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:11:51.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T19:12:21.966+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:12:21.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:12:21.968+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:12:21.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:12:21.984+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:12:22.005+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:12:22.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:12:22.016+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:12:22.016+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:12:22.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:12:41.119+0000] {processor.py:186} INFO - Started process (PID=610) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:12:41.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:12:41.121+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:12:41.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:12:41.144+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:12:41.242+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:12:41.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:12:41.252+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:12:41.252+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:12:41.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.156 seconds
[2025-02-01T19:13:11.361+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:13:11.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:13:11.364+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:13:11.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:13:11.380+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:13:11.400+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:13:11.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:13:11.412+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:13:11.412+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:13:11.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T19:13:41.560+0000] {processor.py:186} INFO - Started process (PID=620) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:13:41.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:13:41.562+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:13:41.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:13:41.578+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:13:41.598+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:13:41.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:13:41.610+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:13:41.609+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:13:41.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:14:11.837+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:11.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:14:11.839+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:11.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:11.856+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:11.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:11.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:14:11.893+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:11.893+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:14:11.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T19:14:15.903+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:15.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:14:15.906+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:15.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:15.928+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:16.021+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:16.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:14:16.032+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:16.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:14:16.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.151 seconds
[2025-02-01T19:14:16.980+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:16.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:14:16.983+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:16.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:17.007+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:17.016+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:17.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:14:17.030+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:17.030+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:14:17.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T19:14:17.996+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:17.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:14:17.999+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:17.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:18.032+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:18.042+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:18.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:14:18.056+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:18.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:14:18.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T19:14:48.288+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:48.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:14:48.291+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:48.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:48.308+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:14:48.412+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:48.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:14:48.423+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:14:48.423+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:14:48.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.158 seconds
[2025-02-01T19:15:18.494+0000] {processor.py:186} INFO - Started process (PID=656) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:18.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:15:18.496+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:18.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:18.512+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:18.532+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:18.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:15:18.544+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:18.544+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:15:18.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:15:48.688+0000] {processor.py:186} INFO - Started process (PID=661) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:48.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:15:48.690+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:48.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:48.712+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:48.738+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:48.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:15:48.751+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:48.751+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:15:48.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T19:15:49.752+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:49.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:15:49.754+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:49.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:49.777+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:15:49.903+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:49.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:15:49.913+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:15:49.913+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:15:49.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.184 seconds
[2025-02-01T19:16:20.004+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:16:20.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:16:20.007+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:16:20.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:16:20.024+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:16:20.047+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:16:20.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:16:20.059+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:16:20.059+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:16:20.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T19:16:50.216+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:16:50.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:16:50.218+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:16:50.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:16:50.235+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:16:50.256+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:16:50.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:16:50.269+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:16:50.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:16:50.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T19:17:20.485+0000] {processor.py:186} INFO - Started process (PID=681) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:20.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:17:20.487+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:20.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:20.503+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:20.523+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:20.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:17:20.537+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:20.537+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:17:20.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T19:17:30.677+0000] {processor.py:186} INFO - Started process (PID=686) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:30.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:17:30.679+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:30.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:30.701+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:30.796+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:30.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:17:30.807+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:30.807+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:17:30.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.177 seconds
[2025-02-01T19:17:31.697+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:31.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:17:31.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:31.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:31.728+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:31.739+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:31.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:17:31.752+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:31.752+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:17:31.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T19:17:32.710+0000] {processor.py:186} INFO - Started process (PID=696) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:32.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:17:32.713+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:32.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:32.736+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:17:32.746+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:32.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:17:32.759+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:17:32.759+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:17:32.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T19:18:02.909+0000] {processor.py:186} INFO - Started process (PID=707) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:18:02.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:18:02.912+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:18:02.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:18:02.928+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:18:02.951+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:18:02.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:18:02.964+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:18:02.963+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:18:03.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T19:18:33.169+0000] {processor.py:186} INFO - Started process (PID=712) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:18:33.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:18:33.172+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:18:33.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:18:33.192+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:18:33.220+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:18:33.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:18:33.234+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:18:33.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:18:33.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T19:19:03.396+0000] {processor.py:186} INFO - Started process (PID=717) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:19:03.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:19:03.400+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:19:03.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:19:03.421+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:19:03.442+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:19:03.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:19:03.455+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:19:03.454+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:19:03.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T19:19:33.683+0000] {processor.py:186} INFO - Started process (PID=722) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:19:33.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:19:33.687+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:19:33.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:19:33.708+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:19:33.735+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:19:33.735+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:19:33.750+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:19:33.750+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:19:33.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T19:25:57.960+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:25:57.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:25:57.965+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:57.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:25:57.985+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:25:58.115+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.114+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T19:25:58.125+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.124+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T19:25:58.131+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.131+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T19:25:58.138+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.138+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T19:25:58.145+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.144+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T19:25:58.152+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.151+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T19:25:58.159+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.158+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T19:25:58.159+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:25:58.173+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.173+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T19:25:58.174+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:25:58.174+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:25:58.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.238 seconds
[2025-02-01T19:26:28.396+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:26:28.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:26:28.398+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:26:28.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:26:28.415+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:26:28.436+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:26:28.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:26:28.448+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:26:28.447+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:26:28.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T19:26:58.610+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:26:58.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:26:58.612+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:26:58.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:26:58.628+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:26:58.648+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:26:58.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:26:58.660+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:26:58.660+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:26:58.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:27:28.850+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:27:28.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:27:28.852+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:28.851+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:27:28.867+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:27:28.886+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:28.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:27:28.898+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:28.898+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:27:28.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.067 seconds
[2025-02-01T19:27:59.052+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:27:59.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:27:59.054+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:59.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:27:59.070+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:27:59.091+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:59.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:27:59.102+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:27:59.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:27:59.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.068 seconds
[2025-02-01T19:28:29.288+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:28:29.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:28:29.290+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:29.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:28:29.307+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:28:29.328+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:29.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:28:29.340+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:29.340+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:28:29.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T19:28:59.496+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:28:59.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:28:59.498+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:59.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:28:59.515+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:28:59.539+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:59.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:28:59.552+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:28:59.552+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:28:59.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T19:29:29.747+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:29:29.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:29:29.749+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:29:29.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:29:29.765+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:29:29.785+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:29:29.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:29:29.797+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:29:29.797+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:29:29.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:29:59.961+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:29:59.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:29:59.963+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:29:59.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:29:59.980+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:30:00.002+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:30:00.002+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:30:00.163+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:30:00.163+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:30:00.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.223 seconds
[2025-02-01T19:31:46.625+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:31:46.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:31:46.630+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:31:46.651+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:31:46.770+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.769+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T19:31:46.779+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.779+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T19:31:46.786+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.785+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T19:31:46.793+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.793+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T19:31:46.800+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.799+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T19:31:46.806+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.806+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T19:31:46.813+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.812+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T19:31:46.813+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:31:46.826+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.826+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T19:31:46.827+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:31:46.827+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:31:46.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.225 seconds
[2025-02-01T19:32:17.053+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:32:17.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:32:17.055+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:32:17.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:32:17.073+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:32:17.094+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:32:17.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:32:17.106+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:32:17.106+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:32:17.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T19:32:47.258+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:32:47.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:32:47.261+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:32:47.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:32:47.279+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:32:47.303+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:32:47.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:32:47.316+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:32:47.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:32:47.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T19:33:17.529+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:33:17.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:33:17.531+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:33:17.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:33:17.547+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:33:17.566+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:33:17.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:33:17.578+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:33:17.578+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:33:17.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.091 seconds
[2025-02-01T19:33:47.764+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:33:47.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:33:47.766+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:33:47.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:33:47.784+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:33:47.807+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:33:47.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:33:47.820+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:33:47.819+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:33:47.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T19:34:18.005+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:34:18.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:34:18.007+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:34:18.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:34:18.024+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:34:18.047+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:34:18.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:34:18.060+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:34:18.060+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:34:18.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T19:34:48.223+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:34:48.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:34:48.225+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:34:48.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:34:48.243+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:34:48.269+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:34:48.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:34:48.282+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:34:48.282+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:34:48.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T19:35:18.476+0000] {processor.py:186} INFO - Started process (PID=241) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:35:18.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:35:18.478+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:35:18.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:35:18.496+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:35:18.519+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:35:18.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:35:18.532+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:35:18.531+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:35:18.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T19:35:48.698+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:35:48.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:35:48.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:35:48.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:35:48.716+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:35:48.737+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:35:48.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:35:48.877+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:35:48.877+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:35:48.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.197 seconds
[2025-02-01T19:36:18.948+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:36:18.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:36:18.950+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:36:18.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:36:18.965+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:36:18.986+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:36:18.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:36:19.127+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:36:19.127+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:36:19.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.197 seconds
[2025-02-01T19:36:49.288+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:36:49.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:36:49.291+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:36:49.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:36:49.307+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:36:49.329+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:36:49.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:36:49.342+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:36:49.342+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:36:49.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T19:37:19.550+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:37:19.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:37:19.552+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:37:19.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:37:19.569+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:37:19.592+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:37:19.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:37:19.604+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:37:19.604+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:37:19.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T19:37:49.764+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:37:49.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:37:49.766+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:37:49.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:37:49.781+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:37:49.802+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:37:49.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:37:49.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:37:49.814+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:37:49.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T19:38:20.025+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:38:20.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:38:20.027+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:38:20.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:38:20.044+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:38:20.066+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:38:20.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:38:20.081+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:38:20.081+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:38:20.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.224 seconds
[2025-02-01T19:44:07.371+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:44:07.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:44:07.375+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:44:07.395+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:44:07.520+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.520+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:spark_orchestration
[2025-02-01T19:44:07.530+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.530+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:spark_orchestration
[2025-02-01T19:44:07.537+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.537+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:spark_orchestration
[2025-02-01T19:44:07.544+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.544+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:spark_orchestration
[2025-02-01T19:44:07.551+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.551+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:spark_orchestration
[2025-02-01T19:44:07.558+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.558+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:spark_orchestration
[2025-02-01T19:44:07.564+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.564+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:spark_orchestration
[2025-02-01T19:44:07.565+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:44:07.579+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.578+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T19:44:07.579+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:07.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:44:07.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.232 seconds
[2025-02-01T19:44:37.816+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:44:37.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:44:37.819+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:37.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:44:37.837+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:44:37.863+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:37.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:44:37.877+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:44:37.877+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:44:37.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T19:45:08.036+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:45:08.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:45:08.039+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:45:08.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:45:08.055+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:45:08.077+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:45:08.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:45:08.091+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:45:08.091+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:45:08.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T19:45:38.311+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:45:38.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:45:38.313+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:45:38.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:45:38.329+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:45:38.351+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:45:38.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:45:38.365+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:45:38.364+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:45:38.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T19:46:08.527+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:46:08.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:46:08.529+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:46:08.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:46:08.546+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:46:08.570+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:46:08.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:46:08.584+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:46:08.583+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:46:08.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T19:46:38.816+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:46:38.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:46:38.818+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:46:38.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:46:38.838+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:46:38.863+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:46:38.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:46:38.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:46:38.878+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:46:38.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T19:47:09.041+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:47:09.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:47:09.043+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:47:09.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:47:09.059+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:47:09.082+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:47:09.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:47:09.095+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:47:09.094+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:47:09.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T19:47:39.298+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:47:39.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:47:39.300+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:47:39.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:47:39.318+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:47:39.341+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:47:39.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:47:39.353+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:47:39.353+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:47:39.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T19:48:09.526+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:09.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:09.528+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:09.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:09.544+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:09.565+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:09.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:48:09.713+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:09.713+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:48:09.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.206 seconds
[2025-02-01T19:48:12.792+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:12.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:12.794+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:12.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:12.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:12.811+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T19:48:12.815+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:12.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T19:48:13.804+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:13.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:13.807+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:13.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:13.826+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:13.822+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark/jobs']}
[2025-02-01T19:48:13.827+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:13.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T19:48:20.914+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:20.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:20.916+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:20.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:20.936+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:20.932+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/wsl/Ubuntu/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:48:20.937+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:20.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T19:48:38.064+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:38.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:38.066+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:38.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:38.087+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:38.083+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt//D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:48:38.087+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:38.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T19:48:39.113+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:39.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:39.116+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:39.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:39.138+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:39.134+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/D/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:48:39.139+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:39.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.046 seconds
[2025-02-01T19:48:43.174+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:43.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:43.176+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:43.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:43.196+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:43.192+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/DDRepo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:48:43.197+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:43.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.066 seconds
[2025-02-01T19:48:46.231+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:46.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:46.234+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:46.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:46.253+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:46.250+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:48:46.254+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:46.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.042 seconds
[2025-02-01T19:48:48.294+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:48.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:48:48.296+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:48.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:48.317+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:48:48.313+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:48:48.317+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:48:48.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T19:49:03.451+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:03.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:03.454+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:03.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:03.467+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:03.466+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 30
    volumes=[/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark'],  # Example: Ubuntu WSL, D: drive
                                                              ^
SyntaxError: unterminated string literal (detected at line 30)
[2025-02-01T19:49:03.468+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:03.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.037 seconds
[2025-02-01T19:49:04.493+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:04.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:04.497+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:04.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:04.510+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:04.508+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 30
    volumes=[/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark],  # Example: Ubuntu WSL, D: drive
             ^
SyntaxError: invalid syntax
[2025-02-01T19:49:04.510+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:04.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T19:49:07.569+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:07.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:07.571+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:07.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:07.584+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:07.583+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 31
    []/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark],  # Example: Ubuntu WSL, D: drive
                                    ^
SyntaxError: invalid syntax
[2025-02-01T19:49:07.585+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:07.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T19:49:08.590+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:08.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:08.592+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:08.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:08.605+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:08.604+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 30
    volumes=[/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark],  # Example: Ubuntu WSL, D: drive
             ^
SyntaxError: invalid syntax
[2025-02-01T19:49:08.605+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:08.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T19:49:10.666+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:10.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:10.668+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:10.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:10.678+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:10.677+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 30
    volumes=["/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark],  # Example: Ubuntu WSL, D: drive
             ^
SyntaxError: unterminated string literal (detected at line 30)
[2025-02-01T19:49:10.679+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:10.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.030 seconds
[2025-02-01T19:49:12.709+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:12.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:12.711+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:12.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:12.731+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:12.728+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:49:12.732+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:12.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.043 seconds
[2025-02-01T19:49:13.743+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:13.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:13.745+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:13.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:13.759+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:13.754+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:49:13.760+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:13.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.044 seconds
[2025-02-01T19:49:43.988+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:43.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:49:43.990+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:43.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:44.004+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:49:44.000+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:49:44.004+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:49:44.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T19:50:14.200+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:14.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:50:14.202+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:14.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:14.215+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:14.212+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/docker/operators/docker.py", line 285, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 957, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/mnt/d/Repo/Spark-Bitnami/jobs:/opt/bitnami/spark']}
[2025-02-01T19:50:14.216+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:14.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T19:50:28.337+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:28.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:50:28.339+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:28.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:28.363+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:28.593+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:28.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:50:28.605+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:28.604+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:50:28.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.346 seconds
[2025-02-01T19:50:29.372+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:29.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:50:29.374+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:29.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:29.398+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:29.418+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:29.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:50:29.432+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:29.432+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:50:29.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T19:50:59.587+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:59.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:50:59.589+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:59.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:59.608+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:50:59.631+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:59.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:50:59.812+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:50:59.812+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:50:59.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.271 seconds
[2025-02-01T19:51:30.078+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:51:30.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:51:30.081+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:51:30.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:51:30.100+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:51:30.124+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:51:30.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:51:30.292+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:51:30.292+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:51:30.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.233 seconds
[2025-02-01T19:52:00.531+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:00.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:52:00.533+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:00.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:00.551+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:00.573+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:00.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:52:00.586+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:00.586+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:52:00.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T19:52:30.742+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:30.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:52:30.744+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:30.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:30.760+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:30.781+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:30.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:52:30.794+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:30.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:52:30.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T19:52:45.907+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:45.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:52:45.909+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:45.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:45.933+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:45.957+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:45.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:52:45.970+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:45.969+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:52:45.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T19:52:50.947+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:50.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:52:50.949+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:50.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:50.971+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:50.992+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:50.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:52:51.005+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:51.004+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:52:51.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T19:52:54.062+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:54.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:52:54.064+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:54.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:54.087+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:54.107+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:54.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:52:54.119+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:54.119+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:52:54.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.110 seconds
[2025-02-01T19:52:56.134+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:56.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:52:56.136+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:56.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:56.178+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:52:56.201+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:56.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:52:56.213+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:52:56.213+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:52:56.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T19:53:01.298+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:01.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:53:01.300+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:01.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:01.322+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:01.342+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:01.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:53:01.355+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:01.355+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:53:01.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T19:53:03.334+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:03.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:53:03.336+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:03.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:03.365+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:03.390+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:03.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:53:03.402+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:03.402+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:53:03.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T19:53:05.463+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:05.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:53:05.465+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:05.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:05.488+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:05.509+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:05.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:53:05.521+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:05.521+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:53:05.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T19:53:35.697+0000] {processor.py:186} INFO - Started process (PID=412) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:35.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:53:35.699+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:35.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:35.717+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:53:35.741+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:35.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:53:35.757+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:53:35.757+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:53:35.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.241 seconds
[2025-02-01T19:54:05.990+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:54:05.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:54:05.992+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:05.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:54:06.010+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:54:06.034+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:06.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:54:06.191+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:06.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:54:06.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.247 seconds
[2025-02-01T19:54:36.370+0000] {processor.py:186} INFO - Started process (PID=422) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:54:36.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:54:36.372+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:36.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:54:36.388+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:54:36.535+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:36.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:54:36.547+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:54:36.546+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:54:36.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.219 seconds
[2025-02-01T19:55:06.663+0000] {processor.py:186} INFO - Started process (PID=427) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:06.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:55:06.665+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:06.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:06.686+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:06.713+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:06.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:55:06.726+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:06.726+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:55:06.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T19:55:36.844+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:36.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:55:36.846+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:36.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:36.862+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:36.883+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:36.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:55:36.895+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:36.895+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:55:36.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T19:55:51.933+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:51.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:55:51.935+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:51.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:51.960+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:55:51.983+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:51.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:55:51.997+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:55:51.996+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:55:52.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T19:56:07.140+0000] {processor.py:186} INFO - Started process (PID=442) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:07.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:56:07.142+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:07.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:07.166+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:07.186+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:07.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:56:07.198+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:07.198+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:56:07.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T19:56:08.168+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:08.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:56:08.170+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:08.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:08.197+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:08.221+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:08.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:56:08.234+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:08.234+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:56:08.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T19:56:38.475+0000] {processor.py:186} INFO - Started process (PID=458) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:38.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:56:38.477+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:38.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:38.496+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:56:38.517+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:38.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:56:38.667+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:56:38.666+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:56:38.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.214 seconds
[2025-02-01T19:57:08.906+0000] {processor.py:186} INFO - Started process (PID=463) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:57:08.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:57:08.907+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:08.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:57:08.924+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:57:08.946+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:08.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:57:09.080+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:09.080+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:57:09.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.217 seconds
[2025-02-01T19:57:39.360+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:57:39.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:57:39.362+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:39.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:57:39.382+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:57:39.533+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:39.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:57:39.544+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:57:39.543+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:57:39.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.225 seconds
[2025-02-01T19:58:09.780+0000] {processor.py:186} INFO - Started process (PID=473) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:09.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:58:09.781+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:09.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:09.799+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:09.821+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:09.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:58:09.834+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:09.834+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:58:09.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T19:58:13.806+0000] {processor.py:186} INFO - Started process (PID=478) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:13.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:58:13.808+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:13.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:13.830+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:13.851+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:13.851+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:58:13.863+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:13.863+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:58:13.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T19:58:14.910+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:14.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:58:14.912+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:14.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:14.934+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:14.954+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:14.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:58:14.966+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:14.966+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:58:14.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T19:58:16.934+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:16.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:58:16.935+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:16.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:16.958+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:16.979+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:16.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:58:16.993+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:16.992+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:58:17.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T19:58:24.074+0000] {processor.py:186} INFO - Started process (PID=493) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:24.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:58:24.077+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:24.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:24.108+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:24.413+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:24.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:58:24.424+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:24.424+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:58:24.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.372 seconds
[2025-02-01T19:58:54.672+0000] {processor.py:186} INFO - Started process (PID=498) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:54.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:58:54.675+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:54.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:54.694+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:58:54.719+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:54.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:58:54.733+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:58:54.733+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:58:54.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T19:59:24.926+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:24.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:59:24.928+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:24.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:24.946+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:24.970+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:24.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:59:25.143+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:25.143+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:59:25.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.242 seconds
[2025-02-01T19:59:30.053+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:30.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:59:30.055+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:30.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:30.081+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:30.333+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:30.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:59:30.346+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:30.346+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:59:30.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.320 seconds
[2025-02-01T19:59:41.341+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:41.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T19:59:41.343+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:41.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:41.360+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T19:59:41.371+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:41.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T19:59:41.387+0000] {logging_mixin.py:190} INFO - [2025-02-01T19:59:41.386+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T19:59:41.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.205 seconds
[2025-02-01T20:00:11.664+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:00:11.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:00:11.665+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:11.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:00:11.682+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:00:11.838+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:11.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:00:11.854+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:11.854+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:00:11.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.213 seconds
[2025-02-01T20:00:41.973+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:00:41.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:00:41.976+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:41.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:00:41.995+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:00:42.019+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:42.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:00:42.033+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:00:42.032+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:00:42.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.082 seconds
[2025-02-01T20:01:12.194+0000] {processor.py:186} INFO - Started process (PID=534) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:12.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:01:12.196+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:12.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:12.213+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:12.236+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:12.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:01:12.249+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:12.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:01:12.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T20:01:42.485+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:42.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:01:42.486+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:42.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:42.502+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:42.522+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:42.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:01:42.535+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:42.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:01:42.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T20:01:51.545+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:51.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:01:51.547+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:51.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:51.572+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:51.594+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:51.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:01:51.608+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:51.608+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:01:51.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.218 seconds
[2025-02-01T20:01:52.635+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:52.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:01:52.637+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:52.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:52.655+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:01:52.677+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:52.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:01:52.691+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:01:52.691+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:01:52.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.235 seconds
[2025-02-01T20:02:23.008+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:23.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:02:23.010+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:23.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:23.025+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:23.047+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:23.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:02:23.188+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:23.188+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:02:23.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.198 seconds
[2025-02-01T20:02:37.199+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:37.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:02:37.201+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:37.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:37.224+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:37.246+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:37.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:02:37.416+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:37.416+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:02:37.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.242 seconds
[2025-02-01T20:02:50.545+0000] {processor.py:186} INFO - Started process (PID=570) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:50.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:02:50.546+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:50.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:50.570+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:50.717+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:50.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:02:50.728+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:50.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:02:50.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.206 seconds
[2025-02-01T20:02:52.565+0000] {processor.py:186} INFO - Started process (PID=575) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:52.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:02:52.566+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:52.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:52.590+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:52.737+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:52.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:02:52.748+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:52.748+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:02:52.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.204 seconds
[2025-02-01T20:02:53.801+0000] {processor.py:186} INFO - Started process (PID=580) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:53.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:02:53.803+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:53.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:53.825+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:53.966+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:53.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:02:53.977+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:53.977+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:02:54.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.218 seconds
[2025-02-01T20:02:54.820+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:54.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:02:54.821+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:54.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:54.843+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:54.983+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:54.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:02:54.993+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:54.993+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:02:55.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.216 seconds
[2025-02-01T20:02:59.139+0000] {processor.py:186} INFO - Started process (PID=590) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:59.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:02:59.141+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:59.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:59.163+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:02:59.305+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:59.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:02:59.316+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:02:59.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:02:59.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.220 seconds
[2025-02-01T20:03:08.205+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:08.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:03:08.207+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:08.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:08.230+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:08.459+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:08.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:03:08.469+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:08.469+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:03:08.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.284 seconds
[2025-02-01T20:03:11.458+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:11.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:03:11.460+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:11.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:11.482+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:11.491+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:11.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:03:11.625+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:11.625+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:03:11.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.187 seconds
[2025-02-01T20:03:14.560+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:14.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:03:14.562+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:14.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:14.584+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:14.724+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:14.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:03:14.736+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:14.736+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:03:14.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.222 seconds
[2025-02-01T20:03:45.030+0000] {processor.py:186} INFO - Started process (PID=616) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:45.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:03:45.032+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:45.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:45.049+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:03:45.152+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:45.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:03:45.164+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:03:45.163+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:03:45.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.156 seconds
[2025-02-01T20:04:15.268+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:04:15.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:04:15.270+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:15.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:04:15.288+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:04:15.310+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:15.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:04:15.324+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:15.324+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:04:15.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T20:04:45.477+0000] {processor.py:186} INFO - Started process (PID=626) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:04:45.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:04:45.480+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:45.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:04:45.497+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:04:45.520+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:45.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:04:45.535+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:04:45.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:04:45.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.103 seconds
[2025-02-01T20:05:52.436+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:05:52.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:05:52.438+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:05:52.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:05:52.458+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:05:52.480+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:05:52.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:05:52.495+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:05:52.495+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:05:52.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T20:06:22.655+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:06:22.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:06:22.659+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:22.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:06:22.679+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:06:22.703+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:22.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:06:22.717+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:22.717+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:06:22.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T20:06:52.921+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:06:52.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:06:52.924+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:52.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:06:52.943+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:06:52.966+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:52.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:06:52.982+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:06:52.982+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:06:53.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T20:07:23.136+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:07:23.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:07:23.138+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:23.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:07:23.155+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:07:23.177+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:23.177+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:07:23.191+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:23.191+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:07:23.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T20:07:53.429+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:07:53.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:07:53.432+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:53.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:07:53.448+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:07:53.470+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:53.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:07:53.483+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:07:53.482+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:07:53.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T20:08:23.643+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:08:23.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:08:23.645+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:23.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:08:23.660+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:08:23.682+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:23.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:08:23.694+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:23.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:08:23.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T20:08:53.919+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:08:53.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:08:53.921+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:53.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:08:53.939+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:08:53.964+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:53.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:08:53.978+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:08:53.977+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:08:54.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T20:09:24.142+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:09:24.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:09:24.144+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:09:24.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:09:24.160+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:09:24.181+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:09:24.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:09:24.193+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:09:24.193+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:09:24.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T20:09:54.445+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:09:54.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:09:54.447+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:09:54.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:09:54.464+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:09:54.487+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:09:54.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:09:54.501+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:09:54.501+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:09:54.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.236 seconds
[2025-02-01T20:10:24.909+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:24.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:10:24.912+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:24.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:24.928+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:24.950+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:24.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:10:25.102+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:25.102+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:10:25.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.215 seconds
[2025-02-01T20:10:40.016+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:40.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:10:40.020+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:40.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:40.049+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:40.040+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^
NameError: name 'DockerOperator' is not defined
[2025-02-01T20:10:40.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:40.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.063 seconds
[2025-02-01T20:10:51.081+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:51.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:10:51.083+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:51.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:51.097+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:51.096+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    python_job = DockerOperator(
                               ^
SyntaxError: '(' was never closed
[2025-02-01T20:10:51.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:51.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.061 seconds
[2025-02-01T20:10:53.257+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:53.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:10:53.260+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:53.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:53.275+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:53.274+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    python_job = DockerOperator(
                               ^
SyntaxError: '(' was never closed
[2025-02-01T20:10:53.276+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:53.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.040 seconds
[2025-02-01T20:10:54.283+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:54.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:10:54.286+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:54.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:54.315+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:54.307+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20, in <module>
    python_job = DockerOperator(
                 ^^^^^^^^^^^^^^
NameError: name 'DockerOperator' is not defined
[2025-02-01T20:10:54.322+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:54.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T20:10:56.363+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:56.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:10:56.366+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:56.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:56.378+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:56.377+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator(
                                 ^
IndentationError: unindent does not match any outer indentation level
[2025-02-01T20:10:56.378+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:56.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.049 seconds
[2025-02-01T20:10:59.437+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:59.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:10:59.440+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:59.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:59.452+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:10:59.451+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 25
    dag=dag
    ^^^^^^^
SyntaxError: keyword argument repeated: dag
[2025-02-01T20:10:59.452+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:10:59.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.057 seconds
[2025-02-01T20:11:29.683+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:11:29.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:11:29.685+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:11:29.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:11:29.696+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:11:29.696+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 25
    dag=dag
    ^^^^^^^
SyntaxError: keyword argument repeated: dag
[2025-02-01T20:11:29.697+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:11:29.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.056 seconds
[2025-02-01T20:11:59.938+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:11:59.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:11:59.940+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:11:59.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:11:59.951+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:11:59.951+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 25
    dag=dag
    ^^^^^^^
SyntaxError: keyword argument repeated: dag
[2025-02-01T20:11:59.952+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:11:59.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.055 seconds
[2025-02-01T20:12:30.174+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:30.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:12:30.176+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:12:30.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:30.187+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:12:30.186+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 25
    dag=dag
    ^^^^^^^
SyntaxError: keyword argument repeated: dag
[2025-02-01T20:12:30.188+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:30.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.031 seconds
[2025-02-01T20:12:53.364+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:53.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:12:53.366+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:12:53.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:53.379+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:12:53.379+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator(
                                ^
SyntaxError: '(' was never closed
[2025-02-01T20:12:53.380+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:53.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T20:12:55.399+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:55.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:12:55.402+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:12:55.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:55.420+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:12:55.419+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 25
    dag=dag
    ^^^^^^^
SyntaxError: keyword argument repeated: dag
[2025-02-01T20:12:55.421+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:12:55.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:13:03.500+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:03.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:03.501+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:03.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:03.516+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:03.515+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator(
                                ^
SyntaxError: '(' was never closed
[2025-02-01T20:13:03.517+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:03.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T20:13:05.553+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:05.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:05.555+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:05.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:05.568+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:05.567+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator(
                                ^
SyntaxError: '(' was never closed
[2025-02-01T20:13:05.569+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:05.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T20:13:13.659+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:13.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:13.661+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:13.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:13.674+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:13.673+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator(
                                ^
SyntaxError: '(' was never closed
[2025-02-01T20:13:13.674+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:13.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.033 seconds
[2025-02-01T20:13:15.693+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:15.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:15.695+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:15.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:15.709+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:15.708+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator (
                                 ^
SyntaxError: '(' was never closed
[2025-02-01T20:13:15.709+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:15.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T20:13:16.747+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:16.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:16.749+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:16.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:16.763+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:16.762+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator(
                                ^
SyntaxError: '(' was never closed
[2025-02-01T20:13:16.763+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:16.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T20:13:18.792+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:18.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:18.795+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:18.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:18.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:18.813+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 20
    run_spark_job = BashOperator(
                                ^
SyntaxError: '(' was never closed
[2025-02-01T20:13:18.815+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:18.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T20:13:27.932+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:27.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:27.934+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:27.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:27.957+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:27.950+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 45, in <module>
    start >> [python_job] >> end
              ^^^^^^^^^^
NameError: name 'python_job' is not defined
[2025-02-01T20:13:27.962+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:28.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T20:13:35.020+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:35.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:35.023+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:35.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:35.053+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:35.046+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 45, in <module>
    start >> [python_job] >> end
              ^^^^^^^^^^
NameError: name 'python_job' is not defined
[2025-02-01T20:13:35.058+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:35.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.095 seconds
[2025-02-01T20:13:36.078+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:36.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:13:36.080+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:36.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:36.105+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:13:36.098+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 45, in <module>
    start >> [python_job] >> end
              ^^^^^^^^^^
NameError: name 'python_job' is not defined
[2025-02-01T20:13:36.110+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:13:36.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.051 seconds
[2025-02-01T20:14:06.366+0000] {processor.py:186} INFO - Started process (PID=350) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:06.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:14:06.368+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:06.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:06.385+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:06.378+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 45, in <module>
    start >> [python_job] >> end
              ^^^^^^^^^^
NameError: name 'python_job' is not defined
[2025-02-01T20:14:06.389+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:06.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.065 seconds
[2025-02-01T20:14:11.419+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:11.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:14:11.421+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:11.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:11.449+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:11.707+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:11.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:14:11.718+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:11.718+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:14:11.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.327 seconds
[2025-02-01T20:14:41.983+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:41.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:14:41.986+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:41.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:42.001+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:14:42.024+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:42.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:14:42.038+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:14:42.038+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:14:42.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T20:15:12.222+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:15:12.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:15:12.224+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:15:12.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:15:12.238+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:15:12.259+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:15:12.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:15:12.271+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:15:12.271+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:15:12.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.069 seconds
[2025-02-01T20:15:42.525+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:15:42.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:15:42.527+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:15:42.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:15:42.541+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:15:42.561+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:15:42.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:15:42.701+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:15:42.701+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:15:42.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.194 seconds
[2025-02-01T20:16:29.400+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:16:29.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:16:29.402+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:16:29.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:16:29.422+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:16:29.450+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:16:29.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:16:29.471+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:16:29.470+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:16:29.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T20:16:59.637+0000] {processor.py:186} INFO - Started process (PID=199) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:16:59.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:16:59.639+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:16:59.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:16:59.656+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:16:59.680+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:16:59.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:16:59.693+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:16:59.692+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:16:59.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T20:17:29.962+0000] {processor.py:186} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:17:29.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:17:29.965+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:17:29.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:17:29.982+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:17:30.007+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:17:30.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:17:30.020+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:17:30.020+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:17:30.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T20:18:00.201+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:18:00.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:18:00.203+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:18:00.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:18:00.220+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:18:00.244+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:18:00.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:18:00.258+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:18:00.258+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:18:00.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T20:18:30.491+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:18:30.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:18:30.493+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:18:30.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:18:30.511+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:18:30.535+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:18:30.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:18:30.549+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:18:30.549+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:18:30.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T20:19:00.719+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:19:00.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:19:00.722+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:19:00.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:19:00.737+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:19:00.760+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:19:00.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:19:00.775+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:19:00.775+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:19:00.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T20:19:31.017+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:19:31.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:19:31.019+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:19:31.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:19:31.033+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:19:31.055+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:19:31.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:19:31.067+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:19:31.067+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:19:31.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:20:01.272+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:20:01.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:20:01.275+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:20:01.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:20:01.293+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:20:01.319+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:20:01.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:20:01.334+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:20:01.334+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:20:01.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.089 seconds
[2025-02-01T20:20:31.546+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:20:31.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:20:31.548+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:20:31.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:20:31.563+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:20:31.585+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:20:31.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:20:31.597+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:20:31.597+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:20:31.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.095 seconds
[2025-02-01T20:21:01.813+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:21:01.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:21:01.816+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:21:01.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:21:01.832+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:21:01.854+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:21:01.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:21:01.867+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:21:01.867+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:21:01.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T20:21:32.145+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:21:32.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:21:32.147+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:21:32.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:21:32.163+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:21:32.186+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:21:32.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:21:32.201+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:21:32.200+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:21:32.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T20:22:02.405+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:22:02.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:22:02.408+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:22:02.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:22:02.423+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:22:02.447+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:22:02.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:22:02.461+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:22:02.461+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:22:02.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T20:22:32.695+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:22:32.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:22:32.698+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:22:32.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:22:32.714+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:22:32.737+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:22:32.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:22:32.751+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:22:32.750+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:22:32.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T20:23:02.932+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:02.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:23:02.935+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:02.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:02.951+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:02.975+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:02.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:23:02.988+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:02.988+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:23:03.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T20:23:24.170+0000] {processor.py:186} INFO - Started process (PID=302) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:24.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:23:24.173+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:24.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:24.198+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:24.322+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:24.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:23:24.334+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:24.334+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:23:24.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.193 seconds
[2025-02-01T20:23:35.458+0000] {processor.py:186} INFO - Started process (PID=307) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:35.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:23:35.461+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:35.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:35.483+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:23:35.493+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:35.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:23:35.506+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:23:35.506+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:23:35.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T20:24:05.697+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:05.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:24:05.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:05.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:05.715+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:05.737+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:05.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:24:05.750+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:05.750+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:24:05.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T20:24:14.819+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:14.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:24:14.822+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:14.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:14.845+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:14.957+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:14.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:24:14.969+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:14.969+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:24:15.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.301 seconds
[2025-02-01T20:24:16.865+0000] {processor.py:186} INFO - Started process (PID=329) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:16.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:24:16.868+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:16.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:16.887+0000] {logging_mixin.py:190} WARNING - /opt/airflow/dags/spark_airflow.py:30 SyntaxWarning: invalid escape sequence '\/'
[2025-02-01T20:24:16.891+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:16.901+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:16.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:24:16.920+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:16.920+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:24:16.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T20:24:47.110+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:47.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:24:47.113+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:47.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:47.130+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:24:47.247+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:47.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:24:47.393+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:24:47.393+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:24:47.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.305 seconds
[2025-02-01T20:25:17.654+0000] {processor.py:186} INFO - Started process (PID=346) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:25:17.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:25:17.657+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:25:17.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:25:17.671+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:25:17.694+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:25:17.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:25:17.706+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:25:17.706+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:25:17.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:25:47.898+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:25:47.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:25:47.901+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:25:47.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:25:47.916+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:25:47.937+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:25:47.937+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:25:47.950+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:25:47.949+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:25:47.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.095 seconds
[2025-02-01T20:26:18.172+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:26:18.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:26:18.174+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:26:18.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:26:18.189+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:26:18.212+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:26:18.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:26:18.225+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:26:18.225+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:26:18.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T20:26:48.457+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:26:48.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:26:48.459+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:26:48.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:26:48.477+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:26:48.501+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:26:48.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:26:48.514+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:26:48.514+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:26:48.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T20:27:18.698+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:18.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:27:18.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:18.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:18.714+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:18.736+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:18.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:27:18.748+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:18.748+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:27:18.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T20:27:26.889+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:26.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:27:26.892+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:26.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:26.915+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:27.024+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:27.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:27:27.165+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:27.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:27:27.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.299 seconds
[2025-02-01T20:27:29.246+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:29.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:27:29.249+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:29.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:29.271+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:29.281+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:29.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:27:29.294+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:29.294+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:27:29.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:27:30.263+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:30.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:27:30.265+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:30.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:30.281+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:27:30.291+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:30.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:27:30.304+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:27:30.303+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:27:30.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T20:28:00.605+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:28:00.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:28:00.608+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:28:00.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:28:00.623+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:28:00.868+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:28:00.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:28:00.879+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:28:00.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:28:00.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.316 seconds
[2025-02-01T20:28:31.180+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:28:31.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:28:31.183+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:28:31.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:28:31.203+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:28:31.234+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:28:31.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:28:31.251+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:28:31.251+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:28:31.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T20:29:01.428+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:29:01.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:29:01.432+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:01.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:29:01.450+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:29:01.476+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:01.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:29:01.491+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:01.491+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:29:01.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.113 seconds
[2025-02-01T20:29:31.767+0000] {processor.py:186} INFO - Started process (PID=439) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:29:31.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:29:31.773+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:31.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:29:31.805+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:29:31.857+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:31.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:29:31.883+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:29:31.882+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:29:31.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.166 seconds
[2025-02-01T20:30:01.997+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:01.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:30:02.000+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:01.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:02.014+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:02.038+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:02.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:30:02.052+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:02.051+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:30:02.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T20:30:21.115+0000] {processor.py:186} INFO - Started process (PID=449) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:21.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:30:21.117+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:21.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:21.139+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:21.135+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job = BashOperator(
                    ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:30:21.141+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:21.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.047 seconds
[2025-02-01T20:30:27.217+0000] {processor.py:186} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:27.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:30:27.220+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:27.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:27.243+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:27.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job_dqc = BashOperator(
                        ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:30:27.244+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:27.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.047 seconds
[2025-02-01T20:30:32.307+0000] {processor.py:186} INFO - Started process (PID=459) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:32.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:30:32.309+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:32.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:32.331+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:32.327+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job_dqc = BashOperator(
                        ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:30:32.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:32.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.045 seconds
[2025-02-01T20:30:38.366+0000] {processor.py:186} INFO - Started process (PID=464) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:38.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:30:38.368+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:38.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:38.391+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:38.387+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job_dqc = BashOperator(
                        ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:30:38.392+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:38.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.048 seconds
[2025-02-01T20:30:56.590+0000] {processor.py:186} INFO - Started process (PID=469) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:56.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:30:56.593+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:56.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:56.616+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:56.612+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job_dqc = BashOperator(
                        ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:30:56.617+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:56.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.047 seconds
[2025-02-01T20:30:58.627+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:58.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:30:58.631+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:58.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:58.657+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:30:58.652+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job_dqc = BashOperator(
                        ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:30:58.658+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:30:58.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.056 seconds
[2025-02-01T20:31:28.890+0000] {processor.py:186} INFO - Started process (PID=479) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:31:28.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:31:28.893+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:31:28.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:31:28.909+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:31:28.905+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job_dqc = BashOperator(
                        ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:31:28.910+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:31:28.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.041 seconds
[2025-02-01T20:31:47.061+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:31:47.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:31:47.063+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:31:47.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:31:47.088+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:31:47.083+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 39, in <module>
    run_spark_job_dqc = BashOperator(
                        ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 166, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 506, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 975, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 256, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_spark_job' has already been added to the DAG
[2025-02-01T20:31:47.089+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:31:47.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.050 seconds
[2025-02-01T20:32:12.305+0000] {processor.py:186} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:32:12.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:32:12.307+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:32:12.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:32:12.334+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:32:12.481+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:32:12.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:32:12.500+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:32:12.499+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:32:12.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.232 seconds
[2025-02-01T20:32:42.602+0000] {processor.py:186} INFO - Started process (PID=522) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:32:42.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:32:42.604+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:32:42.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:32:42.632+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:32:42.665+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:32:42.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:32:42.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:32:42.700+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:32:42.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.132 seconds
[2025-02-01T20:33:12.847+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:33:12.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:33:12.849+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:33:12.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:33:12.865+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:33:12.891+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:33:12.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:33:12.905+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:33:12.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:33:12.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T20:33:43.090+0000] {processor.py:186} INFO - Started process (PID=532) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:33:43.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:33:43.092+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:33:43.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:33:43.108+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:33:43.131+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:33:43.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:33:43.144+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:33:43.144+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:33:43.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T20:34:13.384+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:13.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:34:13.387+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:13.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:13.404+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:13.430+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:13.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:34:13.446+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:13.446+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:34:13.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.089 seconds
[2025-02-01T20:34:43.616+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:43.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:34:43.617+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:43.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:43.632+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:43.654+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:43.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:34:43.666+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:43.666+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:34:43.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.070 seconds
[2025-02-01T20:34:58.847+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:58.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:34:58.849+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:58.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:58.872+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:34:58.988+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:58.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:34:59.000+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:34:59.000+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:34:59.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.179 seconds
[2025-02-01T20:35:29.078+0000] {processor.py:186} INFO - Started process (PID=552) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:35:29.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:35:29.080+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:35:29.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:35:29.095+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:35:29.118+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:35:29.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:35:29.131+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:35:29.130+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:35:29.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T20:35:59.325+0000] {processor.py:186} INFO - Started process (PID=557) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:35:59.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:35:59.327+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:35:59.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:35:59.342+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:35:59.365+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:35:59.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:35:59.378+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:35:59.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:35:59.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T20:36:29.665+0000] {processor.py:186} INFO - Started process (PID=595) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:36:29.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:36:29.668+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:36:29.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:36:29.689+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:36:29.720+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:36:29.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:36:29.740+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:36:29.739+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:36:29.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.116 seconds
[2025-02-01T20:36:59.970+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:36:59.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:36:59.972+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:36:59.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:36:59.989+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:37:00.013+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:37:00.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:37:00.027+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:37:00.026+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:37:00.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.104 seconds
[2025-02-01T20:37:30.257+0000] {processor.py:186} INFO - Started process (PID=605) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:37:30.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:37:30.260+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:37:30.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:37:30.274+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:37:30.297+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:37:30.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:37:30.310+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:37:30.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:37:30.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T20:38:00.518+0000] {processor.py:186} INFO - Started process (PID=610) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:38:00.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:38:00.521+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:38:00.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:38:00.536+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:38:00.558+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:38:00.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:38:00.571+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:38:00.571+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:38:00.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T20:38:30.794+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:38:30.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:38:30.795+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:38:30.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:38:30.811+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:38:30.833+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:38:30.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:38:30.846+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:38:30.846+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:38:30.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T20:39:01.027+0000] {processor.py:186} INFO - Started process (PID=620) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:39:01.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:39:01.029+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:39:01.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:39:01.043+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:39:01.065+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:39:01.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:39:01.078+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:39:01.078+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:39:01.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:39:31.297+0000] {processor.py:186} INFO - Started process (PID=625) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:39:31.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:39:31.299+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:39:31.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:39:31.315+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:39:31.339+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:39:31.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:39:31.353+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:39:31.353+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:39:31.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T20:40:01.532+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:40:01.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:40:01.534+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:40:01.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:40:01.549+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:40:01.572+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:40:01.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:40:01.586+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:40:01.585+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:40:01.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T20:40:31.833+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:40:31.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:40:31.835+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:40:31.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:40:31.849+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:40:31.871+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:40:31.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:40:31.884+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:40:31.883+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:40:31.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:41:02.080+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:02.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:41:02.082+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:02.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:02.097+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:02.121+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:02.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:41:02.133+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:02.133+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:41:02.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T20:41:06.163+0000] {processor.py:186} INFO - Started process (PID=645) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:06.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:41:06.166+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:06.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:06.198+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:06.303+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:06.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:41:06.314+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:06.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:41:06.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.305 seconds
[2025-02-01T20:41:21.578+0000] {processor.py:186} INFO - Started process (PID=650) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:21.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:41:21.580+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:21.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:21.603+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:21.613+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:21.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:41:21.628+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:21.627+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:41:21.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T20:41:51.854+0000] {processor.py:186} INFO - Started process (PID=686) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:51.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:41:51.856+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:51.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:51.876+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:41:51.907+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:51.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:41:51.927+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:41:51.926+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:41:51.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T20:42:22.173+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:42:22.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:42:22.175+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:42:22.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:42:22.198+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:42:22.228+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:42:22.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:42:22.241+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:42:22.241+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:42:22.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T20:42:52.414+0000] {processor.py:186} INFO - Started process (PID=696) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:42:52.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:42:52.416+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:42:52.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:42:52.431+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:42:52.454+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:42:52.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:42:52.466+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:42:52.466+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:42:52.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:43:07.650+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:07.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:43:07.652+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:07.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:07.667+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:07.665+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 25
    run_regular_job = 
                      ^
SyntaxError: invalid syntax
[2025-02-01T20:43:07.667+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:07.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T20:43:11.692+0000] {processor.py:186} INFO - Started process (PID=706) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:11.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:43:11.694+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:11.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:11.720+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:11.744+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:11.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:43:11.760+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:11.759+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:43:11.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T20:43:41.982+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:41.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:43:41.984+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:41.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:42.002+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:43:42.030+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:42.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:43:42.044+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:43:42.044+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:43:42.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T20:44:12.281+0000] {processor.py:186} INFO - Started process (PID=736) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:44:12.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:44:12.283+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:44:12.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:44:12.299+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:44:12.322+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:44:12.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:44:12.338+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:44:12.337+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:44:12.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T20:44:42.540+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:44:42.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:44:42.542+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:44:42.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:44:42.556+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:44:42.579+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:44:42.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:44:42.593+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:44:42.592+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:44:42.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T20:45:12.831+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:45:12.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:45:12.833+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:12.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:45:12.850+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:45:12.873+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:12.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:45:12.887+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:12.886+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:45:12.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T20:45:43.072+0000] {processor.py:186} INFO - Started process (PID=751) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:45:43.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:45:43.074+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:43.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:45:43.089+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:45:43.112+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:43.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:45:43.124+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:45:43.124+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:45:43.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.071 seconds
[2025-02-01T20:46:13.368+0000] {processor.py:186} INFO - Started process (PID=756) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:46:13.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:46:13.370+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:13.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:46:13.385+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:46:13.409+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:13.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:46:13.424+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:13.424+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:46:13.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T20:46:43.647+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:46:43.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:46:43.648+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:43.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:46:43.664+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:46:43.687+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:43.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:46:43.700+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:46:43.700+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:46:43.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.073 seconds
[2025-02-01T20:47:13.903+0000] {processor.py:186} INFO - Started process (PID=766) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:13.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:47:13.905+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:13.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:13.927+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:13.961+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:13.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:47:13.979+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:13.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:47:14.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T20:47:36.146+0000] {processor.py:186} INFO - Started process (PID=771) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:36.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:47:36.149+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:36.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:36.175+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:36.201+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:36.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:47:36.215+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:36.215+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:47:36.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T20:47:50.299+0000] {processor.py:186} INFO - Started process (PID=776) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:50.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:47:50.302+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:50.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:50.317+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:50.315+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 8
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:47:50.318+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:50.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.063 seconds
[2025-02-01T20:47:53.365+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:53.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:47:53.367+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:53.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:53.379+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:47:53.378+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 7
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:47:53.380+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:47:53.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.058 seconds
[2025-02-01T20:48:22.643+0000] {processor.py:186} INFO - Started process (PID=786) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:22.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:48:22.645+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:22.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:22.658+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:22.657+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 7
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:48:22.658+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:22.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.036 seconds
[2025-02-01T20:48:23.671+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:23.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:48:23.673+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:23.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:23.687+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:23.686+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 7
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:48:23.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:23.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.037 seconds
[2025-02-01T20:48:24.730+0000] {processor.py:186} INFO - Started process (PID=796) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:24.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:48:24.732+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:24.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:24.745+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:24.744+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 7
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:48:24.746+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:24.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.058 seconds
[2025-02-01T20:48:25.759+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:25.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:48:25.761+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:25.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:25.777+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:25.776+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 7
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:48:25.777+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:25.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T20:48:38.978+0000] {processor.py:186} INFO - Started process (PID=806) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:38.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:48:38.980+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:38.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:39.003+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:39.037+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:39.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:48:39.052+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:39.052+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:48:39.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T20:48:46.044+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:46.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:48:46.047+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:46.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:46.062+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:46.061+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:48:46.063+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:46.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.065 seconds
[2025-02-01T20:48:47.063+0000] {processor.py:186} INFO - Started process (PID=816) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:47.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:48:47.065+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:47.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:47.079+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:48:47.078+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:48:47.080+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:48:47.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.037 seconds
[2025-02-01T20:49:17.300+0000] {processor.py:186} INFO - Started process (PID=821) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:49:17.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:49:17.303+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:49:17.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:49:17.316+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:49:17.315+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:49:17.316+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:49:17.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.058 seconds
[2025-02-01T20:49:47.572+0000] {processor.py:186} INFO - Started process (PID=826) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:49:47.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:49:47.574+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:49:47.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:49:47.589+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:49:47.588+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:49:47.590+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:49:47.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.063 seconds
[2025-02-01T20:50:17.827+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:17.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:50:17.829+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:17.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:17.842+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:17.841+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:50:17.843+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:17.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.061 seconds
[2025-02-01T20:50:30.022+0000] {processor.py:186} INFO - Started process (PID=836) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:30.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:50:30.024+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:30.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:30.038+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:30.037+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
                                      ^
IndentationError: unindent does not match any outer indentation level
[2025-02-01T20:50:30.038+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:30.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.059 seconds
[2025-02-01T20:50:32.064+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:32.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:50:32.066+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:32.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:32.079+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:32.078+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
                                      ^
IndentationError: unindent does not match any outer indentation level
[2025-02-01T20:50:32.080+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:32.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.035 seconds
[2025-02-01T20:50:34.148+0000] {processor.py:186} INFO - Started process (PID=846) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:34.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:50:34.150+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:34.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:34.165+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:34.164+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:50:34.166+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:34.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.067 seconds
[2025-02-01T20:50:37.180+0000] {processor.py:186} INFO - Started process (PID=851) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:37.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:50:37.182+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:37.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:37.208+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:37.543+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:37.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:50:37.554+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:37.554+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:50:37.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.402 seconds
[2025-02-01T20:50:44.304+0000] {processor.py:186} INFO - Started process (PID=856) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:44.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:50:44.306+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:44.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:44.332+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:50:44.343+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:44.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:50:44.356+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:50:44.356+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:50:44.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T20:51:14.556+0000] {processor.py:186} INFO - Started process (PID=861) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:51:14.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:51:14.558+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:51:14.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:51:14.574+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:51:14.604+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:51:14.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:51:14.616+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:51:14.616+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:51:14.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.104 seconds
[2025-02-01T20:51:44.885+0000] {processor.py:186} INFO - Started process (PID=885) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:51:44.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:51:44.887+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:51:44.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:51:44.903+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:51:44.934+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:51:44.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:51:44.946+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:51:44.946+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:51:44.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.108 seconds
[2025-02-01T20:52:15.179+0000] {processor.py:186} INFO - Started process (PID=910) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:52:15.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:52:15.182+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:52:15.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:52:15.205+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:52:15.255+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:52:15.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:52:15.279+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:52:15.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:52:15.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.164 seconds
[2025-02-01T20:52:45.486+0000] {processor.py:186} INFO - Started process (PID=915) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:52:45.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:52:45.489+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:52:45.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:52:45.507+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:52:45.539+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:52:45.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:52:45.552+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:52:45.552+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:52:45.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T20:53:15.831+0000] {processor.py:186} INFO - Started process (PID=920) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:15.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:53:15.833+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:15.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:15.848+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:15.880+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:15.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:53:15.895+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:15.894+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:53:15.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T20:53:39.039+0000] {processor.py:186} INFO - Started process (PID=925) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:39.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:53:39.041+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:39.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:39.055+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:39.054+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 8
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:53:39.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:39.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.036 seconds
[2025-02-01T20:53:47.103+0000] {processor.py:186} INFO - Started process (PID=930) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:47.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:53:47.104+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:47.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:47.127+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:47.158+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:47.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:53:47.172+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:47.172+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:53:47.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T20:53:51.185+0000] {processor.py:186} INFO - Started process (PID=935) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:51.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:53:51.187+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:51.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:51.201+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:51.200+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:53:51.202+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:51.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.050 seconds
[2025-02-01T20:53:53.285+0000] {processor.py:186} INFO - Started process (PID=940) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:53.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:53:53.288+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:53.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:53.305+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:53:53.304+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:53:53.306+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:53:53.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.045 seconds
[2025-02-01T20:54:23.538+0000] {processor.py:186} INFO - Started process (PID=945) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:54:23.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:54:23.540+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:54:23.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:54:23.553+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:54:23.552+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:54:23.554+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:54:23.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T20:54:53.818+0000] {processor.py:186} INFO - Started process (PID=950) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:54:53.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:54:53.820+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:54:53.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:54:53.834+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:54:53.833+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:54:53.835+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:54:53.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.038 seconds
[2025-02-01T20:55:24.060+0000] {processor.py:186} INFO - Started process (PID=955) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:55:24.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:55:24.062+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:55:24.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:55:24.076+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:55:24.075+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:55:24.076+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:55:24.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.058 seconds
[2025-02-01T20:55:54.334+0000] {processor.py:186} INFO - Started process (PID=960) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:55:54.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:55:54.336+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:55:54.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:55:54.348+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:55:54.347+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 23
    airflow variables set run_dqc True
            ^^^^^^^^^
SyntaxError: invalid syntax
[2025-02-01T20:55:54.349+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:55:54.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.057 seconds
[2025-02-01T20:56:18.562+0000] {processor.py:186} INFO - Started process (PID=965) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:18.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:56:18.564+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:18.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:18.587+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:18.835+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:18.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:56:18.846+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:18.845+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:56:18.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.309 seconds
[2025-02-01T20:56:19.614+0000] {processor.py:186} INFO - Started process (PID=970) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:19.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:56:19.616+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:19.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:19.648+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:19.658+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:19.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:56:19.673+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:19.673+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:56:19.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T20:56:49.908+0000] {processor.py:186} INFO - Started process (PID=1007) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:49.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:56:49.911+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:49.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:50.010+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:56:50.045+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:50.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:56:50.061+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:56:50.061+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:56:50.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.184 seconds
[2025-02-01T20:57:09.174+0000] {processor.py:186} INFO - Started process (PID=1012) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:57:09.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:57:09.176+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:57:09.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:57:09.209+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:57:09.234+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:57:09.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:57:09.247+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:57:09.247+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:57:09.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T20:57:39.529+0000] {processor.py:186} INFO - Started process (PID=1049) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:57:39.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:57:39.531+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:57:39.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:57:39.557+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:57:39.584+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:57:39.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:57:39.603+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:57:39.602+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:57:39.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T20:58:09.804+0000] {processor.py:186} INFO - Started process (PID=1087) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:58:09.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:58:09.807+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:58:09.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:58:09.915+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:58:09.957+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:58:09.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:58:09.988+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:58:09.987+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:58:10.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.216 seconds
[2025-02-01T20:58:40.145+0000] {processor.py:186} INFO - Started process (PID=1092) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:58:40.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:58:40.147+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:58:40.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:58:40.178+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:58:40.202+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:58:40.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:58:40.215+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:58:40.215+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:58:40.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T20:59:10.408+0000] {processor.py:186} INFO - Started process (PID=1097) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:10.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:59:10.410+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:10.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:10.437+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:10.464+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:10.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:59:10.480+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:10.479+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:59:10.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T20:59:18.525+0000] {processor.py:186} INFO - Started process (PID=1102) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:18.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:59:18.527+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:18.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:18.561+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:18.586+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:18.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:59:18.598+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:18.598+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:59:18.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T20:59:19.596+0000] {processor.py:186} INFO - Started process (PID=1107) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:19.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:59:19.598+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:19.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:19.627+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:19.651+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:19.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:59:19.663+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:19.663+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:59:19.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T20:59:49.922+0000] {processor.py:186} INFO - Started process (PID=1144) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:49.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T20:59:49.924+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:49.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:49.952+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T20:59:49.979+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:49.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T20:59:49.999+0000] {logging_mixin.py:190} INFO - [2025-02-01T20:59:49.999+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T20:59:50.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.110 seconds
[2025-02-01T21:00:13.158+0000] {processor.py:186} INFO - Started process (PID=1149) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:13.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:00:13.160+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:13.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:13.195+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:13.170+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    if run_regular_job =:
                       ^
SyntaxError: invalid syntax
[2025-02-01T21:00:13.196+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:13.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.059 seconds
[2025-02-01T21:00:16.266+0000] {processor.py:186} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:16.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:00:16.268+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:16.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:16.298+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:16.322+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:16.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:00:16.336+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:16.336+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:00:16.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.094 seconds
[2025-02-01T21:00:24.329+0000] {processor.py:186} INFO - Started process (PID=1159) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:24.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:00:24.331+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:24.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:24.366+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:24.394+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:24.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:00:24.408+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:24.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:00:24.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T21:00:24.471+0000] {processor.py:186} INFO - Started process (PID=1164) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:24.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:00:24.473+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:24.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:24.495+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:24.519+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:24.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:00:24.531+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:24.531+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:00:24.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.081 seconds
[2025-02-01T21:00:33.597+0000] {processor.py:186} INFO - Started process (PID=1169) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:33.598+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:00:33.599+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:33.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:33.628+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:00:33.651+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:33.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:00:33.664+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:00:33.663+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:00:33.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.104 seconds
[2025-02-01T21:01:03.928+0000] {processor.py:186} INFO - Started process (PID=1183) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:01:03.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:01:03.930+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:01:03.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:01:03.955+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:01:03.980+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:01:03.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:01:03.994+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:01:03.993+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:01:04.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T21:01:34.218+0000] {processor.py:186} INFO - Started process (PID=1197) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:01:34.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:01:34.220+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:01:34.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:01:34.242+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:01:34.265+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:01:34.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:01:34.277+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:01:34.277+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:01:34.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T21:02:04.505+0000] {processor.py:186} INFO - Started process (PID=1202) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:02:04.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:02:04.507+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:02:04.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:02:04.532+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:02:04.556+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:02:04.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:02:04.571+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:02:04.570+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:02:04.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T21:02:34.755+0000] {processor.py:186} INFO - Started process (PID=1207) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:02:34.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:02:34.757+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:02:34.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:02:34.780+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:02:34.802+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:02:34.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:02:34.815+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:02:34.815+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:02:34.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.104 seconds
[2025-02-01T21:03:05.061+0000] {processor.py:186} INFO - Started process (PID=1212) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:03:05.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:03:05.063+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:03:05.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:03:05.084+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:03:05.106+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:03:05.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:03:05.118+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:03:05.118+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:03:05.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T21:03:35.329+0000] {processor.py:186} INFO - Started process (PID=1226) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:03:35.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:03:35.331+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:03:35.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:03:35.347+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:03:35.371+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:03:35.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:03:35.385+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:03:35.385+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:03:35.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T21:04:05.638+0000] {processor.py:186} INFO - Started process (PID=1231) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:05.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:04:05.640+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:05.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:05.656+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:05.683+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:05.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:04:05.699+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:05.699+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:04:05.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T21:04:35.909+0000] {processor.py:186} INFO - Started process (PID=1236) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:35.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:04:35.911+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:35.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:35.928+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:35.952+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:35.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:04:35.964+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:35.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:04:35.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T21:04:55.070+0000] {processor.py:186} INFO - Started process (PID=1241) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:55.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:04:55.072+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:55.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:55.084+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:55.083+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 29
    if run_regular_job == "True:
                          ^
SyntaxError: unterminated string literal (detected at line 29)
[2025-02-01T21:04:55.084+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:55.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.058 seconds
[2025-02-01T21:04:58.134+0000] {processor.py:186} INFO - Started process (PID=1246) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:58.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:04:58.136+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:58.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:58.158+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:04:58.181+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:58.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:04:58.194+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:04:58.194+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:04:58.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T21:05:03.279+0000] {processor.py:186} INFO - Started process (PID=1251) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:03.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:05:03.280+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:03.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:03.292+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:03.291+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_airflow.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1133, in get_code
  File "<frozen importlib._bootstrap_external>", line 1063, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_airflow.py", line 31
    if run_dqc == "True:
                  ^
SyntaxError: unterminated string literal (detected at line 31)
[2025-02-01T21:05:03.292+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:03.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.034 seconds
[2025-02-01T21:05:04.356+0000] {processor.py:186} INFO - Started process (PID=1256) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:04.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:05:04.358+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:04.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:04.380+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:04.405+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:04.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:05:04.418+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:04.418+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:05:04.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.087 seconds
[2025-02-01T21:05:05.379+0000] {processor.py:186} INFO - Started process (PID=1261) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:05.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:05:05.381+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:05.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:05.398+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:05.442+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:05.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:05:05.455+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:05.455+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:05:05.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.124 seconds
[2025-02-01T21:05:35.744+0000] {processor.py:186} INFO - Started process (PID=1286) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:35.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:05:35.745+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:35.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:35.761+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:05:35.787+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:35.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:05:35.803+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:05:35.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:05:35.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T21:06:06.023+0000] {processor.py:186} INFO - Started process (PID=1325) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:06:06.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:06:06.025+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:06:06.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:06:06.043+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:06:06.069+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:06:06.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:06:06.083+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:06:06.083+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:06:06.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T21:06:36.376+0000] {processor.py:186} INFO - Started process (PID=1339) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:06:36.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:06:36.378+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:06:36.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:06:36.393+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:06:36.417+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:06:36.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:06:36.431+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:06:36.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:06:36.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T21:07:06.666+0000] {processor.py:186} INFO - Started process (PID=1344) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:07:06.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:07:06.668+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:07:06.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:07:06.685+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:07:06.711+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:07:06.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:07:06.725+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:07:06.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:07:06.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.105 seconds
[2025-02-01T21:07:36.955+0000] {processor.py:186} INFO - Started process (PID=1349) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:07:36.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:07:36.957+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:07:36.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:07:36.973+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:07:36.998+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:07:36.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:07:37.011+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:07:37.011+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:07:37.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T21:08:07.257+0000] {processor.py:186} INFO - Started process (PID=1354) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:08:07.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:08:07.259+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:08:07.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:08:07.275+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:08:07.297+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:08:07.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:08:07.310+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:08:07.310+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:08:07.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T21:08:37.511+0000] {processor.py:186} INFO - Started process (PID=1359) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:08:37.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:08:37.513+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:08:37.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:08:37.530+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:08:37.554+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:08:37.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:08:37.567+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:08:37.566+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:08:37.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T21:09:07.831+0000] {processor.py:186} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:09:07.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:09:07.833+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:09:07.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:09:07.848+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:09:07.872+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:09:07.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:09:07.890+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:09:07.890+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:09:07.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.129 seconds
[2025-02-01T21:09:38.091+0000] {processor.py:186} INFO - Started process (PID=1369) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:09:38.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:09:38.092+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:09:38.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:09:38.109+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:09:38.136+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:09:38.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:09:38.152+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:09:38.152+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:09:38.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T21:10:08.330+0000] {processor.py:186} INFO - Started process (PID=1374) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:10:08.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:10:08.332+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:10:08.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:10:08.347+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:10:08.370+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:10:08.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:10:08.382+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:10:08.382+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:10:08.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.072 seconds
[2025-02-01T21:10:38.656+0000] {processor.py:186} INFO - Started process (PID=1379) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:10:38.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:10:38.658+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:10:38.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:10:38.673+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:10:38.696+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:10:38.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:10:38.709+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:10:38.709+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:10:38.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T21:11:08.919+0000] {processor.py:186} INFO - Started process (PID=1403) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:11:08.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:11:08.921+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:11:08.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:11:08.945+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:11:08.973+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:11:08.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:11:08.992+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:11:08.991+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:11:09.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.098 seconds
[2025-02-01T21:11:39.270+0000] {processor.py:186} INFO - Started process (PID=1408) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:11:39.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:11:39.271+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:11:39.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:11:39.286+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:11:39.310+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:11:39.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:11:39.323+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:11:39.322+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:11:39.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.122 seconds
[2025-02-01T21:12:09.539+0000] {processor.py:186} INFO - Started process (PID=1413) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:12:09.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:12:09.541+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:12:09.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:12:09.560+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:12:09.589+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:12:09.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:12:09.608+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:12:09.607+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:12:09.630+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.096 seconds
[2025-02-01T21:12:39.885+0000] {processor.py:186} INFO - Started process (PID=1418) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:12:39.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:12:39.887+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:12:39.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:12:39.903+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:12:39.927+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:12:39.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:12:39.941+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:12:39.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:12:39.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T21:13:10.174+0000] {processor.py:186} INFO - Started process (PID=1713) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:13:10.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:13:10.176+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:13:10.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:13:10.195+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:13:10.231+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:13:10.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:13:10.247+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:13:10.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:13:10.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.097 seconds
[2025-02-01T21:13:40.558+0000] {processor.py:186} INFO - Started process (PID=1738) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:13:40.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:13:40.562+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:13:40.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:13:40.616+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:13:40.755+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:13:40.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:13:40.905+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:13:40.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:13:41.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.474 seconds
[2025-02-01T21:14:11.567+0000] {processor.py:186} INFO - Started process (PID=1935) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:14:11.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:14:11.576+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:14:11.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:14:11.798+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:14:12.041+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:14:12.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:14:12.098+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:14:12.097+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:14:12.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.638 seconds
[2025-02-01T21:14:42.588+0000] {processor.py:186} INFO - Started process (PID=2090) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:14:42.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:14:42.593+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:14:42.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:14:42.653+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:14:42.762+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:14:42.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:14:42.804+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:14:42.803+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:14:42.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.275 seconds
[2025-02-01T21:15:12.959+0000] {processor.py:186} INFO - Started process (PID=2095) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:15:12.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:15:12.961+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:15:12.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:15:12.978+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:15:13.014+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:15:13.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:15:13.029+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:15:13.028+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:15:13.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.089 seconds
[2025-02-01T21:15:43.217+0000] {processor.py:186} INFO - Started process (PID=2100) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:15:43.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:15:43.220+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:15:43.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:15:43.236+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:15:43.264+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:15:43.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:15:43.279+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:15:43.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:15:43.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T21:16:13.569+0000] {processor.py:186} INFO - Started process (PID=2105) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:16:13.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:16:13.571+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:16:13.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:16:13.589+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:16:13.620+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:16:13.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:16:13.636+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:16:13.636+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:16:13.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T21:16:43.875+0000] {processor.py:186} INFO - Started process (PID=2110) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:16:43.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:16:43.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:16:43.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:16:43.898+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:16:43.925+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:16:43.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:16:43.940+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:16:43.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:16:43.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T21:17:14.177+0000] {processor.py:186} INFO - Started process (PID=2115) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:17:14.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:17:14.179+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:17:14.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:17:14.196+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:17:14.221+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:17:14.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:17:14.238+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:17:14.237+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:17:14.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T21:17:44.473+0000] {processor.py:186} INFO - Started process (PID=2120) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:17:44.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:17:44.475+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:17:44.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:17:44.492+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:17:44.515+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:17:44.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:17:44.529+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:17:44.529+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:17:45.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 1.308 seconds
[2025-02-01T21:18:16.059+0000] {processor.py:186} INFO - Started process (PID=2125) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:18:16.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:18:16.062+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:18:16.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:18:16.080+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:18:16.109+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:18:16.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:18:16.124+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:18:16.124+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:18:16.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T21:18:46.310+0000] {processor.py:186} INFO - Started process (PID=2130) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:18:46.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:18:46.312+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:18:46.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:18:46.329+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:18:46.353+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:18:46.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:18:46.367+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:18:46.366+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:18:46.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T21:19:15.661+0000] {processor.py:186} INFO - Started process (PID=2135) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:15.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:19:15.663+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:15.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:15.680+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:15.710+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:15.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:19:15.726+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:15.726+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:19:15.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.090 seconds
[2025-02-01T21:19:22.718+0000] {processor.py:186} INFO - Started process (PID=2140) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:22.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:19:22.720+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:22.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:22.739+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:22.767+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:22.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:19:22.782+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:22.782+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:19:22.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.091 seconds
[2025-02-01T21:19:53.074+0000] {processor.py:186} INFO - Started process (PID=2145) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:53.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:19:53.076+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:53.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:53.093+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:19:53.118+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:53.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:19:53.131+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:19:53.131+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:19:53.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T21:20:23.329+0000] {processor.py:186} INFO - Started process (PID=2150) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:20:23.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:20:23.331+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:20:23.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:20:23.349+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:20:23.375+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:20:23.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:20:23.388+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:20:23.388+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:20:23.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.233 seconds
[2025-02-01T21:20:53.631+0000] {processor.py:186} INFO - Started process (PID=2155) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:20:53.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:20:53.632+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:20:53.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:20:53.648+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:20:53.673+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:20:53.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:20:53.686+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:20:53.686+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:20:53.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T21:21:23.878+0000] {processor.py:186} INFO - Started process (PID=2160) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:21:23.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:21:23.880+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:21:23.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:21:23.896+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:21:23.921+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:21:23.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:21:23.936+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:21:23.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:21:23.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.079 seconds
[2025-02-01T21:21:54.269+0000] {processor.py:186} INFO - Started process (PID=2165) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:21:54.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:21:54.271+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:21:54.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:21:54.287+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:21:54.311+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:21:54.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:21:54.324+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:21:54.323+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:21:54.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.115 seconds
[2025-02-01T21:22:24.519+0000] {processor.py:186} INFO - Started process (PID=2170) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:22:24.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:22:24.521+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:22:24.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:22:24.538+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:22:24.567+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:22:24.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:22:24.588+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:22:24.588+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:22:24.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.095 seconds
[2025-02-01T21:22:54.850+0000] {processor.py:186} INFO - Started process (PID=2175) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:22:54.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:22:54.852+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:22:54.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:22:54.869+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:22:54.892+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:22:54.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:22:54.905+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:22:54.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:22:54.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.137 seconds
[2025-02-01T21:23:25.111+0000] {processor.py:186} INFO - Started process (PID=2180) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:23:25.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:23:25.113+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:23:25.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:23:25.129+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:23:25.152+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:23:25.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:23:25.166+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:23:25.166+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:23:25.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.074 seconds
[2025-02-01T21:23:55.358+0000] {processor.py:186} INFO - Started process (PID=2185) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:23:55.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:23:55.360+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:23:55.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:23:55.376+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:23:55.400+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:23:55.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:23:55.414+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:23:55.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:23:55.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T21:24:25.677+0000] {processor.py:186} INFO - Started process (PID=2229) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:24:25.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:24:25.679+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:24:25.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:24:25.695+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:24:25.721+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:24:25.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:24:25.734+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:24:25.734+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:24:25.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T21:24:55.928+0000] {processor.py:186} INFO - Started process (PID=2248) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:24:55.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:24:55.930+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:24:55.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:24:55.946+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:24:55.974+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:24:55.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:24:55.988+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:24:55.988+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:24:56.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T21:25:26.244+0000] {processor.py:186} INFO - Started process (PID=2253) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:25:26.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:25:26.246+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:25:26.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:25:26.264+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:25:26.289+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:25:26.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:25:26.305+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:25:26.304+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:25:26.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T21:25:56.513+0000] {processor.py:186} INFO - Started process (PID=2258) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:25:56.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:25:56.515+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:25:56.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:25:56.532+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:25:56.558+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:25:56.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:25:56.572+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:25:56.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:25:56.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.264 seconds
[2025-02-01T21:26:26.836+0000] {processor.py:186} INFO - Started process (PID=2263) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:26:26.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:26:26.838+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:26:26.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:26:26.854+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:26:26.878+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:26:26.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:26:26.891+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:26:26.891+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:26:26.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T21:26:57.111+0000] {processor.py:186} INFO - Started process (PID=2268) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:26:57.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:26:57.113+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:26:57.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:26:57.130+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:26:57.155+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:26:57.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:26:57.171+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:26:57.170+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:26:57.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.083 seconds
[2025-02-01T21:27:27.400+0000] {processor.py:186} INFO - Started process (PID=2273) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:27:27.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:27:27.402+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:27:27.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:27:27.420+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:27:27.444+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:27:27.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:27:27.457+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:27:27.457+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:27:27.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T21:27:57.713+0000] {processor.py:186} INFO - Started process (PID=2278) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:27:57.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:27:57.715+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:27:57.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:27:57.732+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:27:57.757+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:27:57.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:27:57.771+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:27:57.771+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:27:57.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.080 seconds
[2025-02-01T21:28:28.027+0000] {processor.py:186} INFO - Started process (PID=2283) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:28:28.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:28:28.030+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:28:28.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:28:28.051+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:28:28.090+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:28:28.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:28:28.111+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:28:28.110+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:28:28.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.118 seconds
[2025-02-01T21:28:58.306+0000] {processor.py:186} INFO - Started process (PID=2288) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:28:58.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:28:58.308+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:28:58.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:28:58.325+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:28:58.350+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:28:58.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:28:58.515+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:28:58.515+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:28:58.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.254 seconds
[2025-02-01T21:29:28.660+0000] {processor.py:186} INFO - Started process (PID=2293) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:29:28.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:29:28.662+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:29:28.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:29:28.680+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:29:28.713+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:29:28.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:29:28.728+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:29:28.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:29:28.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.089 seconds
[2025-02-01T21:29:58.925+0000] {processor.py:186} INFO - Started process (PID=2298) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:29:58.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:29:58.927+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:29:58.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:29:58.945+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:29:58.973+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:29:58.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:29:58.987+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:29:58.987+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:29:59.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.085 seconds
[2025-02-01T21:30:29.252+0000] {processor.py:186} INFO - Started process (PID=2303) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:30:29.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:30:29.254+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:30:29.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:30:29.269+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:30:29.294+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:30:29.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:30:29.307+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:30:29.306+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:30:29.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T21:30:59.508+0000] {processor.py:186} INFO - Started process (PID=2308) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:30:59.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:30:59.510+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:30:59.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:30:59.526+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:30:59.551+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:30:59.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:30:59.564+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:30:59.564+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:30:59.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T21:31:29.813+0000] {processor.py:186} INFO - Started process (PID=2313) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:31:29.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:31:29.814+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:31:29.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:31:29.831+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:31:29.854+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:31:29.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:31:29.867+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:31:29.867+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:31:30.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.229 seconds
[2025-02-01T21:32:00.331+0000] {processor.py:186} INFO - Started process (PID=2318) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:32:00.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:32:00.333+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:32:00.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:32:00.350+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:32:00.374+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:32:00.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:32:00.387+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:32:00.387+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:32:00.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.076 seconds
[2025-02-01T21:32:30.581+0000] {processor.py:186} INFO - Started process (PID=2323) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:32:30.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:32:30.582+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:32:30.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:32:30.598+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:32:30.623+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:32:30.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:32:30.635+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:32:30.635+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:32:30.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.075 seconds
[2025-02-01T21:33:00.904+0000] {processor.py:186} INFO - Started process (PID=2328) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:33:00.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:33:00.906+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:33:00.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:33:00.922+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:33:00.945+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:33:00.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:33:00.959+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:33:00.958+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:33:01.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.101 seconds
[2025-02-01T21:33:31.173+0000] {processor.py:186} INFO - Started process (PID=2333) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:33:31.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:33:31.176+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:33:31.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:33:31.195+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:33:31.226+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:33:31.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:33:31.242+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:33:31.241+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:33:31.284+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.117 seconds
[2025-02-01T21:34:01.506+0000] {processor.py:186} INFO - Started process (PID=2338) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:34:01.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:34:01.509+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:34:01.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:34:01.527+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:34:01.556+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:34:01.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:34:01.570+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:34:01.570+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:34:01.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.114 seconds
[2025-02-01T21:34:31.792+0000] {processor.py:186} INFO - Started process (PID=2358) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:34:31.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:34:31.794+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:34:31.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:34:31.811+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:34:31.837+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:34:31.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:34:32.008+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:34:32.008+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:34:32.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.237 seconds
[2025-02-01T21:35:02.136+0000] {processor.py:186} INFO - Started process (PID=2364) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:35:02.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:35:02.138+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:35:02.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:35:02.154+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:35:02.181+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:35:02.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:35:02.195+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:35:02.195+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:35:02.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T21:35:32.391+0000] {processor.py:186} INFO - Started process (PID=2379) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:35:32.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:35:32.393+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:35:32.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:35:32.416+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:35:32.444+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:35:32.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:35:32.462+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:35:32.462+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:35:32.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.099 seconds
[2025-02-01T21:36:02.756+0000] {processor.py:186} INFO - Started process (PID=2393) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:36:02.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:36:02.758+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:36:02.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:36:02.776+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:36:02.802+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:36:02.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:36:02.818+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:36:02.817+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:36:02.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.111 seconds
[2025-02-01T21:36:33.092+0000] {processor.py:186} INFO - Started process (PID=2398) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:36:33.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:36:33.094+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:36:33.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:36:33.111+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:36:33.479+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:36:33.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:36:33.496+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:36:33.496+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_orchestration
[2025-02-01T21:36:33.497+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:36:33.497+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:36:33.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.445 seconds
[2025-02-01T21:37:03.821+0000] {processor.py:186} INFO - Started process (PID=2412) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:37:03.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:37:03.824+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:37:03.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:37:03.849+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:37:03.880+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:37:03.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:37:03.895+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:37:03.894+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:37:04.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.273 seconds
[2025-02-01T21:37:34.363+0000] {processor.py:186} INFO - Started process (PID=2419) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:37:34.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:37:34.365+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:37:34.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:37:34.383+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:37:34.414+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:37:34.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:37:34.429+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:37:34.429+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:37:34.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.092 seconds
[2025-02-01T21:38:04.624+0000] {processor.py:186} INFO - Started process (PID=2425) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:38:04.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:38:04.627+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:38:04.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:38:04.644+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:38:04.669+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:38:04.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:38:04.683+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:38:04.682+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:38:04.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.082 seconds
[2025-02-01T21:38:34.970+0000] {processor.py:186} INFO - Started process (PID=2437) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:38:34.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:38:34.972+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:38:34.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:38:34.990+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:38:35.018+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:38:35.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:38:35.033+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:38:35.033+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:38:35.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.088 seconds
[2025-02-01T21:39:05.242+0000] {processor.py:186} INFO - Started process (PID=2443) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:39:05.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:39:05.244+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:39:05.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:39:05.267+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:39:05.300+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:39:05.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:39:05.317+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:39:05.316+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:39:05.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.102 seconds
[2025-02-01T21:39:35.558+0000] {processor.py:186} INFO - Started process (PID=2450) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:39:35.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:39:35.563+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:39:35.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:39:35.590+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:39:35.618+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:39:35.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:39:35.634+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:39:35.633+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:39:35.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T21:40:05.859+0000] {processor.py:186} INFO - Started process (PID=2476) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:40:05.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:40:05.861+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:40:05.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:40:05.880+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:40:05.910+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:40:05.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:40:05.926+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:40:05.925+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:40:06.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.256 seconds
[2025-02-01T21:40:36.185+0000] {processor.py:186} INFO - Started process (PID=2487) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:40:36.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:40:36.187+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:40:36.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:40:36.204+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:40:36.231+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:40:36.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:40:36.247+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:40:36.246+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:40:36.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.086 seconds
[2025-02-01T21:41:06.445+0000] {processor.py:186} INFO - Started process (PID=2511) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:41:06.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:41:06.447+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:41:06.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:41:06.465+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:41:06.497+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:41:06.496+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:41:06.512+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:41:06.512+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:41:06.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.093 seconds
[2025-02-01T21:41:36.865+0000] {processor.py:186} INFO - Started process (PID=2530) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:41:36.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:41:36.868+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:41:36.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:41:36.890+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:41:36.919+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:41:36.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:41:36.937+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:41:36.936+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:41:36.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.100 seconds
[2025-02-01T21:42:07.150+0000] {processor.py:186} INFO - Started process (PID=2549) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:42:07.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:42:07.152+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:42:07.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:42:07.168+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:42:07.194+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:42:07.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:42:07.207+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:42:07.207+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:42:07.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.078 seconds
[2025-02-01T21:42:37.478+0000] {processor.py:186} INFO - Started process (PID=2554) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:42:37.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:42:37.480+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:42:37.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:42:37.496+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:42:37.520+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:42:37.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:42:37.534+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:42:37.534+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:42:37.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.249 seconds
[2025-02-01T21:43:07.990+0000] {processor.py:186} INFO - Started process (PID=2559) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:43:07.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:43:07.992+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:43:07.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:43:08.010+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:43:08.036+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:43:08.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:43:08.202+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:43:08.202+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:43:08.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.233 seconds
[2025-02-01T21:43:38.493+0000] {processor.py:186} INFO - Started process (PID=2564) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:43:38.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:43:38.494+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:43:38.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:43:38.511+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:43:38.547+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:43:38.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:43:38.569+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:43:38.568+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:43:38.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T21:44:08.769+0000] {processor.py:186} INFO - Started process (PID=2569) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:44:08.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:44:08.771+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:44:08.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:44:08.787+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:44:08.812+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:44:08.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:44:08.825+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:44:08.825+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:44:08.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.077 seconds
[2025-02-01T21:44:39.132+0000] {processor.py:186} INFO - Started process (PID=2574) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:44:39.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:44:39.135+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:44:39.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:44:39.152+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:44:39.179+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:44:39.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:44:39.193+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:44:39.192+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:44:39.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.084 seconds
[2025-02-01T21:45:09.398+0000] {processor.py:186} INFO - Started process (PID=2579) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:45:09.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:45:09.400+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:45:09.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:45:09.418+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:45:09.445+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:45:09.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:45:09.459+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:45:09.458+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:45:09.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.106 seconds
[2025-02-01T21:45:39.718+0000] {processor.py:186} INFO - Started process (PID=2584) to work on /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:45:39.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_airflow.py for tasks to queue
[2025-02-01T21:45:39.720+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:45:39.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:45:39.736+0000] {processor.py:925} INFO - DAG(s) 'spark_orchestration' retrieved from /opt/airflow/dags/spark_airflow.py
[2025-02-01T21:45:39.760+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:45:39.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-01T21:45:39.773+0000] {logging_mixin.py:190} INFO - [2025-02-01T21:45:39.773+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_orchestration to None, run_after=None
[2025-02-01T21:45:39.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_airflow.py took 0.220 seconds
